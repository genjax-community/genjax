{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Custom proposals\n",
    "subtitle: I'm doing importance sampling as advised but it's bad, what can I do?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing one can do is write a custom proposal for importance sampling.\n",
    "The idea is to sample from this one instead of the default one used by genjax when using `model.importance`.\n",
    "The default one is only informed by the structure of the model, and not by the posterior defined by both the model and the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax import gen, normal\n",
    "from jax import jit, random, vmap\n",
    "from jax.scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define a simple model with a broad normal prior and some observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def model():\n",
    "    # Initially, the prior is a pretty broad normal distribution centred at 0\n",
    "    x = normal(0.0, 100.0) @ \"x\"\n",
    "    # We add some observations, which will shift the posterior towards these values\n",
    "    _ = normal(x, 1.0) @ \"obs1\"\n",
    "    _ = normal(x, 1.0) @ \"obs2\"\n",
    "    _ = normal(x, 1.0) @ \"obs3\"\n",
    "    return x\n",
    "\n",
    "\n",
    "# We create some data, 3 observed values at 234\n",
    "obs = C[\"obs1\"].set(234.0) ^ C[\"obs2\"].set(234.0) ^ C[\"obs3\"].set(234.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run importance sampling with a default proposal,\n",
    "snd print the average weight of the samples, to give us a sense of how well the proposal is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "key, *sub_keys = random.split(key, 1000 + 1)\n",
    "sub_keys = jnp.array(sub_keys)\n",
    "args = ()\n",
    "jitted = jit(vmap(model.importance, in_axes=(0, None, None)))\n",
    "trace, weight = jitted(sub_keys, obs, args)\n",
    "print(\"The average weight is\", logsumexp(weight) - jnp.log(len(weight)))\n",
    "print(\"The maximum weight is\", weight.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both the average and even maximum weight are quite low, which means that the proposal is not doing a great job.\n",
    "Ideally, the weight should center around 1 and be quite concentrated around that value.\n",
    "A weight much higher than 1 means that the proposal is too narrow and is missing modes. Indeed, for that to happen, one has to sample a very unlikely value under the proposal which is very likely under the target.\n",
    "A weight much lower than 1 means that the proposal is too broad and is wasting samples. This happens in this case as the default proposal uses the broad prior `normal(0.0, 100.0)` as a proposal, which is far from the observed values centred around 234.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a custom proposal, which will be a normal distribution centred around the observed values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def proposal(obs):\n",
    "    avg_val = jnp.array(obs).mean()\n",
    "    std = jnp.array(obs).std()\n",
    "    x = (\n",
    "        normal(avg_val, 0.1 + std) @ \"x\"\n",
    "    )  # To avoid a degenerate proposal, we add a small value to the standard deviation\n",
    "    # Note that this is not very elegant as we'd like to only propose the latent variable `x`, but we need to add the observations to get a full trace\n",
    "    _ = normal(x, 1.0) @ \"obs1\"\n",
    "    _ = normal(x, 1.0) @ \"obs2\"\n",
    "    _ = normal(x, 1.0) @ \"obs3\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do things by hand first, let's reimplement the importance function.\n",
    "It samples from the proposal and then computes the importance weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_sample(target, proposal):\n",
    "    def _inner(key, target_args, proposal_args):\n",
    "        trace = proposal.simulate(key, *proposal_args)\n",
    "        chm = trace.get_sample()\n",
    "        proposal_logpdf = trace.get_score()\n",
    "        target_logpdf, _ = target.assess(chm, *target_args)\n",
    "        importance_weight = target_logpdf - proposal_logpdf\n",
    "        return (trace, importance_weight)\n",
    "\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run importance sampling with the custom proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "key, *sub_keys = random.split(key, 1000 + 1)\n",
    "sub_keys = jnp.array(sub_keys)\n",
    "args_for_model = ()\n",
    "args_for_proposal = (jnp.array([obs[\"obs1\"], obs[\"obs2\"], obs[\"obs3\"]]),)\n",
    "jitted = jit(vmap(importance_sample(model, proposal), in_axes=(0, None, None)))\n",
    "trace, new_weight = jitted(sub_keys, (args_for_model,), (args_for_proposal,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the new values, both average and maximum, are much higher than before, which means that the custom proposal is doing a much better job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The new average weight is\", logsumexp(new_weight) - jnp.log(len(new_weight)))\n",
    "print(\"The new maximum weight is\", new_weight.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
