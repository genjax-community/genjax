{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a generative function with a single variable but 2000 observations or I just want to use/apply it repeatedly, what do I do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genjax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from genjax import bernoulli, gen\n",
    "\n",
    "\n",
    "# First start by creating a simple generative function\n",
    "@gen\n",
    "def double_flip(p, q):\n",
    "    v1 = bernoulli(p) @ \"v1\"\n",
    "    v2 = bernoulli(q) @ \"v2\"\n",
    "    return v1 + v2\n",
    "\n",
    "\n",
    "# Now we can create a vectorized version that takes a batch of p values\n",
    "# and calls the function for each value in the batch.\n",
    "# The `in_axes` tell the `vmap_combinator` which arguments are\n",
    "# mapped over, and which are not.\n",
    "# The value `0` means we will map over this argument and `None` means we will not.\n",
    "batched_double_flip = genjax.vmap_combinator(double_flip, in_axes=(0, None))\n",
    "\n",
    "# Now we can use the batched version to generate a batch of samples\n",
    "key = jax.random.PRNGKey(0)\n",
    "size_of_batch = 20\n",
    "# To do so, we have to create batched keys and p values\n",
    "p = jax.random.uniform(key, (size_of_batch,))\n",
    "q = 0.5\n",
    "# We will run the generative function once for (p1, q), once for (p2, q), ...\n",
    "traces = batched_double_flip.simulate(key, (p, q))\n",
    "print(traces.get_retval())\n",
    "\n",
    "# We can also use call it on (p1,q1), (p2,q2), ...\n",
    "p = jax.random.uniform(key, (size_of_batch,))\n",
    "q = jax.random.uniform(key, (size_of_batch,))\n",
    "batched_double_flip_v2 = genjax.vmap_combinator(double_flip, in_axes=(0, 0))\n",
    "traces = batched_double_flip_v2.simulate(key, (p, q))\n",
    "print(traces.get_retval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We cannot batch different variables with different shapes\n",
    "try:\n",
    "    p = jax.random.uniform(key, (size_of_batch,))\n",
    "    q = jax.random.uniform(key, (size_of_batch + 1,))\n",
    "    traces = batched_double_flip_v2.simulate(key, (p, q))\n",
    "    print(traces.get_retval())\n",
    "except Exception:\n",
    "    print(\n",
    "        \"Error: The batched version of the generative function is not working correctly\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about iterating `vmap`, e.g. if we want to apply a generative function acting on a pixel over a 2D space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(42)\n",
    "image = jnp.zeros([300, 500], dtype=jnp.float32)\n",
    "\n",
    "\n",
    "# Generative function on one \"pixel\" value\n",
    "@gen\n",
    "def sample_pixel(pixel):\n",
    "    new_pixel = genjax.normal(pixel, 1.0) @ \"new_pixel\"\n",
    "    return new_pixel\n",
    "\n",
    "\n",
    "tr = sample_pixel.simulate(key, (0.0,))\n",
    "print(\"new_pixel:\", tr.get_sample()[\"new_pixel\"])\n",
    "\n",
    "# Now what if we want to apply a generative function over a 2D space?\n",
    "# We can use a nested `vmap_combinator`\n",
    "sample_image = genjax.vmap_combinator(in_axes=(0,))(\n",
    "    genjax.vmap_combinator(in_axes=(0,))(sample_pixel)\n",
    ")\n",
    "\n",
    "tr = sample_image.simulate(key, (image,))\n",
    "# We can access the new_pixel value for each pixel in the image\n",
    "print(tr.get_sample())\n",
    "print(\"2D space choicemap:\", tr.get_sample()[0, 0, \"new_pixel\"])\n",
    "print(\"2D space choicemap:\", tr.get_sample()[299, 499, \"new_pixel\"])\n",
    "\n",
    "# Model wrapped in a bigger model\n",
    "image = jnp.zeros([2, 3], dtype=jnp.float32)\n",
    "\n",
    "\n",
    "@gen\n",
    "def model(p):\n",
    "    sampled_image = sample_image(image) @ \"sampled_image\"\n",
    "    return sampled_image[0] + p\n",
    "\n",
    "\n",
    "tr = model.simulate(key, (0.0,))\n",
    "# We can use ellipsis to access the new_pixel value for each pixel in the image\n",
    "print(\"sampled_image:\", tr.get_sample()[\"sampled_image\", ..., ..., \"new_pixel\"])\n",
    "print()\n",
    "\n",
    "# Alternatively, we can flatten the 2 dimensions into one and use a single `vmap_combinator`.\n",
    "# This can be more efficient in some cases and usually has a faster compile time.\n",
    "sample_image_flat = genjax.vmap_combinator(in_axes=(0,))(sample_pixel)\n",
    "tr = sample_image_flat.simulate(key, (image.flatten(),))\n",
    "# resize the sample to the original shape\n",
    "out_image = tr.get_sample()[..., \"new_pixel\"].reshape(image.shape)\n",
    "print(\"sampled_image:\", out_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh but my iteration is actually over time, not space, i.e. I may want to reuse the same model by composing it with itself, e.g. for an HMM. \n",
    "For this, we can use the `scan` combinator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple kernel for a Hidden Markov Model (HMM) example.\n",
    "@gen\n",
    "def hmm_kernel(x):\n",
    "    z = genjax.normal(x, 1.0) @ \"z\"\n",
    "    y = genjax.normal(z, 1.0) @ \"y\"\n",
    "    return y\n",
    "\n",
    "\n",
    "# Now we can create a function that runs the kernel multiple times\n",
    "@genjax.scan_combinator(max_length=10)\n",
    "@gen\n",
    "def hmm(x, c):\n",
    "    x1 = hmm_kernel(x) @ \"x1\"\n",
    "    return x1, None\n",
    "\n",
    "\n",
    "# Alternatively, we can directly create the same HMM model\n",
    "@genjax.scan_combinator(max_length=10)\n",
    "@gen\n",
    "def hmm_v2(x, c):\n",
    "    z = genjax.normal(x, 1.0) @ \"z\"\n",
    "    y = genjax.normal(z, 1.0) @ \"y\"\n",
    "    return y, None\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "key, subkey = jax.random.split(key)\n",
    "initial_x = 0.0\n",
    "tr_1 = hmm.simulate(key, (initial_x, None))\n",
    "print(\"Value of z at the beginning:\", tr_1.get_sample()[0, \"x1\", \"z\"])\n",
    "print(\"Value of y at the end:\", tr_1.get_sample()[9, \"x1\", \"y\"])\n",
    "print(tr_1.get_sample()[..., \"x1\", \"z\"])\n",
    "\n",
    "tr_2 = hmm_v2.simulate(subkey, (initial_x, None))\n",
    "print(tr_2.get_sample()[0, \"z\"])\n",
    "print(tr_2.get_sample()[9, \"y\"])\n",
    "print(tr_2.get_sample()[..., \"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we can call the generative function with a repeat combinator\n",
    "# This will run the generative function multiple times on a single argument and return the results\n",
    "@genjax.gen\n",
    "def model(y):\n",
    "    x = genjax.normal(y, 0.01) @ \"x\"\n",
    "    y = genjax.normal(x, 0.01) @ \"y\"\n",
    "    return y\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "arg = 3.0\n",
    "tr = model.repeat(n=10).simulate(key, (arg,))\n",
    "\n",
    "print(tr.get_sample()[..., \"x\"])\n",
    "print()\n",
    "print(tr.get_retval())\n",
    "print()\n",
    "\n",
    "# It can be combined with vmap\n",
    "sub_keys = jax.random.split(key, 3)\n",
    "args = jnp.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "n = 3\n",
    "tr = jax.jit(jax.vmap(model.repeat(n=n).simulate, in_axes=(0, None)))(sub_keys, (args,))\n",
    "print(tr.get_sample())\n",
    "print()\n",
    "\n",
    "# Note that it's running a computation |keys| * |args| * |n| times,\n",
    "# i.e. 45 times in this case\n",
    "print(tr.get_retval())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genjax-trials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
