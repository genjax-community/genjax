{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22026280-7bc1-4e8b-93ca-c7a819271c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da4f39f5-e06d-40d6-911e-2753bc9daa30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ChoiceMapDistribution' from 'genjax._src.gensp' (/home/femtomc/Research/genjax/src/genjax/_src/gensp/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgenjax\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dippl\n",
      "File \u001b[0;32m~/Research/genjax/src/genjax/__init__.py:20\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenJAX is a probabilistic programming system constructed by combining the concepts of Gen with the program transformation and hardware accelerator compilation capabilities of JAX.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# This __init__ file exports GenJAX's public API.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# For the internals, see _src.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Closed modules.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dippl\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gensp\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inference\n",
      "File \u001b[0;32m~/Research/genjax/src/genjax/dippl.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 MIT Probabilistic Computing Project\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdippl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADEVDistribution\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdippl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flip_enum\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdippl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m geometric_reinforce\n",
      "File \u001b[0;32m~/Research/genjax/src/genjax/_src/dippl/__init__.py:34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01madevjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normal_reparam\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01madevjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sample_with_key\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgensp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChoiceMapDistribution\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerative\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AllSelection\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerative\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChoiceMap\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ChoiceMapDistribution' from 'genjax._src.gensp' (/home/femtomc/Research/genjax/src/genjax/_src/gensp/__init__.py)"
     ]
    }
   ],
   "source": [
    "import genjax\n",
    "from dataclasses import dataclass\n",
    "from genjax import dippl\n",
    "from genjax import gensp\n",
    "from genjax import select, dirac\n",
    "import equinox as eqx\n",
    "import optax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "from jax import config\n",
    "import adevjax\n",
    "from datasets import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "console = genjax.pretty(show_locals=False)\n",
    "key = jax.random.PRNGKey(314159)\n",
    "\n",
    "# Plotting.\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Data.\n",
    "train_images, _, _, _ = mnist()\n",
    "train_images = jnp.where(train_images > 0.5, 1.0, 0.0)\n",
    "\n",
    "\n",
    "def dataloader(image_array, batch_size):\n",
    "    dataset_size = len(train_images)\n",
    "    indices = np.arange(dataset_size)\n",
    "    while True:\n",
    "        perm = np.random.permutation(indices)\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        while end <= dataset_size:\n",
    "            batch_perm = perm[start:end]\n",
    "            yield image_array[batch_perm]\n",
    "            start = end\n",
    "            end = start + batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ebca8-6572-46f3-8bb9-ccf028098347",
   "metadata": {},
   "source": [
    "## Visualize some of the data examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba6282-b772-497f-9a92-b17315ace612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))\n",
    "counter = 0\n",
    "for (i, j) in itertools.product(range(0, 3), range(0, 3)):\n",
    "    sub_axis = axs[i, j]\n",
    "    sub_axis.set_axis_off()\n",
    "    sub_axis.imshow(train_images[counter].reshape(28, 28) / 255.0, cmap=\"gray\")\n",
    "    counter += 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073131cf-e948-48a9-ad34-7bec2b3e1566",
   "metadata": {},
   "source": [
    "## Gradients using `DIPPL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f6d0f-997b-41de-85eb-0bfde6e83b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@genjax.gen\n",
    "def decoder_model(decoder):\n",
    "    latent = dippl.mv_normal_diag_reparam(jnp.zeros(10), jnp.ones(10)) @ \"latent\"\n",
    "    image = decoder(latent)\n",
    "    noisy_image = dippl.mv_normal_diag_reparam(image, jnp.ones(784)) @ \"image\"\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "def encoder_model(encoder, chm):\n",
    "    image = chm.get_leaf_value()[\"image\"]\n",
    "    μ, Σ_diag = encoder(image)\n",
    "    x = dippl.mv_normal_diag_reparam(μ, jnp.ones_like(μ)) @ \"latent\"\n",
    "\n",
    "\n",
    "decoder_model = gensp.choice_map_distribution(\n",
    "    decoder_model, select(\"latent\", \"image\"), None\n",
    ")\n",
    "encoder_model = gensp.choice_map_distribution(encoder_model, select(\"latent\"), None)\n",
    "\n",
    "# Define our gradient estimator using our loss language.\n",
    "def variational_value_and_grad(\n",
    "    key,\n",
    "    data,\n",
    "    encoder,\n",
    "    decoder,\n",
    "):\n",
    "    v_chm = genjax.value_choice_map(genjax.choice_map({\"image\": data}))\n",
    "\n",
    "    @dippl.loss\n",
    "    def vae_loss(encoder, decoder):\n",
    "        v = dippl.upper(encoder_model)(encoder, v_chm)\n",
    "        merged = gensp.merge(v, v_chm)\n",
    "        dippl.lower(decoder_model)(merged, decoder)\n",
    "\n",
    "    return vae_loss.value_and_grad_estimate(key, (encoder, decoder))\n",
    "\n",
    "\n",
    "def minibatch_value_and_grad(key, data, encoder, decoder):\n",
    "    sub_keys = jax.random.split(key, len(data))\n",
    "    loss, (encoder_grad, decoder_grad) = jax.vmap(\n",
    "        variational_value_and_grad, in_axes=(0, 0, None, None)\n",
    "    )(sub_keys, data, encoder, decoder)\n",
    "    encoder_grad, decoder_grad = jtu.tree_map(\n",
    "        lambda v: jnp.mean(v, axis=0), (encoder_grad, decoder_grad)\n",
    "    )\n",
    "    loss = jnp.mean(loss)\n",
    "    return loss, (encoder_grad, decoder_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e39d6d-c414-48a3-aba5-f745da5df392",
   "metadata": {},
   "source": [
    "## Encoder/decoder architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be6a31-f260-4652-a138-3970b3f0935b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EncoderNetwork(genjax.Pytree):\n",
    "    latent_dim: genjax.typing.Int\n",
    "    layers: genjax.typing.List\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.layers,), (self.latent_dim,)\n",
    "\n",
    "    def new(key, latent_dim):\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        conv_1 = eqx.nn.Conv2d(\n",
    "            in_channels=1, out_channels=32, kernel_size=3, stride=(2, 2), key=sub_key\n",
    "        )\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        conv_2 = eqx.nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=3, stride=(2, 2), key=sub_key\n",
    "        )\n",
    "        dense = eqx.nn.Linear(\n",
    "            in_features=2304, out_features=latent_dim + latent_dim, key=key\n",
    "        )\n",
    "        layers = [conv_1, conv_2, dense]\n",
    "        return EncoderNetwork(latent_dim, layers)\n",
    "\n",
    "    def __call__(self, v):\n",
    "        v = v.reshape(1, 28, 28)\n",
    "        for layer in self.layers[:-1]:\n",
    "            v = jax.nn.relu(layer(v))\n",
    "        v = v.flatten()\n",
    "        v = self.layers[-1](v)  # Dense\n",
    "        mu = v[0 : self.latent_dim]\n",
    "        sigma = v[self.latent_dim :]\n",
    "        return mu, jnp.exp(0.5 * sigma)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DecoderNetwork(genjax.Pytree):\n",
    "    layers: genjax.typing.List\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.layers,), ()\n",
    "\n",
    "    def new(key, latent_dim):\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        dense = eqx.nn.Linear(\n",
    "            in_features=latent_dim, out_features=6 * 6 * 32, key=sub_key\n",
    "        )\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        conv_tr_1 = eqx.nn.ConvTranspose2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=3, stride=2, key=sub_key\n",
    "        )\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        conv_tr_2 = eqx.nn.ConvTranspose2d(\n",
    "            in_channels=64, out_channels=32, kernel_size=3, stride=2, key=sub_key\n",
    "        )\n",
    "        conv_tr_3 = eqx.nn.ConvTranspose2d(\n",
    "            in_channels=32, out_channels=1, kernel_size=2, stride=1, key=key\n",
    "        )\n",
    "        layers = [dense, conv_tr_1, conv_tr_2, conv_tr_3]\n",
    "        return DecoderNetwork(layers)\n",
    "\n",
    "    def __call__(self, v):\n",
    "        v = jax.nn.relu(self.layers[0](v))\n",
    "        v = v.reshape(32, 6, 6)\n",
    "        for layer in self.layers[1:]:\n",
    "            v = jax.nn.relu(layer(v))\n",
    "        v = v.reshape(784)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae32d0-3d4c-438a-8e69-516bb26687e9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0c76f-b3a9-4384-ab2e-dcff5a34ee32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(314159)\n",
    "learning_rate = 1e-3\n",
    "iter_data = dataloader(train_images, 64)\n",
    "key, sub_key = jax.random.split(key)\n",
    "encoder_net = EncoderNetwork.new(sub_key, 10)\n",
    "key, sub_key = jax.random.split(key)\n",
    "decoder_net = DecoderNetwork.new(sub_key, 10)\n",
    "steps = 100000\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def make_step(key, encoder_net, decoder_net, data, opt_state):\n",
    "    loss, grads = minibatch_value_and_grad(key, data, encoder_net, decoder_net)\n",
    "    grads = jtu.tree_map(lambda v: -v, grads)\n",
    "    updates, opt_state = optim.update(grads, opt_state)\n",
    "    encoder_net, decoder_net = eqx.apply_updates((encoder_net, decoder_net), updates)\n",
    "    mean_grad = jnp.mean(jnp.array(jtu.tree_leaves(jtu.tree_map(jnp.mean, grads))))\n",
    "    return loss, (encoder_net, decoder_net), opt_state, mean_grad\n",
    "\n",
    "\n",
    "optim = optax.adam(learning_rate)\n",
    "opt_state = optim.init((encoder_net, decoder_net))\n",
    "for step, image_batch in tqdm(zip(range(steps), iter_data)):\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    loss, (encoder_net, decoder_net), opt_state, mean_grad = make_step(\n",
    "        sub_key, encoder_net, decoder_net, image_batch, opt_state\n",
    "    )\n",
    "    loss = loss.item()\n",
    "    if step % 1000 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32acade5-f5e6-40c8-bd41-624c57e39caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key, sub_key = jax.random.split(key)\n",
    "latent = genjax.tfp_mv_normal_diag.sample(sub_key, jnp.zeros(10), jnp.ones(10))\n",
    "plt.imshow(decoder_net(latent).reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e2440-9bf5-453d-acb4-2a0d2db532cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
