{
 "cells": [
  {
   "cell_type": "raw",
   "id": "be057fea-d7f8-4eae-815d-31470d4abe6e",
   "metadata": {},
   "source": [
    "---\n",
    "title: Incremental computation for generative functions\n",
    "date: \"December 1, 2022\"\n",
    "abstract: \"This notebook describes GenJAX's support for incremental computing, focused on the `update` generative function interface method. We also describe the `cache` primitive for the `BuiltinGenerativeFunction` language - which allows storing of deterministic state inside of `BuiltinTrace` instances. We discuss how both incremental computing and `cache` expose optimization opportunities which can be utilized by inference programmers.\n",
    "\n",
    "This notebook is a work in progress! You can refer to the documentation on [Gen.jl's argdiff system](https://www.gen.dev/docs/stable/ref/gfi/#Argdiffs-1) for more intuition.\"\n",
    "callout-appearance: simple\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79bc5678-235d-441c-9cc0-2ecd8f31daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "feb13e84-c9a6-4845-8271-841903b0eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "import genjax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import seaborn as sns\n",
    "from genjax.incremental import Diff, NoChange, UnknownChange\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Pretty printing.\n",
    "console = genjax.console(width=80)\n",
    "\n",
    "# Reproducibility.\n",
    "key = jax.random.PRNGKey(314159)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10095082-7aca-4809-8fc9-65d7de799047",
   "metadata": {},
   "source": [
    "The `update` interface method for generative functions defines an update operation on traces produced by generative functions. \n",
    "\n",
    "`update` allows the user to provide new constraints, as well as new arguments, and returns an updated trace which is consistent with the new constraints, as well as an incremental importance weight which measures the difference between the new and old constraints under the model. `update` is used to implement many types of iterative MCMC inference families.\n",
    "\n",
    "The specification of `update` only requires that a modeling language support the above behavior - nonetheless, modeling languages can implement `update` with custom optimizations to improve the cost of repeatedly calling `update` (e.g. an iterative MCMC inference procedure).\n",
    "\n",
    "In this notebook, we'll be focused on these optimization opportunities within the implementation of `update` for the `BuiltinGenerativeFunction` language. We'll describe a system which supports incremental computing capabilities using change information (called `Diff` in the codebase) propagation.^[Think of a value of `Diff` type as representing a new value $v^\\prime$ using a decomposition $v^\\prime = v \\oplus dv$ where $dv$ is the change to the value and $v$ is the original value.] \n",
    "\n",
    "While we'll be focused on the distribution and builtin languages, this system is also applicable to the combinator implementations of `update`. In another notebook, we'll see how the incremental computing system can be used to efficiently compute `update` for `UnfoldCombinator`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee0f12-574c-41cf-919f-ce26dac3f559",
   "metadata": {},
   "source": [
    "## What is `update` used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c3e26a-1c4d-4043-80b6-4273fc5004da",
   "metadata": {},
   "source": [
    "Before we discuss how `update` can be optimized by a generative function implementor, it's worth constructing a simple example which shows how `update` is used, and to show why optimizing `update` is worthwhile.\n",
    "\n",
    "One common usage of `update` is in MCMC algorithm kernels. MCMC is often repeatedly applied to generate a chain of samples: any optimization opportunities that we identify and take advantage of will provide runtime gains which are multiplied over the length of the chain.\n",
    "\n",
    "Let's example this scenario using a pedagogical example - remember that the potential optimization pattern (based upon random variable dependency information) we'll describe extends to all generative functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24992d53-3a85-47b7-9408-089bca007a42",
   "metadata": {},
   "source": [
    "### Pedagogical example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b79692e-a99c-4bbd-a330-b12744dda83d",
   "metadata": {},
   "source": [
    "Consider the following generative function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3aa8bfe6-fa2e-4b81-8e69-bca3e05e3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@genjax.Static\n",
    "def model(x):\n",
    "    a = genjax.trace(\"a\", genjax.normal)(x, 1.0)\n",
    "    b = genjax.trace(\"b\", genjax.normal)(x, 1.0)\n",
    "    c = genjax.trace(\"c\", genjax.normal)(a + b, 1.0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e11a9-d09b-4586-9638-c07e66119971",
   "metadata": {},
   "source": [
    "The variable dependency graph is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e286b55-79a6-4a55-95d5-c742fcbe97f2",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart LR\n",
    "  x[Argument] --> a[a]\n",
    "  x --> b[b]\n",
    "  a --> c[c]\n",
    "  b --> c\n",
    "  c --> r[Return]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085bc78-3db7-4481-b392-47f8f6888bb9",
   "metadata": {},
   "source": [
    "Now, when we simulate a trace from this model - we get choices for `\"a\"`, `\"b\"`, and `\"c\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "859e6b77-40ff-4dc4-9206-9c745862a361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StaticTrace(gen_fn=StaticGenerativeFunction(source=<function model at 0x130648430>), args=(2.0,), retval=Array(3.6991668, dtype=float32), address_choices=Trie(inner={'a': DistributionTrace(gen_fn=TFPDistribution(make_distribution=<class 'tensorflow_probability.substrates.jax.distributions.normal.Normal'>), args=(2.0, 1.0), value=Array(0.32779634, dtype=float32), score=Array(-2.317071, dtype=float32)), 'b': DistributionTrace(gen_fn=TFPDistribution(make_distribution=<class 'tensorflow_probability.substrates.jax.distributions.normal.Normal'>), args=(2.0, 1.0), value=Array(1.6706116, dtype=float32), score=Array(-0.97318685, dtype=float32)), 'c': DistributionTrace(gen_fn=TFPDistribution(make_distribution=<class 'tensorflow_probability.substrates.jax.distributions.normal.Normal'>), args=(Array(1.998408, dtype=float32), 1.0), value=Array(3.6991668, dtype=float32), score=Array(-2.3652287, dtype=float32))}), cache=Trie(inner={}), score=Array(-5.6554866, dtype=float32))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key, sub_key = jax.random.split(key)\n",
    "tr = model.simulate(sub_key, (2.0,))\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd87959a-a1f0-43eb-92ad-4cb36f753b3d",
   "metadata": {},
   "source": [
    "Iterative inference techniques like Metropolis-Hastings (and other MCMC methods) start with an initial trace, propose an update to the trace using a proposal, and then compute a criterion for accepting or rejecting the update.\n",
    "\n",
    "In Metropolis-Hastings, the criterion involves an _accept-reject ratio_ computation - which requires computing the probability of transitioning from the current trace to the new trace, as well as the probability of transitioning from the new trace back to the current trace, under a kernel defined by the algorithm.\n",
    "\n",
    "The library implementation of Metropolis-Hastings is shown below - `MetropolisHastings.apply` shows the main content of the algorithm (it's safe to ignore other methods for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5488356c-fba5-49cb-8ae5-851548dc0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genjax.inference.mcmc import MCMCKernel\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class MetropolisHastings(MCMCKernel):\n",
    "    selection: genjax.Selection\n",
    "    proposal: genjax.GenerativeFunction\n",
    "\n",
    "    def flatten(self):\n",
    "        return (), (self.selection, self.proposal)\n",
    "\n",
    "    def apply(self, key, trace: genjax.Trace, proposal_args: Tuple):\n",
    "        model = trace.get_gen_fn()\n",
    "        model_args = trace.get_args()\n",
    "        proposal_args_fwd = (trace.get_choices(), *proposal_args)\n",
    "        key, proposal_tr = self.proposal.simulate(key, proposal_args_fwd)\n",
    "        fwd_weight = proposal_tr.get_score()\n",
    "        diffs = jtu.tree_map(Diff.no_change, model_args)\n",
    "        key, (_, weight, new, discard) = model.update(\n",
    "            key, trace, proposal_tr.get_choices(), diffs\n",
    "        )\n",
    "        proposal_args_bwd = (new, *proposal_args)\n",
    "        key, (bwd_weight, _) = self.proposal.importance(key, discard, proposal_args_bwd)\n",
    "        alpha = weight - fwd_weight + bwd_weight\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        check = jnp.log(random.uniform(sub_key)) < alpha\n",
    "        return (\n",
    "            key,\n",
    "            jax.lax.cond(\n",
    "                check,\n",
    "                lambda *args: (new, True),\n",
    "                lambda *args: (trace, False),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def reversal(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b3a859-15bc-4056-a86b-934a1e1e5c05",
   "metadata": {},
   "source": [
    "This computation involves `update` - which _incrementally_ updates a trace to be consistent with new arguments and constraints, and computes an importance weight (the difference between the trace's new score and the old score).\n",
    "\n",
    "::: {.callout-important}\n",
    "\n",
    "In the invocation of `update`, there's an interesting not-yet-explained argument: `diffs` - a tuple of `Diff` values, which represent _changes_ to the original arguments of the call which produced the trace which we are attempting to update. We'll come back to these values in a moment.\n",
    "\n",
    ":::\n",
    "\n",
    "If we naively evaluate the required log probability by re-evaluating the entire model - we're performing extra computation. We can see this by considering a specific target address - let's consider `\"a\"`. If the update changes `\"a\"`, what other generative function calls do we need to visit to compute the correct update - both to the trace, and the importance weight? \n",
    "\n",
    "The graph below shows the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8571f5b-9bda-449f-abae-545749bb2704",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart LR\n",
    "  x[Argument] --> a[a]\n",
    "  x --> b[b]\n",
    "  a --> c[c]\n",
    "  b --> c\n",
    "  c --> r[Return]\n",
    "  style a fill:#f9f,stroke:#333,stroke-width:4px\n",
    "  style c fill:#f9f,stroke:#333,stroke-width:4px\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d40518-059b-465d-be2c-f8fda66a368b",
   "metadata": {},
   "source": [
    "An update to `\"a\"` requires that we re-evaluate the log probability at `\"c\"` because the return value of the generative function call at `\"a\"` flows into the generative function call at `\"c\"` - but we do not need to re-visit `\"b\"` because none of the values which flow into `\"b\"` have changed. \n",
    "\n",
    "When computing the weight difference, unchanged sites thus contribute nothing.^[The important idea is that tracking what values have changed allows us to identify what parts of the computation graph are required - and what parts do not need to be re-visited or re-computed.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38764bd-bf46-4bfa-b618-9e706e4a3bad",
   "metadata": {},
   "source": [
    "## Change information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd452d-947a-4be2-a897-a783b9ab678b",
   "metadata": {},
   "source": [
    "The specification of `update` doesn't require that an implementation track or use the change information - but generative function implementations can choose to optimize their `update` implementation. \n",
    "\n",
    "With that in mind, several of the languages which GenJAX exposes can be instructed to perform optimized `update` computations using `Diff` values.\n",
    "\n",
    "A `Diff` value consists of a base value `v` and a value of `Change` type, which represents the change to the base value. The new argument value for `update` is given by $\\text{v} \\oplus dv$ where `dv :: Change`. \n",
    "\n",
    "The $\\oplus$ operation must be appropriately defined for the change type lattice - we implement this operation for common change types in GenJAX, but users can define their own change types for `Pytree` data classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b80ae672-4b0d-46b5-9b64-1323639e9861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diff(primal=5.0, tangent=_NoChange())"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Diff(5.0, NoChange)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e26baf0-7710-40c3-8c8d-b6285cf3a600",
   "metadata": {},
   "source": [
    "### Diffs for distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c2ddea-72a4-4661-a1a6-4acb6f489fc1",
   "metadata": {},
   "source": [
    "Let's explore the basics with distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a25241e2-237c-47c3-8c7b-edf1d0258ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistributionTrace(gen_fn=TFPDistribution(make_distribution=<class 'tensorflow_probability.substrates.jax.distributions.normal.Normal'>), args=(0.0, 1.0), value=Array(0.27442896, dtype=float32), score=Array(-0.95659417, dtype=float32))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key, sub_key = jax.random.split(key)\n",
    "dist_tr = genjax.normal.simulate(sub_key, (0.0, 1.0))\n",
    "dist_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "329f3c3a-4e9c-4a8a-b222-9b596e8197ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, sub_key = jax.random.split(key)\n",
    "\n",
    "# dist_tr.update is equivalent to model.update(key, tr, ...)\n",
    "(ret_diff, w, tr, d) = dist_tr.update(\n",
    "    sub_key,\n",
    "    genjax.EmptyChoice(),\n",
    "    (\n",
    "        Diff(1.0, UnknownChange),\n",
    "        Diff(1.0, NoChange),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a824aee-88c9-4cf7-ae02-8882ae9b5dfa",
   "metadata": {},
   "source": [
    "The return values do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4140fd3-4cf0-4f94-81de-766c71ef484b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.27442896, dtype=float32), Array(0.27442896, dtype=float32))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dist_tr.get_retval(), ret_diff.get_retval())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c821e-3ec4-449c-95ce-b81e2cc30d79",
   "metadata": {},
   "source": [
    "The weight is non-zero because the arguments have changed, implying that we must re-evaluate the log probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "628a16ba-a3c8-493b-8ce0-5dfdc22cb568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-0.22557098, dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea0b062-175d-4078-b52f-9611864d5c2f",
   "metadata": {},
   "source": [
    "What does the code look like when there is no new constraint and both the arguments do not change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "516ce45c-b0f4-49b8-8a96-ab47c2954a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ lambda a:f32[] b:f32[]; c:u32[2] d:f32[] e:f32[]. let\n",
       "    \n",
       "  in (0.0, 1.0, a, b, 0.0, a) }"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dist_tr.update is equivalent to model.update(key, tr, ...)\n",
    "jaxpr = jax.make_jaxpr(dist_tr.update)(\n",
    "    key,\n",
    "    genjax.EmptyChoice(),\n",
    "    (\n",
    "        Diff(0.0, NoChange),\n",
    "        Diff(1.0, NoChange),\n",
    "    ),\n",
    ")\n",
    "jaxpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253febf4-13e4-4b62-abee-a5dd7279c180",
   "metadata": {},
   "source": [
    "As expected, no computation is required - so the flattened arguments are just forwarded to the return."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf31d5e-2be5-4a35-9d56-c70f7597586a",
   "metadata": {},
   "source": [
    "## `cache`: change aware memoization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e49e98-d0c2-4d96-8e07-47ff40ca86a0",
   "metadata": {},
   "source": [
    "The `BuiltinGenerativeFunction` language exposes a primitive called `cache` that interacts with the change tracking system to support memoization of deterministic computations (even deterministic computations which depend on random choices)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
