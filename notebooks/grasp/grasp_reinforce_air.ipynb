{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de0133f-4e97-401c-b216-e0bc64664444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from collections import namedtuple\n",
    "import pyro\n",
    "import optax\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "import pyro.contrib.examples.multi_mnist as multi_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from matplotlib import rcParams\n",
    "from scipy.interpolate import griddata\n",
    "import genjax\n",
    "from genjax import grasp\n",
    "\n",
    "key = jax.random.PRNGKey(314159)\n",
    "console = genjax.pretty()\n",
    "sns.set_theme(style=\"white\")\n",
    "font_path = (\n",
    "    \"/home/femtomc/.local/share/fonts/Unknown Vendor/TrueType/Lato/Lato_Bold.ttf\"\n",
    ")\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "custom_font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rcParams[\"font.family\"] = custom_font_name\n",
    "\n",
    "console = genjax.pretty()\n",
    "label_fontsize = 70  # Set the desired font size here\n",
    "\n",
    "smoke_test = \"CI\" in os.environ\n",
    "assert pyro.__version__.startswith(\"1.8.6\")\n",
    "\n",
    "from jax import config\n",
    "\n",
    "config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4985e835-14c9-43f0-8652-34da112dd6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size 80\u001b[0m\u001b[1;36m0x200\u001b[0m\u001b[39m with \u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inpath = \"./data/air/.data\"\n",
    "X_np, Y = multi_mnist.load(inpath)\n",
    "X_np = X_np.astype(np.float32)\n",
    "X_np /= 255.0\n",
    "mnist = jnp.array(X_np)\n",
    "true_counts = jnp.array([len(objs) for objs in Y])\n",
    "\n",
    "\n",
    "def show_images(imgs):\n",
    "    fig = plt.figure(figsize=(8, 2))\n",
    "    for i, img in enumerate(imgs):\n",
    "        ax = plt.subplot(1, len(imgs), i + 1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.imshow(img, cmap=\"gray_r\")\n",
    "\n",
    "\n",
    "show_images(mnist[9:14])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65227bc6-fd5e-486d-9cdc-0bfdf6cbde95",
   "metadata": {},
   "source": [
    "## Defining the variational ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78d35c-3e79-4ea7-95d9-82106cb22ad7",
   "metadata": {},
   "source": [
    "### Utilities / learnable pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38987718-1631-423e-8b70-95a469742beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from genjax import Pytree\n",
    "import equinox as eqx\n",
    "from genjax.typing import Any\n",
    "from genjax.typing import Tuple\n",
    "from genjax.typing import FloatArray\n",
    "from genjax.typing import Int\n",
    "from genjax.typing import IntArray\n",
    "from genjax.typing import PRNGKey\n",
    "from genjax.typing import typecheck\n",
    "\n",
    "# Utilities for defining the model and the guide.\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Decoder(Pytree):\n",
    "    dense_1: Any\n",
    "    dense_2: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense_1, self.dense_2), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key1, key2):\n",
    "        dense_1 = eqx.nn.Linear(50, 200, key=key1)\n",
    "        dense_2 = eqx.nn.Linear(200, 400, key=key2)\n",
    "        return Decoder(dense_1, dense_2)\n",
    "\n",
    "    def __call__(self, z_what):\n",
    "        v = self.dense_1(z_what)\n",
    "        v = jax.nn.leaky_relu(v)\n",
    "        v = self.dense_2(v)\n",
    "        return jax.nn.sigmoid(v)\n",
    "\n",
    "\n",
    "# Create our decoder.\n",
    "key, sub_key1, sub_key2 = jax.random.split(key, 3)\n",
    "decoder = Decoder.new(sub_key1, sub_key2)\n",
    "\n",
    "# Create our RNN for the guide.\n",
    "key, sub_key = jax.random.split(key)\n",
    "rnn = eqx.nn.LSTMCell(2554, 256, key=sub_key)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Encoder(Pytree):\n",
    "    dense_1: Any\n",
    "    dense_2: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense_1, self.dense_2), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key1, key2):\n",
    "        dense_1 = eqx.nn.Linear(400, 200, key=key1)\n",
    "        dense_2 = eqx.nn.Linear(200, 100, key=key2)\n",
    "        return Encoder(dense_1, dense_2)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        v = self.dense_1(data)\n",
    "        v = jax.nn.leaky_relu(v)\n",
    "        v = self.dense_2(v)\n",
    "        return v[0:50], jax.nn.softplus(v[50:])\n",
    "\n",
    "\n",
    "key, sub_key1, sub_key2 = jax.random.split(key, 3)\n",
    "encoder = Encoder.new(sub_key1, sub_key2)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Predict(Pytree):\n",
    "    dense: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense,), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key):\n",
    "        dense = eqx.nn.Linear(256, 7, key=key)\n",
    "        return Predict(dense)\n",
    "\n",
    "    def __call__(self, h):\n",
    "        a = self.dense(h)\n",
    "        z_pres_p = jax.nn.sigmoid(a[0:1])\n",
    "        z_where_loc = a[1:4]\n",
    "        z_where_scale = jax.nn.softplus(a[4:])\n",
    "        return z_pres_p, z_where_loc, z_where_scale\n",
    "\n",
    "\n",
    "key, sub_key = jax.random.split(key)\n",
    "predict = Predict.new(sub_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82446361-62cd-4cec-a8aa-d76b477603d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######\n",
    "# STN #\n",
    "#######\n",
    "\n",
    "# modified from https://github.com/kevinzakka/spatial-transformer-network/blob/master/stn/transformer.py\n",
    "\n",
    "\n",
    "def affine_grid_generator(height, width, theta):\n",
    "    \"\"\"\n",
    "    This function returns a sampling grid, which when\n",
    "    used with the bilinear sampler on the input feature\n",
    "    map, will create an output feature map that is an\n",
    "    affine transformation [1] of the input feature map.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - height: desired height of grid/output. Used\n",
    "      to downsample or upsample.\n",
    "\n",
    "    - width: desired width of grid/output. Used\n",
    "      to downsample or upsample.\n",
    "\n",
    "    - theta: affine transform matrices of shape (num_batch, 2, 3).\n",
    "      For each image in the batch, we have 6 theta parameters of\n",
    "      the form (2x3) that define the affine transformation T.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - normalized grid (-1, 1) of shape (num_batch, 2, H, W).\n",
    "      The 2nd dimension has 2 components: (x, y) which are the\n",
    "      sampling points of the original image for each point in the\n",
    "      target image.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    [1]: the affine transformation allows cropping, translation,\n",
    "         and isotropic scaling.\n",
    "    \"\"\"\n",
    "    num_batch = theta.shape[0]\n",
    "\n",
    "    # create normalized 2D grid\n",
    "    x = jnp.linspace(-1.0, 1.0, width)\n",
    "    y = jnp.linspace(-1.0, 1.0, height)\n",
    "    x_t, y_t = jnp.meshgrid(x, y)\n",
    "\n",
    "    # flatten\n",
    "    x_t_flat = jnp.reshape(x_t, [-1])\n",
    "    y_t_flat = jnp.reshape(y_t, [-1])\n",
    "\n",
    "    # reshape to [x_t, y_t , 1] - (homogeneous form)\n",
    "    ones = jnp.ones_like(x_t_flat)\n",
    "    sampling_grid = jnp.stack([x_t_flat, y_t_flat, ones])\n",
    "\n",
    "    # repeat grid num_batch times\n",
    "    sampling_grid = jnp.expand_dims(sampling_grid, axis=0)\n",
    "    sampling_grid = jnp.tile(sampling_grid, [num_batch, 1, 1])\n",
    "\n",
    "    # transform the sampling grid - batch multiply\n",
    "    batch_grids = jnp.matmul(theta, sampling_grid)\n",
    "    # batch grid has shape (num_batch, 2, H*W)\n",
    "\n",
    "    # reshape to (num_batch, 2, H, W)\n",
    "    batch_grids = jnp.reshape(batch_grids, [num_batch, 2, height, width])\n",
    "\n",
    "    return batch_grids\n",
    "\n",
    "\n",
    "def bilinear_sampler(img, x, y):\n",
    "    \"\"\"\n",
    "    Performs bilinear sampling of the input images according to the\n",
    "    normalized coordinates provided by the sampling grid. Note that\n",
    "    the sampling is done identically for each channel of the input.\n",
    "\n",
    "    To test if the function works properly, output image should be\n",
    "    identical to input image when theta is initialized to identity\n",
    "    transform.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - img: batch of images in (B, H, W, C) layout.\n",
    "    - grid: x, y which is the output of affine_grid_generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - out: interpolated images according to grids. Same size as grid.\n",
    "    \"\"\"\n",
    "    H = jnp.shape(img)[1]\n",
    "    W = jnp.shape(img)[2]\n",
    "    max_y = H - 1\n",
    "    max_x = W - 1\n",
    "    zero = jnp.zeros([], dtype=int)\n",
    "\n",
    "    # rescale x and y to [0, W-1/H-1]\n",
    "    x = 0.5 * ((x + 1.0) * max_x - 1)\n",
    "    y = 0.5 * ((y + 1.0) * max_y - 1)\n",
    "\n",
    "    # grab 4 nearest corner points for each (x_i, y_i)\n",
    "    x0 = jnp.floor(x).astype(int)\n",
    "    x1 = x0 + 1\n",
    "    y0 = jnp.floor(y).astype(int)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    # clip to range [0, H-1/W-1] to not violate img boundaries\n",
    "    x0 = jnp.clip(x0, zero, max_x)\n",
    "    x1 = jnp.clip(x1, zero, max_x)\n",
    "    y0 = jnp.clip(y0, zero, max_y)\n",
    "    y1 = jnp.clip(y1, zero, max_y)\n",
    "\n",
    "    # get pixel value at corner coords\n",
    "    Ia = get_pixel_value(img, x0, y0)\n",
    "    Ib = get_pixel_value(img, x0, y1)\n",
    "    Ic = get_pixel_value(img, x1, y0)\n",
    "    Id = get_pixel_value(img, x1, y1)\n",
    "\n",
    "    # recast as float for delta calculation\n",
    "    x0 = x0.astype(float)\n",
    "    x1 = x1.astype(float)\n",
    "    y0 = y0.astype(float)\n",
    "    y1 = y1.astype(float)\n",
    "\n",
    "    # calculate deltas\n",
    "    wa = (x1 - x) * (y1 - y)\n",
    "    wb = (x1 - x) * (y - y0)\n",
    "    wc = (x - x0) * (y1 - y)\n",
    "    wd = (x - x0) * (y - y0)\n",
    "\n",
    "    # add dimension for addition\n",
    "    wa = jnp.expand_dims(wa, axis=3)\n",
    "    wb = jnp.expand_dims(wb, axis=3)\n",
    "    wc = jnp.expand_dims(wc, axis=3)\n",
    "    wd = jnp.expand_dims(wd, axis=3)\n",
    "\n",
    "    # compute output\n",
    "    out = wa * Ia + wb * Ib + wc * Ic + wd * Id\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_pixel_value(img, x, y):\n",
    "    \"\"\"\n",
    "    Utility function to get pixel value for coordinate\n",
    "    vectors x and y from a  4D tensor image.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - img: tensor of shape (B, H, W, C)\n",
    "    - x: flattened tensor of shape (B*H*W,)\n",
    "    - y: flattened tensor of shape (B*H*W,)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - output: tensor of shape (B, H, W, C)\n",
    "    \"\"\"\n",
    "    batch_size, height, width = jnp.shape(x)\n",
    "\n",
    "    batch_idx = jnp.arange(0, batch_size)\n",
    "    batch_idx = jnp.reshape(batch_idx, (batch_size, 1, 1))\n",
    "    b = jnp.tile(batch_idx, (1, height, width))\n",
    "\n",
    "    indices = jnp.stack([b, y, x], 3)\n",
    "\n",
    "    return gather_nd(img, indices)\n",
    "\n",
    "\n",
    "# from: https://github.com/google/jax/discussions/6119\n",
    "def gather_nd_unbatched(params, indices):\n",
    "    return params[tuple(jnp.moveaxis(indices, -1, 0))]\n",
    "\n",
    "\n",
    "def gather_nd(params, indices, batch=False):\n",
    "    if not batch:\n",
    "        return gather_nd_unbatched(params, indices)\n",
    "    else:\n",
    "        return vmap(gather_nd_unbatched, (0, 0), 0)(params, indices)\n",
    "\n",
    "\n",
    "def expand_z_where(z_where):\n",
    "    # Takes 3-dimensional vectors, and massages them into 2x3 matrices with elements like so:\n",
    "    # [s,x,y] -> [[s,0,x],\n",
    "    #             [0,s,y]]\n",
    "    n = 1\n",
    "    expansion_indices = jnp.array([1, 0, 2, 0, 1, 3])\n",
    "    z_where = jnp.expand_dims(z_where, axis=0)\n",
    "    out = jnp.concatenate((jnp.broadcast_to(jnp.zeros([1, 1]), (n, 1)), z_where), 1)\n",
    "    return jnp.reshape(out[:, expansion_indices], (n, 2, 3))\n",
    "\n",
    "\n",
    "def object_to_image(z_where, obj):\n",
    "    n = 1\n",
    "    theta = expand_z_where(z_where)\n",
    "    grid = affine_grid_generator(50, 50, theta)\n",
    "    x_s = grid[:, 0, :, :]\n",
    "    y_s = grid[:, 1, :, :]\n",
    "    out = bilinear_sampler(jnp.reshape(obj, (n, 20, 20, 1)), x_s, y_s)\n",
    "    return jnp.reshape(out, (50, 50))\n",
    "\n",
    "\n",
    "def z_where_inv(z_where):\n",
    "    # Take a batch of z_where vectors, and compute their \"inverse\".\n",
    "    # That is, for each row compute:\n",
    "    # [s,x,y] -> [1/s,-x/s,-y/s]\n",
    "    # These are the parameters required to perform the inverse of the\n",
    "    # spatial transform performed in the generative model.\n",
    "    n = 1\n",
    "    out = jnp.array([1, *(-z_where[1:])])\n",
    "    out = out / z_where[0]\n",
    "    return out\n",
    "\n",
    "\n",
    "def image_to_object(z_where, image):\n",
    "    n = 1\n",
    "    theta_inv = expand_z_where(z_where_inv(z_where))\n",
    "    grid = affine_grid_generator(20, 20, theta_inv)\n",
    "    x_s = grid[:, 0, :, :]\n",
    "    y_s = grid[:, 1, :, :]\n",
    "    out = bilinear_sampler(jnp.reshape(image, (n, 50, 50, 1)), x_s, y_s)\n",
    "    return jnp.reshape(out, (400,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6179494f-ccc0-449f-8fcc-7bb48b4783e9",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60196b16-596f-4b7d-b040-85b8a2808423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########\n",
    "# Model #\n",
    "#########\n",
    "\n",
    "# Fixed constants.\n",
    "z_where_prior_loc = jnp.array([3.0, 0.0, 0.0])\n",
    "z_where_prior_scale = jnp.array([0.2, 1.0, 1.0])\n",
    "z_what_prior_loc = jnp.zeros(50, dtype=float)\n",
    "z_what_prior_scale = jnp.ones(50, dtype=float)\n",
    "z_pres_prior = [0.05, 0.05**2.3, 0.05 ** (5)]\n",
    "eps = 1e-4\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def step(\n",
    "    t: Int,\n",
    "    decoder: Decoder,\n",
    "    prev_x: FloatArray,\n",
    "    prev_z_pres: IntArray,\n",
    "):\n",
    "    z_pres = grasp.flip_reinforce(z_pres_prior[t]) @ f\"z_pres_{t}\"\n",
    "    z_pres = jnp.array([z_pres.astype(int)])\n",
    "    z_where = (\n",
    "        grasp.mv_normal_diag_reparam(z_where_prior_loc, z_where_prior_scale)\n",
    "        @ f\"z_where_{t}\"\n",
    "    )\n",
    "    z_what = (\n",
    "        grasp.mv_normal_diag_reparam(z_what_prior_loc, z_what_prior_scale)\n",
    "        @ f\"z_what_{t}\"\n",
    "    )\n",
    "    y_att = decoder(z_what)\n",
    "    y = object_to_image(z_where, y_att)\n",
    "    x = prev_x + (y * z_pres)\n",
    "    return x, z_pres\n",
    "\n",
    "\n",
    "# TODO: Make sure that this works, where t is a static int.\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def model(decoder: Decoder):\n",
    "    x = jnp.zeros((50, 50), dtype=float)\n",
    "    z_pres = jnp.ones(1, dtype=int)\n",
    "    for t in range(3):\n",
    "        x, z_pres = step.inline(t, decoder, x, z_pres)\n",
    "    obs = grasp.mv_normal_diag_reparam(x, 0.3 * jnp.ones_like(x)) @ \"obs\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee69ad5-2136-4933-ad71-42f01483dab6",
   "metadata": {},
   "source": [
    "#### Samples from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41747dee-44a0-4cd6-8087-4ce4d526fcee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "├── \u001b[1m:z_what_1\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_pres_1\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_pres_0\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_where_0\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:obs\u001b[0m\n",
       "│   └──  f32[50,50]\n",
       "├── \u001b[1m:z_what_0\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_where_2\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_where_1\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_pres_2\u001b[0m\n",
       "│   └──  bool[]\n",
       "└── \u001b[1m:z_what_2\u001b[0m\n",
       "    └──  f32[50]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = jax.jit(model.simulate)(key, (decoder,))\n",
    "tr.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8394159-926b-4607-8df0-bbcc49657ae0",
   "metadata": {},
   "source": [
    "### Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33dd2fbf-df45-4e48-ac82-9d005ffaab01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########\n",
    "# Guide #\n",
    "#########\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def guide_step(\n",
    "    t: Int,\n",
    "    rnn: eqx.nn.LSTMCell,\n",
    "    encoder: Encoder,\n",
    "    predict: Predict,\n",
    "    data,\n",
    "    prev: Tuple,\n",
    "):\n",
    "    (prev_z_where, prev_z_what, prev_z_pres, prev_h, prev_c) = prev\n",
    "    rnn_input = jnp.concatenate([data, prev_z_where, prev_z_what, prev_z_pres])\n",
    "    h, c = rnn(rnn_input, (prev_h, prev_c))\n",
    "    z_pres_p, z_where_loc, z_where_scale = predict(h)\n",
    "    z_pres_p = z_pres_p[0] * prev_z_pres[0]\n",
    "    z_pres_p = jnp.clip(z_pres_p, 0.001, 1.0)\n",
    "    z_pres = grasp.flip_reinforce(z_pres_p) @ f\"z_pres_{t}\"\n",
    "    (z_where_loc, z_where_scale) = jtu.tree_map(\n",
    "        lambda v1, v2: z_pres * v1 + (1 - z_pres) * v2,\n",
    "        (z_where_loc, z_where_scale),\n",
    "        (z_where_prior_loc, z_where_prior_scale),\n",
    "    )\n",
    "    z_where = grasp.mv_normal_diag_reparam(z_where_loc, z_where_scale) @ f\"z_where_{t}\"\n",
    "    x_att = image_to_object(z_where, data)\n",
    "    z_what_loc, z_what_scale = encoder(x_att)\n",
    "    (z_what_loc, z_what_scale) = jtu.tree_map(\n",
    "        lambda v1, v2: z_pres * v1 + (1 - z_pres) * v2,\n",
    "        (z_what_loc, z_what_scale),\n",
    "        (z_what_prior_loc, z_what_prior_scale),\n",
    "    )\n",
    "    z_what = grasp.mv_normal_diag_reparam(z_what_loc, z_what_scale) @ f\"z_what_{t}\"\n",
    "    z_pres = jnp.array([z_pres.astype(int)])\n",
    "    return z_where, z_what, z_pres, h, c\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def guide(\n",
    "    data: genjax.ChoiceMap,\n",
    "    rnn: eqx.nn.LSTMCell,\n",
    "    encoder: Encoder,\n",
    "    predict: Predict,\n",
    "):\n",
    "    h = jnp.zeros(256)\n",
    "    c = jnp.zeros(256)\n",
    "    z_pres = jnp.ones(1)\n",
    "    z_where = jnp.zeros(3)\n",
    "    z_what = jnp.zeros(50)\n",
    "    img = data[\"obs\"]\n",
    "    img_arr = img.flatten()\n",
    "\n",
    "    for t in range(3):\n",
    "        (z_where, z_what, z_pres, h, c) = guide_step.inline(\n",
    "            t, rnn, encoder, predict, img_arr, (z_where, z_what, z_pres, h, c)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89bc83-29fc-4e0e-a47d-dab2acf0c920",
   "metadata": {},
   "source": [
    "#### Samples from the guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2984c5cc-2b4c-40f5-ad0c-a2c3d1508f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "├── \u001b[1m:z_what_1\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_pres_1\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_pres_0\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_where_0\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_what_0\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_where_2\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_where_1\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_pres_2\u001b[0m\n",
       "│   └──  bool[]\n",
       "└── \u001b[1m:z_what_2\u001b[0m\n",
       "    └──  f32[50]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_chm = genjax.choice_map({\"obs\": jnp.ones((50, 50))})\n",
    "tr = guide.simulate(key, (data_chm, rnn, encoder, predict))\n",
    "tr.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b2f0a-dee4-470d-8bfa-c71a9e466690",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32a7cd-d44b-46dd-bea2-8ddac55aa88a",
   "metadata": {},
   "source": [
    "### Make sure grads are working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc1805-57c9-4c44-8ace-2b0fa068c9c7",
   "metadata": {},
   "source": [
    "#### Define ELBO objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "435472dd-c312-4f5f-8fc4-f2c0125491ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = genjax.choice_map({\"obs\": jnp.ones((50, 50))})\n",
    "objective = grasp.elbo(model, guide, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860fc0c2-6adb-4d7d-8ab1-0c1fccc16a65",
   "metadata": {},
   "source": [
    "#### Go go grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1ec3a5-e506-41bb-9a97-0c13bcbfb108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jitted = jax.jit(objective.value_and_grad_estimate)\n",
    "loss, ((decoder_grads,), (_, rnn_grads, encoder_grads, predict_grads)) = jitted(\n",
    "    key, ((decoder,), (data, rnn, encoder, predict))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817c347c-fdff-4822-9091-2d58887f5baa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mArray\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m-1704.9744\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mfloat32\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf5b4af-8df8-4bca-b0f2-c576dd0ba659",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdf9c5ed-4369-4a68-8ce8-af7754576fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_loader(\n",
    "    data,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "):\n",
    "    N = len(data)\n",
    "    data_idxs = np.arange(N)\n",
    "    num_batch = int(np.ceil(N // batch_size))\n",
    "\n",
    "    def init(key):\n",
    "        return (\n",
    "            num_batch,\n",
    "            jax.random.permutation(key, data_idxs) if shuffle else data_idxs,\n",
    "        )\n",
    "\n",
    "    def get_batch(i=0, idxs=data_idxs):\n",
    "        ret_idx = jax.lax.dynamic_slice_in_dim(idxs, i * batch_size, batch_size)\n",
    "        return jax.lax.index_take(data, (ret_idx,), axes=(0,))\n",
    "\n",
    "    return init, get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bce54cb-d22a-43b8-b296-6067484552d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Count Accuracy #\n",
    "##################\n",
    "\n",
    "\n",
    "def count_accuracy(data, true_counts, guide, batch_size=1000):\n",
    "    global prng_key\n",
    "    assert data.shape[0] == true_counts.shape[0], \"Size mismatch.\"\n",
    "    assert data.shape[0] % batch_size == 0, \"Input size must be multiple of batch_size.\"\n",
    "\n",
    "    def eval_guide(key, data, params):\n",
    "        data_chmp = genjax.choice_map({\"obs\": data})\n",
    "        return guide.simulate(key, (data_chmp, *params))\n",
    "\n",
    "    batch_eval_guide = jax.vmap(eval_guide, in_axes=(0, 0, None))\n",
    "\n",
    "    @jax.jit\n",
    "    def evaluate_count_accuracy(key, params):\n",
    "        def evaluate_batch(counts, batch_id):\n",
    "            data_batch = jax.lax.dynamic_slice_in_dim(\n",
    "                data, batch_id * batch_size, batch_size\n",
    "            )\n",
    "            true_counts_batch = jax.lax.dynamic_slice_in_dim(\n",
    "                true_counts, batch_id * batch_size, batch_size\n",
    "            )\n",
    "            data_chmp = genjax.choice_map({\"obs\": data_batch})\n",
    "            # evaluate guide\n",
    "            keys = jax.random.split(jax.random.fold_in(key, batch_id), batch_size)\n",
    "            tr = batch_eval_guide(keys, data_batch, params)\n",
    "            z_where = [tr[f\"z_where_{i}\"] for i in range(3)]\n",
    "            z_pres = [tr[f\"z_pres_{i}\"] for i in range(3)]\n",
    "            # compute stats\n",
    "            inferred_counts = sum(z for z in z_pres)\n",
    "            true_counts_m = jax.nn.one_hot(true_counts_batch, 3)\n",
    "            inferred_counts_m = jax.nn.one_hot(inferred_counts, 4)\n",
    "            counts += (true_counts_m.T @ inferred_counts_m).astype(int)\n",
    "            error_ind = 1 - (true_counts_batch == inferred_counts).astype(int)\n",
    "            # error_ix = error_ind.nonzero()[0]\n",
    "            # error_latent = jnp.take(latents_to_tensor((z_where, z_pres)), error_ix, 0)\n",
    "            return counts, error_ind\n",
    "\n",
    "        counts = jnp.zeros((3, 4), dtype=int)\n",
    "        counts, error_indices = jax.lax.scan(\n",
    "            evaluate_batch, counts, jnp.arange(data.shape[0] // batch_size)\n",
    "        )\n",
    "\n",
    "        acc = jnp.sum(jnp.diag(counts)).astype(float) / data.shape[0]\n",
    "        error_indices = jnp.concatenate(\n",
    "            error_indices\n",
    "        )  # .nonzero()[0]  # <- not JIT compilable\n",
    "        return acc, counts, error_indices\n",
    "\n",
    "    return evaluate_count_accuracy\n",
    "\n",
    "\n",
    "# Combine z_pres and z_where (as returned by the model and guide) into\n",
    "# a single tensor, with size:\n",
    "# [batch_size, num_steps, z_where_size + z_pres_size]\n",
    "def latents_to_tensor(z):\n",
    "    return jnp.stack(\n",
    "        [\n",
    "            jnp.concatenate((z_where, z_pres.reshape(-1, 1)), 1)\n",
    "            for z_where, z_pres in zip(*z)\n",
    "        ]\n",
    "    ).transpose(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3660daf7-584d-4fd9-a26b-371d32fb5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Visualization  #\n",
    "##################\n",
    "\n",
    "\n",
    "def bounding_box(z_where, x_size):\n",
    "    \"\"\"This doesn't take into account interpolation, but it's close\n",
    "    enough to be usable.\"\"\"\n",
    "    w = x_size / z_where.s\n",
    "    h = x_size / z_where.s\n",
    "    xtrans = -z_where.x / z_where.s * x_size / 2.0\n",
    "    ytrans = -z_where.y / z_where.s * x_size / 2.0\n",
    "    x = (x_size - w) / 2 + xtrans  # origin is top left\n",
    "    y = (x_size - h) / 2 + ytrans\n",
    "    return (x, y), w, h\n",
    "\n",
    "\n",
    "z_obj = namedtuple(\"z\", [\"s\", \"x\", \"y\", \"pres\"])\n",
    "\n",
    "\n",
    "# Map a tensor of latents (as produced by latents_to_tensor) to a list\n",
    "# of z_obj named tuples.\n",
    "def tensor_to_objs(latents):\n",
    "    return [[z_obj._make(step) for step in z] for z in latents]\n",
    "\n",
    "\n",
    "def visualize_model(model, guide):\n",
    "    def reconstruct_digits(key, data, params):\n",
    "        decoder, rnn, encoder, predict = params\n",
    "        data_chmp = genjax.choice_map({\"obs\": data})\n",
    "        key1, key2 = jax.random.split(key)\n",
    "        tr = guide.simulate(key1, (data_chmp, rnn, encoder, predict))\n",
    "        _, tr = model.importance(key2, tr, (decoder,))\n",
    "        reconstruction = tr.get_retval()\n",
    "        z_where = [tr[f\"z_where_{i}\"] for i in range(3)]\n",
    "        z_pres = [tr[f\"z_pres_{i}\"] for i in range(3)]\n",
    "        return reconstruction, (z_where, z_pres)\n",
    "\n",
    "    batch_reconstruct_digits = jax.jit(\n",
    "        jax.vmap(reconstruct_digits, in_axes=(0, 0, None))\n",
    "    )\n",
    "\n",
    "    def visualize(key, params, examples_to_viz):\n",
    "        keys = jax.random.split(key, examples_to_viz.shape[0])\n",
    "        recons, z = batch_reconstruct_digits(keys, examples_to_viz, params)\n",
    "        z_wheres = tensor_to_objs(latents_to_tensor(z))\n",
    "        draw_many(examples_to_viz.reshape(-1, 50, 50), z_wheres, title=\"Original\")\n",
    "        draw_many(recons, z_wheres, title=\"Reconstruction\")\n",
    "\n",
    "    return visualize\n",
    "\n",
    "\n",
    "def colors(k):\n",
    "    return [\"r\", \"g\", \"b\"][k % 3]\n",
    "\n",
    "\n",
    "def draw_one(img, z):\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img, cmap=\"gray_r\")\n",
    "    for k, z in enumerate(z):\n",
    "        if z.pres > 0:\n",
    "            (x, y), w, h = bounding_box(z, img.shape[0])\n",
    "            plt.gca().add_patch(\n",
    "                Rectangle(\n",
    "                    (x, y), w, h, linewidth=1, edgecolor=colors(k), facecolor=\"none\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "def draw_many(imgs, zs, title):\n",
    "    plt.figure(figsize=(8, 1.9))\n",
    "    plt.title(title)\n",
    "    plt.tick_params(left=False, labelleft=False, bottom=False, labelbottom=False)\n",
    "    plt.box(False)\n",
    "    for i, (img, z) in enumerate(zip(imgs, zs)):\n",
    "        plt.subplot(1, len(imgs), i + 1)\n",
    "        draw_one(img, z)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da48a46a-fdb1-4b8d-b4e5-d96d27b898d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (decoder, rnn, encoder, predict)\n",
    "evaluate_accuracy = count_accuracy(mnist, true_counts, guide, batch_size=1000)\n",
    "\n",
    "visualize_examples = mnist[5:10]\n",
    "visualize = visualize_model(model, guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaf743cf-aa9e-44db-9078-6a89f1d26f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(key, n=1, num_epochs=200, batch_size=64, learning_rate=1.0e-4):\n",
    "    def svi_update(model, guide, optimiser):\n",
    "        def batch_updater(key, params, opt_state, data_batch):\n",
    "            def grads(key, params, data):\n",
    "                (decoder, rnn, encoder, predict) = params\n",
    "                data = genjax.choice_map({\"obs\": data})\n",
    "                objective = grasp.iwae_elbo(model, guide, data, n)\n",
    "                loss, (\n",
    "                    (decoder_grads,),\n",
    "                    (_, rnn_grads, encoder_grads, predict_grads),\n",
    "                ) = objective.value_and_grad_estimate(\n",
    "                    key, ((decoder,), (data, rnn, encoder, predict))\n",
    "                )\n",
    "                return loss, (decoder_grads, rnn_grads, encoder_grads, predict_grads)\n",
    "\n",
    "            sub_keys = jax.random.split(key, len(data_batch))\n",
    "            loss, (decoder_grads, rnn_grads, encoder_grads, predict_grads) = jax.vmap(\n",
    "                grads, in_axes=(0, None, 0)\n",
    "            )(sub_keys, params, data_batch)\n",
    "\n",
    "            grads = jtu.tree_map(\n",
    "                lambda v: -1.0 * jnp.mean(v, axis=0),\n",
    "                (decoder_grads, rnn_grads, encoder_grads, predict_grads),\n",
    "            )\n",
    "            updates, opt_state = optimiser.update(grads, opt_state, params)\n",
    "            params = optax.apply_updates(params, updates)\n",
    "            loss = jnp.mean(loss)\n",
    "            return params, opt_state, loss\n",
    "\n",
    "        return batch_updater\n",
    "\n",
    "    adam = optax.adam(learning_rate)\n",
    "    svi_updater = svi_update(model, guide, adam)\n",
    "    train_init, train_fetch = data_loader(jnp.array(mnist), batch_size)\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    num_batch, train_idx = train_init(sub_key)\n",
    "\n",
    "    @jax.jit\n",
    "    def epoch_train(opt_state, params, key, train_idx):\n",
    "        def body_fn(carry, xs):\n",
    "            idx, params, opt_state, loss = carry\n",
    "            updater_key = jax.random.fold_in(key, idx)\n",
    "            batch = train_fetch(idx, train_idx)\n",
    "            params, opt_state, loss = svi_updater(updater_key, params, opt_state, batch)\n",
    "            idx += 1\n",
    "            return (idx, params, opt_state, loss), loss\n",
    "\n",
    "        idx = 0\n",
    "        (_, params, opt_state, _), losses = jax.lax.scan(\n",
    "            body_fn, (idx, params, opt_state, 0.0), None, length=num_batch\n",
    "        )\n",
    "        return params, opt_state, losses\n",
    "\n",
    "    # Train.\n",
    "    params = (decoder, rnn, encoder, predict)\n",
    "    opt_state = adam.init(params)\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    wall_clock_times = []\n",
    "\n",
    "    # Warm up.\n",
    "    _ = epoch_train(opt_state, params, key, train_idx)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    acc_time = 0.0\n",
    "    for i in range(0, num_epochs + 1):\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        num_batch, train_idx = train_init(sub_key)\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        start = time.perf_counter() - t0\n",
    "        params, opt_state, loss = epoch_train(opt_state, params, sub_key, train_idx)\n",
    "        stop = time.perf_counter() - t0\n",
    "        acc_time += stop - start\n",
    "        wall_clock_times.append(acc_time)\n",
    "        print(\n",
    "            f\"Epoch={i}, total_epoch_step_time={acc_time:.2f}, loss={jnp.mean(loss):.2f}\"\n",
    "        )\n",
    "        losses.append(jnp.mean(loss))\n",
    "        acc, counts, error_ix = evaluate_accuracy(sub_key, params[1:])\n",
    "        accuracy.append(acc)\n",
    "        print(\"accuracy={}, counts={}\".format(acc, counts))\n",
    "\n",
    "    return losses, accuracy, wall_clock_times, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bee83598-7119-4e04-992d-8a4fa160768e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, total_epoch_step_time=1.52, loss=38.03\n",
      "accuracy=0.2364666759967804, counts=[[11233  7326  1347    42]\n",
      " [17027  2951    42     0]\n",
      " [19174   854     4     0]]\n",
      "Epoch=1, total_epoch_step_time=3.05, loss=435.38\n",
      "accuracy=0.22691667079925537, counts=[[11583  7755   608     2]\n",
      " [17983  2031     6     0]\n",
      " [19583   448     1     0]]\n",
      "Epoch=2, total_epoch_step_time=4.54, loss=442.01\n",
      "accuracy=0.22425000369548798, counts=[[11871  7654   422     1]\n",
      " [18432  1584     4     0]\n",
      " [19731   301     0     0]]\n",
      "Epoch=3, total_epoch_step_time=6.01, loss=446.71\n",
      "accuracy=0.23194999992847443, counts=[[12692  6966   289     1]\n",
      " [18791  1225     4     0]\n",
      " [19834   198     0     0]]\n",
      "Epoch=4, total_epoch_step_time=7.61, loss=451.28\n",
      "accuracy=0.24076667428016663, counts=[[13515  6251   180     2]\n",
      " [19085   931     4     0]\n",
      " [19875   157     0     0]]\n",
      "Epoch=5, total_epoch_step_time=9.18, loss=455.63\n",
      "accuracy=0.2538999915122986, counts=[[14577  5293    78     0]\n",
      " [19362   657     1     0]\n",
      " [19903   129     0     0]]\n",
      "Epoch=6, total_epoch_step_time=10.83, loss=458.20\n",
      "accuracy=0.26809999346733093, counts=[[15532  4372    44     0]\n",
      " [19464   554     2     0]\n",
      " [19931   101     0     0]]\n",
      "Epoch=7, total_epoch_step_time=12.34, loss=459.27\n",
      "accuracy=0.279366672039032, counts=[[16422  3508    18     0]\n",
      " [19680   340     0     0]\n",
      " [19953    79     0     0]]\n",
      "Epoch=8, total_epoch_step_time=13.76, loss=459.63\n",
      "accuracy=0.28165000677108765, counts=[[16498  3440    10     0]\n",
      " [19618   401     1     0]\n",
      " [19957    75     0     0]]\n",
      "Epoch=9, total_epoch_step_time=15.26, loss=459.70\n",
      "accuracy=0.28351667523384094, counts=[[16710  3228    10     0]\n",
      " [19718   301     1     0]\n",
      " [19963    69     0     0]]\n",
      "Epoch=10, total_epoch_step_time=16.63, loss=459.80\n",
      "accuracy=0.2876666784286499, counts=[[17030  2914     4     0]\n",
      " [19790   230     0     0]\n",
      " [19982    50     0     0]]\n",
      "Epoch=11, total_epoch_step_time=18.11, loss=459.91\n",
      "accuracy=0.29528334736824036, counts=[[17567  2377     4     0]\n",
      " [19870   150     0     0]\n",
      " [19965    67     0     0]]\n",
      "Epoch=12, total_epoch_step_time=19.52, loss=459.96\n",
      "accuracy=0.29458335041999817, counts=[[17458  2487     3     0]\n",
      " [19803   217     0     0]\n",
      " [19966    66     0     0]]\n",
      "Epoch=13, total_epoch_step_time=20.95, loss=459.94\n",
      "accuracy=0.29403334856033325, counts=[[17463  2474    11     0]\n",
      " [19840   179     1     0]\n",
      " [19961    71     0     0]]\n",
      "Epoch=14, total_epoch_step_time=22.41, loss=459.96\n",
      "accuracy=0.28788334131240845, counts=[[17133  2810     5     0]\n",
      " [19879   140     1     0]\n",
      " [19975    57     0     0]]\n",
      "Epoch=15, total_epoch_step_time=23.85, loss=460.01\n",
      "accuracy=0.2901500165462494, counts=[[17320  2625     3     0]\n",
      " [19931    89     0     0]\n",
      " [19973    59     0     0]]\n",
      "Epoch=16, total_epoch_step_time=25.26, loss=460.04\n",
      "accuracy=0.28325000405311584, counts=[[16894  3041    13     0]\n",
      " [19919   101     0     0]\n",
      " [19971    61     0     0]]\n",
      "Epoch=17, total_epoch_step_time=26.68, loss=460.05\n",
      "accuracy=0.28189998865127563, counts=[[16810  3133     5     0]\n",
      " [19916   104     0     0]\n",
      " [19969    63     0     0]]\n",
      "Epoch=18, total_epoch_step_time=28.10, loss=460.09\n",
      "accuracy=0.28006666898727417, counts=[[16714  3228     6     0]\n",
      " [19930    90     0     0]\n",
      " [19977    55     0     0]]\n",
      "Epoch=19, total_epoch_step_time=29.48, loss=460.10\n",
      "accuracy=0.27756667137145996, counts=[[16571  3372     5     0]\n",
      " [19937    83     0     0]\n",
      " [19971    61     0     0]]\n",
      "Epoch=20, total_epoch_step_time=30.87, loss=460.10\n",
      "accuracy=0.2777666747570038, counts=[[16589  3354     5     0]\n",
      " [19943    77     0     0]\n",
      " [19967    65     0     0]]\n",
      "Epoch=21, total_epoch_step_time=32.26, loss=460.12\n",
      "accuracy=0.2695833444595337, counts=[[16083  3859     6     0]\n",
      " [19928    92     0     0]\n",
      " [19973    59     0     0]]\n",
      "Epoch=22, total_epoch_step_time=33.66, loss=460.14\n",
      "accuracy=0.2677166759967804, counts=[[15997  3943     8     0]\n",
      " [19954    66     0     0]\n",
      " [19956    76     0     0]]\n",
      "Epoch=23, total_epoch_step_time=35.06, loss=460.08\n",
      "accuracy=0.26249998807907104, counts=[[15666  4276     6     0]\n",
      " [19936    84     0     0]\n",
      " [19965    67     0     0]]\n",
      "Epoch=24, total_epoch_step_time=36.44, loss=460.07\n",
      "accuracy=0.26231667399406433, counts=[[15666  4275     7     0]\n",
      " [19947    73     0     0]\n",
      " [19977    55     0     0]]\n",
      "Epoch=25, total_epoch_step_time=37.82, loss=460.08\n",
      "accuracy=0.2676333487033844, counts=[[15982  3963     3     0]\n",
      " [19944    76     0     0]\n",
      " [19986    46     0     0]]\n",
      "Epoch=26, total_epoch_step_time=39.25, loss=460.09\n",
      "accuracy=0.26276665925979614, counts=[[15699  4237    12     0]\n",
      " [19953    67     0     0]\n",
      " [19979    53     0     0]]\n",
      "Epoch=27, total_epoch_step_time=40.66, loss=460.09\n",
      "accuracy=0.26524999737739563, counts=[[15843  4094    11     0]\n",
      " [19948    72     0     0]\n",
      " [19969    63     0     0]]\n",
      "Epoch=28, total_epoch_step_time=42.06, loss=460.14\n",
      "accuracy=0.2687833309173584, counts=[[16072  3866    10     0]\n",
      " [19965    55     0     0]\n",
      " [19976    56     0     0]]\n",
      "Epoch=29, total_epoch_step_time=43.54, loss=460.12\n",
      "accuracy=0.26961666345596313, counts=[[16102  3835    11     0]\n",
      " [19945    75     0     0]\n",
      " [19980    52     0     0]]\n",
      "Epoch=30, total_epoch_step_time=44.95, loss=460.11\n",
      "accuracy=0.2632666826248169, counts=[[15726  4215     7     0]\n",
      " [19950    70     0     0]\n",
      " [19978    54     0     0]]\n",
      "Epoch=31, total_epoch_step_time=46.32, loss=460.13\n",
      "accuracy=0.26934999227523804, counts=[[16096  3845     7     0]\n",
      " [19955    65     0     0]\n",
      " [19983    49     0     0]]\n",
      "Epoch=32, total_epoch_step_time=47.69, loss=460.15\n",
      "accuracy=0.2723666727542877, counts=[[16287  3657     4     0]\n",
      " [19965    55     0     0]\n",
      " [19966    66     0     0]]\n",
      "Epoch=33, total_epoch_step_time=49.09, loss=460.10\n",
      "accuracy=0.2669166624546051, counts=[[15952  3991     5     0]\n",
      " [19957    63     0     0]\n",
      " [19985    47     0     0]]\n",
      "Epoch=34, total_epoch_step_time=50.48, loss=460.11\n",
      "accuracy=0.2757166624069214, counts=[[16463  3479     6     0]\n",
      " [19940    80     0     0]\n",
      " [19969    63     0     0]]\n",
      "Epoch=35, total_epoch_step_time=51.87, loss=460.08\n",
      "accuracy=0.2727999985218048, counts=[[16310  3631     7     0]\n",
      " [19962    58     0     0]\n",
      " [19971    61     0     0]]\n",
      "Epoch=36, total_epoch_step_time=53.26, loss=460.13\n",
      "accuracy=0.26614999771118164, counts=[[15903  4036     9     0]\n",
      " [19954    66     0     0]\n",
      " [19967    65     0     0]]\n",
      "Epoch=37, total_epoch_step_time=54.64, loss=460.13\n",
      "accuracy=0.2652166783809662, counts=[[15862  4081     5     0]\n",
      " [19969    51     0     0]\n",
      " [19972    60     0     0]]\n",
      "Epoch=38, total_epoch_step_time=56.04, loss=460.14\n",
      "accuracy=0.26508334279060364, counts=[[15845  4092    11     0]\n",
      " [19961    59     0     0]\n",
      " [19969    62     1     0]]\n",
      "Epoch=39, total_epoch_step_time=57.42, loss=460.15\n",
      "accuracy=0.2748166620731354, counts=[[16433  3509     6     0]\n",
      " [19964    56     0     0]\n",
      " [19981    51     0     0]]\n",
      "Epoch=40, total_epoch_step_time=58.81, loss=460.13\n",
      "accuracy=0.2746833264827728, counts=[[16411  3533     4     0]\n",
      " [19950    70     0     0]\n",
      " [19976    56     0     0]]\n",
      "Epoch=0, total_epoch_step_time=1.38, loss=42.97\n",
      "accuracy=0.2376333326101303, counts=[[11202  7135  1538    73]\n",
      " [16900  3051    69     0]\n",
      " [19047   980     5     0]]\n",
      "Epoch=1, total_epoch_step_time=2.80, loss=434.51\n",
      "accuracy=0.232900008559227, counts=[[11585  7495   860     8]\n",
      " [17609  2386    25     0]\n",
      " [19429   600     3     0]]\n",
      "Epoch=2, total_epoch_step_time=4.24, loss=441.41\n",
      "accuracy=0.2284666746854782, counts=[[11878  7478   589     3]\n",
      " [18181  1828    11     0]\n",
      " [19611   419     2     0]]\n",
      "Epoch=3, total_epoch_step_time=5.78, loss=446.68\n",
      "accuracy=0.23206667602062225, counts=[[12700  6956   292     0]\n",
      " [18791  1224     5     0]\n",
      " [19797   235     0     0]]\n",
      "Epoch=4, total_epoch_step_time=7.31, loss=451.59\n",
      "accuracy=0.242533341050148, counts=[[13717  6028   203     0]\n",
      " [19180   834     6     0]\n",
      " [19857   174     1     0]]\n",
      "Epoch=5, total_epoch_step_time=8.84, loss=455.89\n",
      "accuracy=0.2560666799545288, counts=[[14799  4999   149     1]\n",
      " [19455   564     1     0]\n",
      " [19934    97     1     0]]\n",
      "Epoch=6, total_epoch_step_time=10.40, loss=458.26\n",
      "accuracy=0.2679833471775055, counts=[[15763  4117    68     0]\n",
      " [19703   316     1     0]\n",
      " [19948    84     0     0]]\n",
      "Epoch=7, total_epoch_step_time=11.84, loss=459.17\n",
      "accuracy=0.2758166790008545, counts=[[16266  3656    26     0]\n",
      " [19735   283     2     0]\n",
      " [19966    66     0     0]]\n",
      "Epoch=8, total_epoch_step_time=13.25, loss=459.50\n",
      "accuracy=0.2788333296775818, counts=[[16484  3434    30     0]\n",
      " [19774   246     0     0]\n",
      " [19972    60     0     0]]\n",
      "Epoch=9, total_epoch_step_time=14.71, loss=459.71\n",
      "accuracy=0.281333327293396, counts=[[16710  3202    36     0]\n",
      " [19850   170     0     0]\n",
      " [19985    47     0     0]]\n",
      "Epoch=10, total_epoch_step_time=16.24, loss=459.81\n",
      "accuracy=0.28343334794044495, counts=[[16851  3081    16     0]\n",
      " [19865   155     0     0]\n",
      " [19977    55     0     0]]\n",
      "Epoch=11, total_epoch_step_time=17.66, loss=459.85\n",
      "accuracy=0.29021668434143066, counts=[[17275  2646    27     0]\n",
      " [19882   138     0     0]\n",
      " [19962    70     0     0]]\n",
      "Epoch=12, total_epoch_step_time=19.19, loss=459.96\n",
      "accuracy=0.29216668009757996, counts=[[17425  2509    14     0]\n",
      " [19915   105     0     0]\n",
      " [19972    60     0     0]]\n",
      "Epoch=13, total_epoch_step_time=20.68, loss=460.01\n",
      "accuracy=0.29918333888053894, counts=[[17859  2080     9     0]\n",
      " [19928    92     0     0]\n",
      " [19972    60     0     0]]\n",
      "Epoch=14, total_epoch_step_time=22.17, loss=460.01\n",
      "accuracy=0.30346667766571045, counts=[[18121  1821     6     0]\n",
      " [19933    87     0     0]\n",
      " [19969    63     0     0]]\n",
      "Epoch=15, total_epoch_step_time=23.66, loss=460.08\n",
      "accuracy=0.30071666836738586, counts=[[17953  1992     3     0]\n",
      " [19930    90     0     0]\n",
      " [19971    61     0     0]]\n",
      "Epoch=16, total_epoch_step_time=25.16, loss=460.03\n",
      "accuracy=0.30098333954811096, counts=[[17972  1967     9     0]\n",
      " [19933    87     0     0]\n",
      " [19984    48     0     0]]\n",
      "Epoch=17, total_epoch_step_time=26.59, loss=460.10\n",
      "accuracy=0.29828333854675293, counts=[[17824  2112    12     0]\n",
      " [19947    73     0     0]\n",
      " [19962    70     0     0]]\n",
      "Epoch=18, total_epoch_step_time=27.99, loss=460.08\n",
      "accuracy=0.29571667313575745, counts=[[17681  2262     5     0]\n",
      " [19958    62     0     0]\n",
      " [19981    51     0     0]]\n",
      "Epoch=19, total_epoch_step_time=29.38, loss=460.12\n",
      "accuracy=0.29411667585372925, counts=[[17567  2380     1     0]\n",
      " [19940    80     0     0]\n",
      " [19976    56     0     0]]\n",
      "Epoch=20, total_epoch_step_time=30.79, loss=460.10\n",
      "accuracy=0.29893332719802856, counts=[[17880  2064     4     0]\n",
      " [19964    56     0     0]\n",
      " [19951    81     0     0]]\n",
      "Epoch=21, total_epoch_step_time=32.19, loss=460.11\n",
      "accuracy=0.3023333251476288, counts=[[18065  1880     3     0]\n",
      " [19945    75     0     0]\n",
      " [19965    67     0     0]]\n",
      "Epoch=22, total_epoch_step_time=33.60, loss=460.15\n",
      "accuracy=0.3063499927520752, counts=[[18296  1650     2     0]\n",
      " [19935    85     0     0]\n",
      " [19979    53     0     0]]\n",
      "Epoch=23, total_epoch_step_time=34.98, loss=460.12\n",
      "accuracy=0.30526667833328247, counts=[[18206  1738     4     0]\n",
      " [19905   110     3     2]\n",
      " [19962    70     0     0]]\n",
      "Epoch=24, total_epoch_step_time=36.38, loss=460.10\n",
      "accuracy=0.3037833273410797, counts=[[18129  1814     5     0]\n",
      " [19917    98     1     4]\n",
      " [19966    66     0     0]]\n",
      "Epoch=25, total_epoch_step_time=37.76, loss=460.13\n",
      "accuracy=0.30410000681877136, counts=[[18151  1797     0     0]\n",
      " [19924    95     1     0]\n",
      " [19965    67     0     0]]\n",
      "Epoch=26, total_epoch_step_time=39.15, loss=460.13\n",
      "accuracy=0.30053332448005676, counts=[[17933  2012     3     0]\n",
      " [19920    99     1     0]\n",
      " [19975    57     0     0]]\n",
      "Epoch=27, total_epoch_step_time=40.54, loss=460.14\n",
      "accuracy=0.30375000834465027, counts=[[18121  1821     6     0]\n",
      " [19916   103     1     0]\n",
      " [19978    53     1     0]]\n",
      "Epoch=28, total_epoch_step_time=41.93, loss=460.17\n",
      "accuracy=0.30024999380111694, counts=[[17921  2024     3     0]\n",
      " [19926    94     0     0]\n",
      " [19980    52     0     0]]\n",
      "Epoch=29, total_epoch_step_time=43.32, loss=460.15\n",
      "accuracy=0.30059999227523804, counts=[[17967  1978     3     0]\n",
      " [19951    69     0     0]\n",
      " [19982    50     0     0]]\n",
      "Epoch=30, total_epoch_step_time=44.73, loss=460.17\n",
      "accuracy=0.29249998927116394, counts=[[17453  2492     3     0]\n",
      " [19923    97     0     0]\n",
      " [19968    64     0     0]]\n",
      "Epoch=31, total_epoch_step_time=46.18, loss=460.15\n",
      "accuracy=0.2980666756629944, counts=[[17788  2154     6     0]\n",
      " [19924    96     0     0]\n",
      " [19966    66     0     0]]\n",
      "Epoch=32, total_epoch_step_time=47.80, loss=460.14\n",
      "accuracy=0.2986166775226593, counts=[[17843  2100     5     0]\n",
      " [19946    74     0     0]\n",
      " [19986    46     0     0]]\n",
      "Epoch=33, total_epoch_step_time=49.50, loss=460.18\n",
      "accuracy=0.30418333411216736, counts=[[18161  1783     4     0]\n",
      " [19929    90     1     0]\n",
      " [19966    66     0     0]]\n",
      "Epoch=34, total_epoch_step_time=50.99, loss=460.12\n",
      "accuracy=0.2997833490371704, counts=[[17896  2045     7     0]\n",
      " [19929    91     0     0]\n",
      " [19980    52     0     0]]\n",
      "Epoch=35, total_epoch_step_time=52.38, loss=460.15\n",
      "accuracy=0.2964833378791809, counts=[[17705  2242     1     0]\n",
      " [19935    84     1     0]\n",
      " [19973    59     0     0]]\n",
      "Epoch=36, total_epoch_step_time=53.76, loss=460.15\n",
      "accuracy=0.30141666531562805, counts=[[18021  1922     5     0]\n",
      " [19956    64     0     0]\n",
      " [19979    53     0     0]]\n",
      "Epoch=37, total_epoch_step_time=55.17, loss=460.15\n",
      "accuracy=0.2994000017642975, counts=[[17890  2053     5     0]\n",
      " [19946    74     0     0]\n",
      " [19966    66     0     0]]\n",
      "Epoch=38, total_epoch_step_time=56.61, loss=460.17\n",
      "accuracy=0.29864999651908875, counts=[[17860  2084     4     0]\n",
      " [19961    59     0     0]\n",
      " [19979    53     0     0]]\n",
      "Epoch=39, total_epoch_step_time=58.12, loss=460.19\n",
      "accuracy=0.301800012588501, counts=[[18045  1902     1     0]\n",
      " [19957    63     0     0]\n",
      " [19982    50     0     0]]\n",
      "Epoch=40, total_epoch_step_time=59.72, loss=460.21\n",
      "accuracy=0.3006833493709564, counts=[[17982  1963     3     0]\n",
      " [19962    58     0     0]\n",
      " [19961    70     1     0]]\n",
      "Epoch=0, total_epoch_step_time=1.61, loss=32.23\n",
      "accuracy=0.23613333702087402, counts=[[11221  7284  1386    57]\n",
      " [17025  2941    54     0]\n",
      " [19124   902     6     0]]\n",
      "Epoch=1, total_epoch_step_time=3.04, loss=434.52\n",
      "accuracy=0.22895000874996185, counts=[[11584  7599   752    13]\n",
      " [17847  2151    22     0]\n",
      " [19524   506     2     0]]\n",
      "Epoch=2, total_epoch_step_time=4.70, loss=441.37\n",
      "accuracy=0.2273000031709671, counts=[[11959  7499   487     3]\n",
      " [18331  1678    11     0]\n",
      " [19701   330     1     0]]\n",
      "Epoch=3, total_epoch_step_time=6.36, loss=446.19\n",
      "accuracy=0.23253333568572998, counts=[[12636  7032   280     0]\n",
      " [18701  1316     3     0]\n",
      " [19815   217     0     0]]\n",
      "Epoch=4, total_epoch_step_time=7.87, loss=450.92\n",
      "accuracy=0.2428833395242691, counts=[[13512  6230   204     2]\n",
      " [18959  1059     2     0]\n",
      " [19830   200     2     0]]\n",
      "Epoch=5, total_epoch_step_time=9.37, loss=455.43\n",
      "accuracy=0.25558334589004517, counts=[[14720  5061   163     4]\n",
      " [19402   615     3     0]\n",
      " [19923   109     0     0]]\n",
      "Epoch=6, total_epoch_step_time=10.88, loss=458.03\n",
      "accuracy=0.26524999737739563, counts=[[15364  4485    98     1]\n",
      " [19466   551     3     0]\n",
      " [19929   103     0     0]]\n",
      "Epoch=7, total_epoch_step_time=12.43, loss=459.07\n",
      "accuracy=0.27390000224113464, counts=[[15988  3912    48     0]\n",
      " [19574   445     1     0]\n",
      " [19943    88     1     0]]\n",
      "Epoch=8, total_epoch_step_time=14.05, loss=459.51\n",
      "accuracy=0.2718999981880188, counts=[[15846  4066    36     0]\n",
      " [19552   468     0     0]\n",
      " [19938    94     0     0]]\n",
      "Epoch=9, total_epoch_step_time=15.47, loss=459.72\n",
      "accuracy=0.2776666581630707, counts=[[16357  3549    42     0]\n",
      " [19716   303     1     0]\n",
      " [19976    56     0     0]]\n",
      "Epoch=10, total_epoch_step_time=16.99, loss=459.78\n",
      "accuracy=0.2809000015258789, counts=[[16605  3323    20     0]\n",
      " [19770   249     1     0]\n",
      " [19968    64     0     0]]\n",
      "Epoch=11, total_epoch_step_time=18.71, loss=459.85\n",
      "accuracy=0.28501665592193604, counts=[[16877  3039    32     0]\n",
      " [19796   224     0     0]\n",
      " [19949    83     0     0]]\n",
      "Epoch=12, total_epoch_step_time=20.18, loss=459.89\n",
      "accuracy=0.2884666621685028, counts=[[17125  2804    19     0]\n",
      " [19837   183     0     0]\n",
      " [19950    82     0     0]]\n",
      "Epoch=13, total_epoch_step_time=21.57, loss=459.91\n",
      "accuracy=0.279366672039032, counts=[[16544  3367    37     0]\n",
      " [19802   218     0     0]\n",
      " [19960    72     0     0]]\n",
      "Epoch=14, total_epoch_step_time=22.97, loss=459.96\n",
      "accuracy=0.2789166569709778, counts=[[16527  3277   143     1]\n",
      " [19812   208     0     0]\n",
      " [19969    63     0     0]]\n",
      "Epoch=15, total_epoch_step_time=24.51, loss=459.98\n",
      "accuracy=0.2787833511829376, counts=[[16423  3320   201     4]\n",
      " [19716   304     0     0]\n",
      " [19968    64     0     0]]\n",
      "Epoch=16, total_epoch_step_time=26.11, loss=459.97\n",
      "accuracy=0.2780333459377289, counts=[[16394  3342   209     3]\n",
      " [19730   288     2     0]\n",
      " [19965    67     0     0]]\n",
      "Epoch=17, total_epoch_step_time=27.66, loss=459.96\n",
      "accuracy=0.2763333320617676, counts=[[16233  3468   240     7]\n",
      " [19658   346     9     7]\n",
      " [19958    73     1     0]]\n",
      "Epoch=18, total_epoch_step_time=29.03, loss=460.04\n",
      "accuracy=0.2835833430290222, counts=[[16688  3078   180     2]\n",
      " [19666   325    24     5]\n",
      " [19947    83     2     0]]\n",
      "Epoch=19, total_epoch_step_time=30.42, loss=460.05\n",
      "accuracy=0.2878666818141937, counts=[[16960  2713   257    18]\n",
      " [19678   311    21    10]\n",
      " [19946    84     1     1]]\n",
      "Epoch=20, total_epoch_step_time=32.18, loss=460.02\n",
      "accuracy=0.28334999084472656, counts=[[16583  3036   309    20]\n",
      " [19497   413    69    41]\n",
      " [19927    99     5     1]]\n",
      "Epoch=21, total_epoch_step_time=34.07, loss=460.07\n",
      "accuracy=0.2875666618347168, counts=[[16897  2785   250    16]\n",
      " [19614   356    33    17]\n",
      " [19962    69     1     0]]\n",
      "Epoch=22, total_epoch_step_time=36.00, loss=460.10\n",
      "accuracy=0.2848833501338959, counts=[[16849  2867   222    10]\n",
      " [19734   242    31    13]\n",
      " [19945    85     2     0]]\n",
      "Epoch=23, total_epoch_step_time=38.03, loss=460.08\n",
      "accuracy=0.2846499979496002, counts=[[16913  2886   145     4]\n",
      " [19847   166     6     1]\n",
      " [19959    73     0     0]]\n",
      "Epoch=24, total_epoch_step_time=39.79, loss=460.10\n",
      "accuracy=0.2875666618347168, counts=[[17112  2641   188     7]\n",
      " [19872   141     6     1]\n",
      " [19964    67     1     0]]\n",
      "Epoch=25, total_epoch_step_time=41.52, loss=460.13\n",
      "accuracy=0.29126667976379395, counts=[[17337  2496   113     2]\n",
      " [19875   139     6     0]\n",
      " [19978    54     0     0]]\n",
      "Epoch=26, total_epoch_step_time=43.14, loss=460.10\n",
      "accuracy=0.28450000286102295, counts=[[16948  2754   232    14]\n",
      " [19897   122     1     0]\n",
      " [19977    55     0     0]]\n",
      "Epoch=27, total_epoch_step_time=44.78, loss=460.11\n",
      "accuracy=0.27744999527931213, counts=[[16523  2913   463    49]\n",
      " [19893   124     3     0]\n",
      " [19972    60     0     0]]\n",
      "Epoch=28, total_epoch_step_time=46.41, loss=460.05\n",
      "accuracy=0.2814166843891144, counts=[[16735  2721   429    63]\n",
      " [19851   150    13     6]\n",
      " [19969    62     0     1]]\n",
      "Epoch=29, total_epoch_step_time=48.23, loss=460.09\n",
      "accuracy=0.28451666235923767, counts=[[16940  2787   208    13]\n",
      " [19882   131     5     2]\n",
      " [19968    64     0     0]]\n",
      "Epoch=30, total_epoch_step_time=49.76, loss=460.13\n",
      "accuracy=0.2917666733264923, counts=[[17378  2446   120     4]\n",
      " [19883   128     8     1]\n",
      " [19949    83     0     0]]\n",
      "Epoch=31, total_epoch_step_time=51.39, loss=460.14\n",
      "accuracy=0.29321667551994324, counts=[[17449  2410    85     4]\n",
      " [19869   144     6     1]\n",
      " [19964    68     0     0]]\n",
      "Epoch=32, total_epoch_step_time=52.99, loss=460.13\n",
      "accuracy=0.2951500117778778, counts=[[17556  2346    46     0]\n",
      " [19857   153     8     2]\n",
      " [19961    71     0     0]]\n",
      "Epoch=33, total_epoch_step_time=54.67, loss=460.20\n",
      "accuracy=0.29440000653266907, counts=[[17491  2397    60     0]\n",
      " [19834   172    10     4]\n",
      " [19973    58     1     0]]\n",
      "Epoch=34, total_epoch_step_time=56.31, loss=460.15\n",
      "accuracy=0.2954833507537842, counts=[[17536  2357    55     0]\n",
      " [19816   193    11     0]\n",
      " [19961    71     0     0]]\n",
      "Epoch=35, total_epoch_step_time=57.86, loss=460.14\n",
      "accuracy=0.2931666672229767, counts=[[17411  2464    73     0]\n",
      " [19834   179     7     0]\n",
      " [19975    57     0     0]]\n",
      "Epoch=36, total_epoch_step_time=59.42, loss=460.19\n",
      "accuracy=0.29535001516342163, counts=[[17603  2283    62     0]\n",
      " [19900   118     2     0]\n",
      " [19970    62     0     0]]\n",
      "Epoch=37, total_epoch_step_time=60.89, loss=460.20\n",
      "accuracy=0.29303333163261414, counts=[[17484  2383    80     1]\n",
      " [19922    98     0     0]\n",
      " [19964    68     0     0]]\n",
      "Epoch=38, total_epoch_step_time=62.29, loss=460.14\n",
      "accuracy=0.2936333417892456, counts=[[17531  2208   197    12]\n",
      " [19932    87     1     0]\n",
      " [19967    65     0     0]]\n",
      "Epoch=39, total_epoch_step_time=63.74, loss=460.13\n",
      "accuracy=0.29124999046325684, counts=[[17396  2415   131     6]\n",
      " [19940    79     1     0]\n",
      " [19968    64     0     0]]\n",
      "Epoch=40, total_epoch_step_time=65.31, loss=460.18\n",
      "accuracy=0.2980666756629944, counts=[[17829  2015   103     1]\n",
      " [19965    55     0     0]\n",
      " [19972    60     0     0]]\n",
      "Epoch=0, total_epoch_step_time=1.39, loss=24.94\n",
      "accuracy=0.23991666734218597, counts=[[11342  7079  1468    59]\n",
      " [16904  3048    68     0]\n",
      " [19080   947     5     0]]\n",
      "Epoch=1, total_epoch_step_time=2.78, loss=434.66\n",
      "accuracy=0.23163333535194397, counts=[[11538  7546   852    12]\n",
      " [17641  2359    20     0]\n",
      " [19466   565     1     0]]\n",
      "Epoch=2, total_epoch_step_time=4.15, loss=441.74\n",
      "accuracy=0.23098333179950714, counts=[[12017  7332   597     2]\n",
      " [18163  1842    15     0]\n",
      " [19657   375     0     0]]\n",
      "Epoch=3, total_epoch_step_time=5.55, loss=446.49\n",
      "accuracy=0.22965000569820404, counts=[[12426  7131   388     3]\n",
      " [18659  1353     8     0]\n",
      " [19786   246     0     0]]\n",
      "Epoch=4, total_epoch_step_time=6.94, loss=450.77\n",
      "accuracy=0.24093332886695862, counts=[[13409  6272   264     3]\n",
      " [18970  1046     4     0]\n",
      " [19837   194     1     0]]\n",
      "Epoch=5, total_epoch_step_time=8.32, loss=455.23\n",
      "accuracy=0.2559833228588104, counts=[[14576  5271   100     1]\n",
      " [19232   783     5     0]\n",
      " [19897   135     0     0]]\n",
      "Epoch=6, total_epoch_step_time=9.74, loss=457.85\n",
      "accuracy=0.2655166685581207, counts=[[15131  4727    90     0]\n",
      " [19220   800     0     0]\n",
      " [19890   142     0     0]]\n",
      "Epoch=7, total_epoch_step_time=11.24, loss=459.14\n",
      "accuracy=0.2751833498477936, counts=[[15761  4137    50     0]\n",
      " [19267   750     3     0]\n",
      " [19876   156     0     0]]\n",
      "Epoch=8, total_epoch_step_time=12.71, loss=459.55\n",
      "accuracy=0.282150000333786, counts=[[16035  3870    43     0]\n",
      " [19118   894     8     0]\n",
      " [19816   216     0     0]]\n",
      "Epoch=9, total_epoch_step_time=14.17, loss=459.71\n",
      "accuracy=0.2855166792869568, counts=[[15980  3872    96     0]\n",
      " [18859  1149    12     0]\n",
      " [19722   308     2     0]]\n",
      "Epoch=10, total_epoch_step_time=15.75, loss=459.88\n",
      "accuracy=0.29028332233428955, counts=[[16240  3680    28     0]\n",
      " [18839  1176     5     0]\n",
      " [19626   405     1     0]]\n",
      "Epoch=11, total_epoch_step_time=17.18, loss=460.22\n",
      "accuracy=0.3002166748046875, counts=[[16299  3621    28     0]\n",
      " [18290  1709    21     0]\n",
      " [19136   891     5     0]]\n",
      "Epoch=12, total_epoch_step_time=18.61, loss=461.39\n",
      "accuracy=0.3333166837692261, counts=[[15941  3876   131     0]\n",
      " [15442  3335   643   600]\n",
      " [15293  3286   723   730]]\n",
      "Epoch=13, total_epoch_step_time=20.04, loss=475.30\n",
      "accuracy=0.31825000047683716, counts=[[15585  4181   181     1]\n",
      " [ 8122  2870   879  8149]\n",
      " [ 4231  1620   640 13541]]\n",
      "Epoch=14, total_epoch_step_time=21.51, loss=496.69\n",
      "accuracy=0.2854500114917755, counts=[[15455  4261   232     0]\n",
      " [ 4634  1554   468 13364]\n",
      " [ 1216   323   118 18375]]\n",
      "Epoch=15, total_epoch_step_time=22.98, loss=513.49\n",
      "accuracy=0.27683332562446594, counts=[[15480  4299   167     2]\n",
      " [ 3133  1082   345 15460]\n",
      " [  471   112    48 19401]]\n",
      "Epoch=16, total_epoch_step_time=24.42, loss=528.81\n",
      "accuracy=0.2729499936103821, counts=[[15888  3962    98     0]\n",
      " [ 2448   483   103 16986]\n",
      " [  229    22     6 19775]]\n",
      "Epoch=17, total_epoch_step_time=25.88, loss=542.19\n",
      "accuracy=0.27619999647140503, counts=[[16010  3872    66     0]\n",
      " [ 1799   554   177 17490]\n",
      " [  115    24     8 19885]]\n",
      "Epoch=18, total_epoch_step_time=27.35, loss=552.32\n",
      "accuracy=0.2661166787147522, counts=[[15766  4062   119     1]\n",
      " [ 1143   197    63 18617]\n",
      " [   50     1     4 19977]]\n",
      "Epoch=19, total_epoch_step_time=28.79, loss=560.25\n",
      "accuracy=0.2685833275318146, counts=[[15945  3918    85     0]\n",
      " [  881   170    24 18945]\n",
      " [   21     2     0 20009]]\n",
      "Epoch=20, total_epoch_step_time=30.25, loss=566.92\n",
      "accuracy=0.2712666690349579, counts=[[16192  3660    96     0]\n",
      " [  725    83    20 19192]\n",
      " [   16     0     1 20015]]\n",
      "Epoch=21, total_epoch_step_time=31.70, loss=572.62\n",
      "accuracy=0.26766666769981384, counts=[[16010  3796   141     1]\n",
      " [  588    50     9 19373]\n",
      " [   13     0     0 20019]]\n",
      "Epoch=22, total_epoch_step_time=33.13, loss=577.58\n",
      "accuracy=0.2704166769981384, counts=[[16195  3620   129     4]\n",
      " [  458    30     3 19529]\n",
      " [    2     0     0 20030]]\n",
      "Epoch=23, total_epoch_step_time=34.60, loss=581.91\n",
      "accuracy=0.27703332901000977, counts=[[16592  3299    57     0]\n",
      " [  270    30     4 19716]\n",
      " [    7     0     0 20025]]\n",
      "Epoch=24, total_epoch_step_time=36.08, loss=585.64\n",
      "accuracy=0.27834999561309814, counts=[[16682  3195    71     0]\n",
      " [  288    19     2 19711]\n",
      " [    1     0     0 20031]]\n",
      "Epoch=25, total_epoch_step_time=37.53, loss=588.94\n",
      "accuracy=0.27459999918937683, counts=[[16466  3362   120     0]\n",
      " [  237    10     0 19773]\n",
      " [    2     0     0 20030]]\n",
      "Epoch=26, total_epoch_step_time=38.98, loss=591.53\n",
      "accuracy=0.28368332982063293, counts=[[17009  2879    60     0]\n",
      " [  252    12     0 19756]\n",
      " [    2     1     0 20029]]\n",
      "Epoch=27, total_epoch_step_time=40.40, loss=593.92\n",
      "accuracy=0.29083332419395447, counts=[[17437  2474    37     0]\n",
      " [  218    13     0 19789]\n",
      " [    0     0     0 20032]]\n",
      "Epoch=28, total_epoch_step_time=41.91, loss=595.90\n",
      "accuracy=0.29580000042915344, counts=[[17739  2044   131    34]\n",
      " [  208     9     2 19801]\n",
      " [    2     0     0 20030]]\n",
      "Invalid nan value encountered in the output of a C++-jit/pmap function. Calling the de-optimized version.\n",
      "Invalid nan value encountered in the output of a C++-jit/pmap function. Calling the de-optimized version.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">110</span> in           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_nan_check_posthook</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dispatch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">403</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">check_special</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dispatch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">408</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_check_special</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FloatingPointError: </span>invalid value <span style=\"font-weight: bold\">(</span>nan<span style=\"font-weight: bold\">)</span> encountered in pjit\n",
       "\n",
       "<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">110</span> in           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_nan_check_posthook</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dispatch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">403</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">check_special</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dispatch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">408</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_check_special</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FloatingPointError: </span>invalid value <span style=\"font-weight: bold\">(</span>nan<span style=\"font-weight: bold\">)</span> encountered in pjit\n",
       "\n",
       "<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pjit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1152</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_pjit_call_impl_python</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">profiler.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">340</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/interpreters/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pxla.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">56</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dispatch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">403</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">check_special</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dispatch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">408</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_check_special</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FloatingPointError: </span>invalid value <span style=\"font-weight: bold\">(</span>nan<span style=\"font-weight: bold\">)</span> encountered in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">jit</span><span style=\"font-weight: bold\">(</span>epoch_train<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>losses, accuracy, wall_clock_times = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> train_idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>):                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>key, sub_key = jax.random.split(key)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 7 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>r_loss, r_acc, r_times, params = train(                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>sub_key, learning_rate=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0e-4</span>, n=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, batch_size=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">64</span>, num_epochs=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">40</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>)                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Save run.</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">71</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">68 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>num_batch, train_idx = train_init(sub_key)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">69 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>key, sub_key = jax.random.split(key)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">70 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>start = time.perf_counter() - t0                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>71 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>params, opt_state, loss = epoch_train(opt_state, params, sub_key, train_idx)        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">72 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>stop = time.perf_counter() - t0                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">73 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>acc_time += stop - start                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">74 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>wall_clock_times.append(acc_time)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">116</span> in           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_nan_check_posthook</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">traceback_util.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">177</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reraise_with_filtered_traceback</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pjit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">256</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cache_miss</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pjit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">167</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_python_pjit_helper</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2656</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bind</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">388</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bind_with_trace</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">868</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">process_primitive</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pjit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1212</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_pjit_call_impl</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">116</span> in           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_nan_check_posthook</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pjit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1196</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">call_impl_cache_miss</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pjit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1176</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_pjit_call_impl_python</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FloatingPointError: </span>An invalid value was encountered in the output of the `jit`-decorated function epoch_train. \n",
       "Because jax_config.debug_nans.value and/or config.jax_debug_infs is set, the de-optimized function <span style=\"font-weight: bold\">(</span>i.e., the \n",
       "function as if the `jit` decorator were removed<span style=\"font-weight: bold\">)</span> was called in an attempt to get a more precise error message. \n",
       "However, the de-optimized function did not produce invalid values during its execution. This behavior can result \n",
       "from `jit` optimizations causing the invalid value to be produced. It may also arise from having nan/inf constants \n",
       "as outputs, like `<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">jax.jit</span><span style=\"font-weight: bold\">(</span>lambda <span style=\"color: #808000; text-decoration-color: #808000\">...</span>: jax.numpy.nan<span style=\"font-weight: bold\">)(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>`. \n",
       "\n",
       "It may be possible to avoid the invalid value by removing the `jit` decorator, at the cost of losing optimizations.\n",
       "\n",
       "If you see this error, consider opening a bug report at <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/google/jax.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m110\u001b[0m in           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_nan_check_posthook\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mdispatch.py\u001b[0m:\u001b[94m403\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mcheck_special\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mdispatch.py\u001b[0m:\u001b[94m408\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_check_special\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFloatingPointError: \u001b[0minvalid value \u001b[1m(\u001b[0mnan\u001b[1m)\u001b[0m encountered in pjit\n",
       "\n",
       "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m110\u001b[0m in           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_nan_check_posthook\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mdispatch.py\u001b[0m:\u001b[94m403\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mcheck_special\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mdispatch.py\u001b[0m:\u001b[94m408\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_check_special\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFloatingPointError: \u001b[0minvalid value \u001b[1m(\u001b[0mnan\u001b[1m)\u001b[0m encountered in pjit\n",
       "\n",
       "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mpjit.py\u001b[0m:\u001b[94m1152\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_pjit_call_impl_python\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mprofiler.py\u001b[0m:\u001b[94m340\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mwrapper\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/interpreters/\u001b[0m\u001b[1;33mpxla.py\u001b[0m:\u001b[94m11\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m56\u001b[0m in \u001b[92m__call__\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mdispatch.py\u001b[0m:\u001b[94m403\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mcheck_special\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mdispatch.py\u001b[0m:\u001b[94m408\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_check_special\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFloatingPointError: \u001b[0minvalid value \u001b[1m(\u001b[0mnan\u001b[1m)\u001b[0m encountered in \u001b[1;35mjit\u001b[0m\u001b[1m(\u001b[0mepoch_train\u001b[1m)\u001b[0m\n",
       "\n",
       "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0mlosses, accuracy, wall_clock_times = \u001b[94mNone\u001b[0m, \u001b[94mNone\u001b[0m, \u001b[94mNone\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[94mfor\u001b[0m train_idx \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[94m0\u001b[0m, \u001b[94m5\u001b[0m):                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   \u001b[0mkey, sub_key = jax.random.split(key)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 7 \u001b[2m│   \u001b[0mr_loss, r_acc, r_times, params = train(                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   │   \u001b[0msub_key, learning_rate=\u001b[94m1.0e-4\u001b[0m, n=\u001b[94m1\u001b[0m, batch_size=\u001b[94m64\u001b[0m, num_epochs=\u001b[94m40\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Save run.\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtrain\u001b[0m:\u001b[94m71\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m68 \u001b[0m\u001b[2m│   │   \u001b[0mnum_batch, train_idx = train_init(sub_key)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m69 \u001b[0m\u001b[2m│   │   \u001b[0mkey, sub_key = jax.random.split(key)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m70 \u001b[0m\u001b[2m│   │   \u001b[0mstart = time.perf_counter() - t0                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m71 \u001b[2m│   │   \u001b[0mparams, opt_state, loss = epoch_train(opt_state, params, sub_key, train_idx)        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m72 \u001b[0m\u001b[2m│   │   \u001b[0mstop = time.perf_counter() - t0                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m73 \u001b[0m\u001b[2m│   │   \u001b[0macc_time += stop - start                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m74 \u001b[0m\u001b[2m│   │   \u001b[0mwall_clock_times.append(acc_time)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m116\u001b[0m in           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_nan_check_posthook\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mtraceback_util.py\u001b[0m:\u001b[94m177\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mreraise_with_filtered_traceback\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mpjit.py\u001b[0m:\u001b[94m256\u001b[0m in          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mcache_miss\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mpjit.py\u001b[0m:\u001b[94m167\u001b[0m in          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_python_pjit_helper\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m2656\u001b[0m in \u001b[92mbind\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m388\u001b[0m in          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mbind_with_trace\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m868\u001b[0m in          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mprocess_primitive\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mpjit.py\u001b[0m:\u001b[94m1212\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_pjit_call_impl\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m116\u001b[0m in           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_nan_check_posthook\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mpjit.py\u001b[0m:\u001b[94m1196\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mcall_impl_cache_miss\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mpjit.py\u001b[0m:\u001b[94m1176\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_pjit_call_impl_python\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFloatingPointError: \u001b[0mAn invalid value was encountered in the output of the `jit`-decorated function epoch_train. \n",
       "Because jax_config.debug_nans.value and/or config.jax_debug_infs is set, the de-optimized function \u001b[1m(\u001b[0mi.e., the \n",
       "function as if the `jit` decorator were removed\u001b[1m)\u001b[0m was called in an attempt to get a more precise error message. \n",
       "However, the de-optimized function did not produce invalid values during its execution. This behavior can result \n",
       "from `jit` optimizations causing the invalid value to be produced. It may also arise from having nan/inf constants \n",
       "as outputs, like `\u001b[1;35mjax.jit\u001b[0m\u001b[1m(\u001b[0mlambda \u001b[33m...\u001b[0m: jax.numpy.nan\u001b[1m)\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m`. \n",
       "\n",
       "It may be possible to avoid the invalid value by removing the `jit` decorator, at the cost of losing optimizations.\n",
       "\n",
       "If you see this error, consider opening a bug report at \u001b[4;94mhttps://github.com/google/jax.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Run with different random seeds.\n",
    "losses, accuracy, wall_clock_times = None, None, None\n",
    "for train_idx in range(0, 5):\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    r_loss, r_acc, r_times, params = train(\n",
    "        sub_key, learning_rate=1.0e-4, n=1, batch_size=64, num_epochs=40\n",
    "    )\n",
    "    # Save run.\n",
    "    arr = np.array([r_loss, r_acc, r_times])\n",
    "    df = pd.DataFrame(\n",
    "        arr.T, columns=[\"ELBO loss\", \"Accuracy\", \"Epoch wall clock times\"]\n",
    "    )\n",
    "    df.to_csv(\n",
    "        f\"./training_runs/grasp_air_reinforce_epochs_41_mccoy_prior_{train_idx}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    if losses is None:\n",
    "        losses = r_loss\n",
    "        accuracy = r_acc\n",
    "        wall_clock_times = r_times\n",
    "\n",
    "    else:\n",
    "        losses = np.vstack((losses, r_loss))\n",
    "        accuracy = np.vstack((accuracy, r_acc))\n",
    "        wall_clock_times = np.vstack((wall_clock_times, r_times))\n",
    "\n",
    "arr = np.array([losses, accuracy, wall_clock_times])\n",
    "mean_arr = jnp.mean(arr, axis=1)\n",
    "std_arr = jnp.std(arr, axis=1)\n",
    "df_arr = jnp.vstack((mean_arr, std_arr))\n",
    "df = pd.DataFrame(\n",
    "    df_arr.T,\n",
    "    columns=[\n",
    "        \"Mean ELBO loss\",\n",
    "        \"Mean accuracy\",\n",
    "        \"Mean epoch wall clock times\",\n",
    "        \"Std ELBO loss\",\n",
    "        \"Std accuracy\",\n",
    "        \"Std epoch wall clock times\",\n",
    "    ],\n",
    ")\n",
    "df.to_csv(\"./training_runs/grasp_air_reinforce_epochs_41_mccoy_prior.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b57d1b-155d-4a25-a8f1-b1c37375f95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run with different random seeds.\n",
    "losses, accuracy, wall_clock_times = None, None, None\n",
    "for train_idx in range(0, 5):\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    r_loss, r_acc, r_times, params = train(\n",
    "        sub_key, learning_rate=1.0e-4, n=2, batch_size=64, num_epochs=40\n",
    "    )\n",
    "    # Save run.\n",
    "    arr = np.array([r_loss, r_acc, r_times])\n",
    "    df = pd.DataFrame(\n",
    "        arr.T, columns=[\"ELBO loss\", \"Accuracy\", \"Epoch wall clock times\"]\n",
    "    )\n",
    "    df.to_csv(\n",
    "        f\"./training_runs/grasp_air_iwae_2_reinforce_epochs_41_mccoy_prior_{train_idx}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    if losses is None:\n",
    "        losses = r_loss\n",
    "        accuracy = r_acc\n",
    "        wall_clock_times = r_times\n",
    "\n",
    "    else:\n",
    "        losses = np.vstack((losses, r_loss))\n",
    "        accuracy = np.vstack((accuracy, r_acc))\n",
    "        wall_clock_times = np.vstack((wall_clock_times, r_times))\n",
    "\n",
    "arr = np.array([losses, accuracy, wall_clock_times])\n",
    "mean_arr = jnp.mean(arr, axis=1)\n",
    "std_arr = jnp.std(arr, axis=1)\n",
    "df_arr = jnp.vstack((mean_arr, std_arr))\n",
    "df = pd.DataFrame(\n",
    "    df_arr.T,\n",
    "    columns=[\n",
    "        \"Mean ELBO loss\",\n",
    "        \"Mean accuracy\",\n",
    "        \"Mean epoch wall clock times\",\n",
    "        \"Std ELBO loss\",\n",
    "        \"Std accuracy\",\n",
    "        \"Std epoch wall clock times\",\n",
    "    ],\n",
    ")\n",
    "df.to_csv(\n",
    "    \"./training_runs/grasp_air_iwae_2_reinforce_epochs_41_mccoy_prior.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
