{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de0133f-4e97-401c-b216-e0bc64664444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from collections import namedtuple\n",
    "import pyro\n",
    "import optax\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "import pyro.contrib.examples.multi_mnist as multi_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from matplotlib import rcParams\n",
    "from scipy.interpolate import griddata\n",
    "import genjax\n",
    "from genjax import grasp\n",
    "\n",
    "key = jax.random.PRNGKey(314159)\n",
    "console = genjax.pretty()\n",
    "sns.set_theme(style=\"white\")\n",
    "font_path = (\n",
    "    \"/home/femtomc/.local/share/fonts/Unknown Vendor/TrueType/Lato/Lato_Bold.ttf\"\n",
    ")\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "custom_font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rcParams[\"font.family\"] = custom_font_name\n",
    "\n",
    "console = genjax.pretty()\n",
    "label_fontsize = 70  # Set the desired font size here\n",
    "\n",
    "smoke_test = \"CI\" in os.environ\n",
    "assert pyro.__version__.startswith(\"1.8.6\")\n",
    "\n",
    "from jax import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4985e835-14c9-43f0-8652-34da112dd6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size 80\u001b[0m\u001b[1;36m0x200\u001b[0m\u001b[39m with \u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inpath = \"./data/air/.data\"\n",
    "X_np, Y = multi_mnist.load(inpath)\n",
    "X_np = X_np.astype(np.float32)\n",
    "X_np /= 255.0\n",
    "mnist = jnp.array(X_np)\n",
    "true_counts = jnp.array([len(objs) for objs in Y])\n",
    "\n",
    "\n",
    "def show_images(imgs):\n",
    "    fig = plt.figure(figsize=(8, 2))\n",
    "    for i, img in enumerate(imgs):\n",
    "        ax = plt.subplot(1, len(imgs), i + 1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.imshow(img, cmap=\"gray_r\")\n",
    "\n",
    "\n",
    "show_images(mnist[9:14])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65227bc6-fd5e-486d-9cdc-0bfdf6cbde95",
   "metadata": {},
   "source": [
    "## Defining the variational ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78d35c-3e79-4ea7-95d9-82106cb22ad7",
   "metadata": {},
   "source": [
    "### Utilities / learnable pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38987718-1631-423e-8b70-95a469742beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from genjax import Pytree\n",
    "import equinox as eqx\n",
    "from genjax.typing import Any\n",
    "from genjax.typing import Tuple\n",
    "from genjax.typing import FloatArray\n",
    "from genjax.typing import Int\n",
    "from genjax.typing import IntArray\n",
    "from genjax.typing import PRNGKey\n",
    "from genjax.typing import typecheck\n",
    "\n",
    "# Utilities for defining the model and the guide.\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Decoder(Pytree):\n",
    "    dense_1: Any\n",
    "    dense_2: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense_1, self.dense_2), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key1, key2):\n",
    "        dense_1 = eqx.nn.Linear(50, 200, key=key1)\n",
    "        dense_2 = eqx.nn.Linear(200, 400, key=key2)\n",
    "        return Decoder(dense_1, dense_2)\n",
    "\n",
    "    def __call__(self, z_what):\n",
    "        v = self.dense_1(z_what)\n",
    "        v = jax.nn.leaky_relu(v)\n",
    "        v = self.dense_2(v)\n",
    "        return jax.nn.sigmoid(v)\n",
    "\n",
    "\n",
    "# Create our decoder.\n",
    "key, sub_key1, sub_key2 = jax.random.split(key, 3)\n",
    "decoder = Decoder.new(sub_key1, sub_key2)\n",
    "\n",
    "# Create our RNN for the guide.\n",
    "key, sub_key = jax.random.split(key)\n",
    "rnn = eqx.nn.LSTMCell(2554, 256, key=sub_key)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Encoder(Pytree):\n",
    "    dense_1: Any\n",
    "    dense_2: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense_1, self.dense_2), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key1, key2):\n",
    "        dense_1 = eqx.nn.Linear(400, 200, key=key1)\n",
    "        dense_2 = eqx.nn.Linear(200, 100, key=key2)\n",
    "        return Encoder(dense_1, dense_2)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        v = self.dense_1(data)\n",
    "        v = jax.nn.leaky_relu(v)\n",
    "        v = self.dense_2(v)\n",
    "        return v[0:50], jax.nn.softplus(v[50:])\n",
    "\n",
    "\n",
    "key, sub_key1, sub_key2 = jax.random.split(key, 3)\n",
    "encoder = Encoder.new(sub_key1, sub_key2)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Predict(Pytree):\n",
    "    dense: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense,), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key):\n",
    "        dense = eqx.nn.Linear(256, 7, key=key)\n",
    "        return Predict(dense)\n",
    "\n",
    "    def __call__(self, h):\n",
    "        a = self.dense(h)\n",
    "        z_pres_p = jax.nn.sigmoid(a[0:1])\n",
    "        z_where_loc = a[1:4]\n",
    "        z_where_scale = jax.nn.softplus(a[4:])\n",
    "        return z_pres_p, z_where_loc, z_where_scale\n",
    "\n",
    "\n",
    "key, sub_key = jax.random.split(key)\n",
    "predict = Predict.new(sub_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82446361-62cd-4cec-a8aa-d76b477603d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######\n",
    "# STN #\n",
    "#######\n",
    "\n",
    "# modified from https://github.com/kevinzakka/spatial-transformer-network/blob/master/stn/transformer.py\n",
    "\n",
    "\n",
    "def affine_grid_generator(height, width, theta):\n",
    "    \"\"\"\n",
    "    This function returns a sampling grid, which when\n",
    "    used with the bilinear sampler on the input feature\n",
    "    map, will create an output feature map that is an\n",
    "    affine transformation [1] of the input feature map.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - height: desired height of grid/output. Used\n",
    "      to downsample or upsample.\n",
    "\n",
    "    - width: desired width of grid/output. Used\n",
    "      to downsample or upsample.\n",
    "\n",
    "    - theta: affine transform matrices of shape (num_batch, 2, 3).\n",
    "      For each image in the batch, we have 6 theta parameters of\n",
    "      the form (2x3) that define the affine transformation T.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - normalized grid (-1, 1) of shape (num_batch, 2, H, W).\n",
    "      The 2nd dimension has 2 components: (x, y) which are the\n",
    "      sampling points of the original image for each point in the\n",
    "      target image.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    [1]: the affine transformation allows cropping, translation,\n",
    "         and isotropic scaling.\n",
    "    \"\"\"\n",
    "    num_batch = theta.shape[0]\n",
    "\n",
    "    # create normalized 2D grid\n",
    "    x = jnp.linspace(-1.0, 1.0, width)\n",
    "    y = jnp.linspace(-1.0, 1.0, height)\n",
    "    x_t, y_t = jnp.meshgrid(x, y)\n",
    "\n",
    "    # flatten\n",
    "    x_t_flat = jnp.reshape(x_t, [-1])\n",
    "    y_t_flat = jnp.reshape(y_t, [-1])\n",
    "\n",
    "    # reshape to [x_t, y_t , 1] - (homogeneous form)\n",
    "    ones = jnp.ones_like(x_t_flat)\n",
    "    sampling_grid = jnp.stack([x_t_flat, y_t_flat, ones])\n",
    "\n",
    "    # repeat grid num_batch times\n",
    "    sampling_grid = jnp.expand_dims(sampling_grid, axis=0)\n",
    "    sampling_grid = jnp.tile(sampling_grid, [num_batch, 1, 1])\n",
    "\n",
    "    # transform the sampling grid - batch multiply\n",
    "    batch_grids = jnp.matmul(theta, sampling_grid)\n",
    "    # batch grid has shape (num_batch, 2, H*W)\n",
    "\n",
    "    # reshape to (num_batch, 2, H, W)\n",
    "    batch_grids = jnp.reshape(batch_grids, [num_batch, 2, height, width])\n",
    "\n",
    "    return batch_grids\n",
    "\n",
    "\n",
    "def bilinear_sampler(img, x, y):\n",
    "    \"\"\"\n",
    "    Performs bilinear sampling of the input images according to the\n",
    "    normalized coordinates provided by the sampling grid. Note that\n",
    "    the sampling is done identically for each channel of the input.\n",
    "\n",
    "    To test if the function works properly, output image should be\n",
    "    identical to input image when theta is initialized to identity\n",
    "    transform.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - img: batch of images in (B, H, W, C) layout.\n",
    "    - grid: x, y which is the output of affine_grid_generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - out: interpolated images according to grids. Same size as grid.\n",
    "    \"\"\"\n",
    "    H = jnp.shape(img)[1]\n",
    "    W = jnp.shape(img)[2]\n",
    "    max_y = H - 1\n",
    "    max_x = W - 1\n",
    "    zero = jnp.zeros([], dtype=int)\n",
    "\n",
    "    # rescale x and y to [0, W-1/H-1]\n",
    "    x = 0.5 * ((x + 1.0) * max_x - 1)\n",
    "    y = 0.5 * ((y + 1.0) * max_y - 1)\n",
    "\n",
    "    # grab 4 nearest corner points for each (x_i, y_i)\n",
    "    x0 = jnp.floor(x).astype(int)\n",
    "    x1 = x0 + 1\n",
    "    y0 = jnp.floor(y).astype(int)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    # clip to range [0, H-1/W-1] to not violate img boundaries\n",
    "    x0 = jnp.clip(x0, zero, max_x)\n",
    "    x1 = jnp.clip(x1, zero, max_x)\n",
    "    y0 = jnp.clip(y0, zero, max_y)\n",
    "    y1 = jnp.clip(y1, zero, max_y)\n",
    "\n",
    "    # get pixel value at corner coords\n",
    "    Ia = get_pixel_value(img, x0, y0)\n",
    "    Ib = get_pixel_value(img, x0, y1)\n",
    "    Ic = get_pixel_value(img, x1, y0)\n",
    "    Id = get_pixel_value(img, x1, y1)\n",
    "\n",
    "    # recast as float for delta calculation\n",
    "    x0 = x0.astype(float)\n",
    "    x1 = x1.astype(float)\n",
    "    y0 = y0.astype(float)\n",
    "    y1 = y1.astype(float)\n",
    "\n",
    "    # calculate deltas\n",
    "    wa = (x1 - x) * (y1 - y)\n",
    "    wb = (x1 - x) * (y - y0)\n",
    "    wc = (x - x0) * (y1 - y)\n",
    "    wd = (x - x0) * (y - y0)\n",
    "\n",
    "    # add dimension for addition\n",
    "    wa = jnp.expand_dims(wa, axis=3)\n",
    "    wb = jnp.expand_dims(wb, axis=3)\n",
    "    wc = jnp.expand_dims(wc, axis=3)\n",
    "    wd = jnp.expand_dims(wd, axis=3)\n",
    "\n",
    "    # compute output\n",
    "    out = wa * Ia + wb * Ib + wc * Ic + wd * Id\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_pixel_value(img, x, y):\n",
    "    \"\"\"\n",
    "    Utility function to get pixel value for coordinate\n",
    "    vectors x and y from a  4D tensor image.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - img: tensor of shape (B, H, W, C)\n",
    "    - x: flattened tensor of shape (B*H*W,)\n",
    "    - y: flattened tensor of shape (B*H*W,)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - output: tensor of shape (B, H, W, C)\n",
    "    \"\"\"\n",
    "    batch_size, height, width = jnp.shape(x)\n",
    "\n",
    "    batch_idx = jnp.arange(0, batch_size)\n",
    "    batch_idx = jnp.reshape(batch_idx, (batch_size, 1, 1))\n",
    "    b = jnp.tile(batch_idx, (1, height, width))\n",
    "\n",
    "    indices = jnp.stack([b, y, x], 3)\n",
    "\n",
    "    return gather_nd(img, indices)\n",
    "\n",
    "\n",
    "# from: https://github.com/google/jax/discussions/6119\n",
    "def gather_nd_unbatched(params, indices):\n",
    "    return params[tuple(jnp.moveaxis(indices, -1, 0))]\n",
    "\n",
    "\n",
    "def gather_nd(params, indices, batch=False):\n",
    "    if not batch:\n",
    "        return gather_nd_unbatched(params, indices)\n",
    "    else:\n",
    "        return vmap(gather_nd_unbatched, (0, 0), 0)(params, indices)\n",
    "\n",
    "\n",
    "def expand_z_where(z_where):\n",
    "    # Takes 3-dimensional vectors, and massages them into 2x3 matrices with elements like so:\n",
    "    # [s,x,y] -> [[s,0,x],\n",
    "    #             [0,s,y]]\n",
    "    n = 1\n",
    "    expansion_indices = jnp.array([1, 0, 2, 0, 1, 3])\n",
    "    z_where = jnp.expand_dims(z_where, axis=0)\n",
    "    out = jnp.concatenate((jnp.broadcast_to(jnp.zeros([1, 1]), (n, 1)), z_where), 1)\n",
    "    return jnp.reshape(out[:, expansion_indices], (n, 2, 3))\n",
    "\n",
    "\n",
    "def object_to_image(z_where, obj):\n",
    "    n = 1\n",
    "    theta = expand_z_where(z_where)\n",
    "    grid = affine_grid_generator(50, 50, theta)\n",
    "    x_s = grid[:, 0, :, :]\n",
    "    y_s = grid[:, 1, :, :]\n",
    "    out = bilinear_sampler(jnp.reshape(obj, (n, 20, 20, 1)), x_s, y_s)\n",
    "    return jnp.reshape(out, (50, 50))\n",
    "\n",
    "\n",
    "def z_where_inv(z_where):\n",
    "    # Take a batch of z_where vectors, and compute their \"inverse\".\n",
    "    # That is, for each row compute:\n",
    "    # [s,x,y] -> [1/s,-x/s,-y/s]\n",
    "    # These are the parameters required to perform the inverse of the\n",
    "    # spatial transform performed in the generative model.\n",
    "    n = 1\n",
    "    out = jnp.array([1, *(-z_where[1:])])\n",
    "    out = out / z_where[0]\n",
    "    return out\n",
    "\n",
    "\n",
    "def image_to_object(z_where, image):\n",
    "    n = 1\n",
    "    theta_inv = expand_z_where(z_where_inv(z_where))\n",
    "    grid = affine_grid_generator(20, 20, theta_inv)\n",
    "    x_s = grid[:, 0, :, :]\n",
    "    y_s = grid[:, 1, :, :]\n",
    "    out = bilinear_sampler(jnp.reshape(image, (n, 50, 50, 1)), x_s, y_s)\n",
    "    return jnp.reshape(out, (400,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6179494f-ccc0-449f-8fcc-7bb48b4783e9",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60196b16-596f-4b7d-b040-85b8a2808423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########\n",
    "# Model #\n",
    "#########\n",
    "\n",
    "# Fixed constants.\n",
    "z_where_prior_loc = jnp.array([3.0, 0.0, 0.0])\n",
    "z_where_prior_scale = jnp.array([0.2, 1.0, 1.0])\n",
    "z_what_prior_loc = jnp.zeros(50, dtype=float)\n",
    "z_what_prior_scale = jnp.ones(50, dtype=float)\n",
    "z_pres_prior = [0.05, 0.05**2.3, 0.05 ** (5)]\n",
    "eps = 1e-4\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def step(\n",
    "    t: Int,\n",
    "    decoder: Decoder,\n",
    "    prev_x: FloatArray,\n",
    "    prev_z_pres: IntArray,\n",
    "):\n",
    "    z_pres = grasp.flip_reinforce(z_pres_prior[t]) @ f\"z_pres_{t}\"\n",
    "    z_pres = jnp.array([z_pres.astype(int)])\n",
    "    z_where = (\n",
    "        grasp.mv_normal_diag_reparam(z_where_prior_loc, z_where_prior_scale)\n",
    "        @ f\"z_where_{t}\"\n",
    "    )\n",
    "    z_what = (\n",
    "        grasp.mv_normal_diag_reparam(z_what_prior_loc, z_what_prior_scale)\n",
    "        @ f\"z_what_{t}\"\n",
    "    )\n",
    "    y_att = decoder(z_what)\n",
    "    y = object_to_image(z_where, y_att)\n",
    "    x = prev_x + (y * z_pres)\n",
    "    return x, z_pres\n",
    "\n",
    "\n",
    "# TODO: Make sure that this works, where t is a static int.\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def model(decoder: Decoder):\n",
    "    x = jnp.zeros((50, 50), dtype=float)\n",
    "    z_pres = jnp.ones(1, dtype=int)\n",
    "    for t in range(3):\n",
    "        x, z_pres = step.inline(t, decoder, x, z_pres)\n",
    "    obs = grasp.mv_normal_diag_reparam(x, 0.3 * jnp.ones_like(x)) @ \"obs\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee69ad5-2136-4933-ad71-42f01483dab6",
   "metadata": {},
   "source": [
    "#### Samples from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41747dee-44a0-4cd6-8087-4ce4d526fcee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "├── \u001b[1m:z_pres_0\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_where_1\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_what_0\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_what_2\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_where_0\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_pres_2\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_pres_1\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_what_1\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_where_2\u001b[0m\n",
       "│   └──  f32[3]\n",
       "└── \u001b[1m:obs\u001b[0m\n",
       "    └──  f32[50,50]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = jax.jit(model.simulate)(key, (decoder,))\n",
    "tr.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8394159-926b-4607-8df0-bbcc49657ae0",
   "metadata": {},
   "source": [
    "### Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33dd2fbf-df45-4e48-ac82-9d005ffaab01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########\n",
    "# Guide #\n",
    "#########\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def guide_step(\n",
    "    t: Int,\n",
    "    rnn: eqx.nn.LSTMCell,\n",
    "    encoder: Encoder,\n",
    "    predict: Predict,\n",
    "    data,\n",
    "    prev: Tuple,\n",
    "):\n",
    "    (prev_z_where, prev_z_what, prev_z_pres, prev_h, prev_c) = prev\n",
    "    rnn_input = jnp.concatenate([data, prev_z_where, prev_z_what, prev_z_pres])\n",
    "    h, c = rnn(rnn_input, (prev_h, prev_c))\n",
    "    z_pres_p, z_where_loc, z_where_scale = predict(h)\n",
    "    z_pres_p = z_pres_p[0] * prev_z_pres[0]\n",
    "    z_pres_p = jnp.clip(z_pres_p, 0.001, 1.0)\n",
    "    z_pres = grasp.flip_reinforce(z_pres_p) @ f\"z_pres_{t}\"\n",
    "    (z_where_loc, z_where_scale) = jtu.tree_map(\n",
    "        lambda v1, v2: z_pres * v1 + (1 - z_pres) * v2,\n",
    "        (z_where_loc, z_where_scale),\n",
    "        (z_where_prior_loc, z_where_prior_scale),\n",
    "    )\n",
    "    z_where = grasp.mv_normal_diag_reparam(z_where_loc, z_where_scale) @ f\"z_where_{t}\"\n",
    "    x_att = image_to_object(z_where, data)\n",
    "    z_what_loc, z_what_scale = encoder(x_att)\n",
    "    (z_what_loc, z_what_scale) = jtu.tree_map(\n",
    "        lambda v1, v2: z_pres * v1 + (1 - z_pres) * v2,\n",
    "        (z_what_loc, z_what_scale),\n",
    "        (z_what_prior_loc, z_what_prior_scale),\n",
    "    )\n",
    "    z_what = grasp.mv_normal_diag_reparam(z_what_loc, z_what_scale) @ f\"z_what_{t}\"\n",
    "    z_pres = jnp.array([z_pres.astype(int)])\n",
    "    return z_where, z_what, z_pres, h, c\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def guide(\n",
    "    data: genjax.ChoiceMap,\n",
    "    rnn: eqx.nn.LSTMCell,\n",
    "    encoder: Encoder,\n",
    "    predict: Predict,\n",
    "):\n",
    "    h = jnp.zeros(256)\n",
    "    c = jnp.zeros(256)\n",
    "    z_pres = jnp.ones(1)\n",
    "    z_where = jnp.zeros(3)\n",
    "    z_what = jnp.zeros(50)\n",
    "    img = data[\"obs\"]\n",
    "    img_arr = img.flatten()\n",
    "\n",
    "    for t in range(3):\n",
    "        (z_where, z_what, z_pres, h, c) = guide_step.inline(\n",
    "            t, rnn, encoder, predict, img_arr, (z_where, z_what, z_pres, h, c)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89bc83-29fc-4e0e-a47d-dab2acf0c920",
   "metadata": {},
   "source": [
    "#### Samples from the guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2984c5cc-2b4c-40f5-ad0c-a2c3d1508f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "├── \u001b[1m:z_pres_0\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_where_1\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_what_0\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_what_2\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_where_0\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_pres_2\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_pres_1\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_what_1\u001b[0m\n",
       "│   └──  f32[50]\n",
       "└── \u001b[1m:z_where_2\u001b[0m\n",
       "    └──  f32[3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_chm = genjax.choice_map({\"obs\": jnp.ones((50, 50))})\n",
    "tr = guide.simulate(key, (data_chm, rnn, encoder, predict))\n",
    "tr.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b2f0a-dee4-470d-8bfa-c71a9e466690",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32a7cd-d44b-46dd-bea2-8ddac55aa88a",
   "metadata": {},
   "source": [
    "### Make sure grads are working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc1805-57c9-4c44-8ace-2b0fa068c9c7",
   "metadata": {},
   "source": [
    "#### Define ELBO objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "435472dd-c312-4f5f-8fc4-f2c0125491ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = genjax.choice_map({\"obs\": jnp.ones((50, 50))})\n",
    "objective = grasp.elbo(model, guide, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860fc0c2-6adb-4d7d-8ab1-0c1fccc16a65",
   "metadata": {},
   "source": [
    "#### Go go grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1ec3a5-e506-41bb-9a97-0c13bcbfb108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jitted = jax.jit(objective.value_and_grad_estimate)\n",
    "loss, ((decoder_grads,), (_, rnn_grads, encoder_grads, predict_grads)) = jitted(\n",
    "    key, ((decoder,), (data, rnn, encoder, predict))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817c347c-fdff-4822-9091-2d58887f5baa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mArray\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m-1704.9744\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mfloat32\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf5b4af-8df8-4bca-b0f2-c576dd0ba659",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdf9c5ed-4369-4a68-8ce8-af7754576fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_loader(\n",
    "    data,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "):\n",
    "    N = len(data)\n",
    "    data_idxs = np.arange(N)\n",
    "    num_batch = int(np.ceil(N // batch_size))\n",
    "\n",
    "    def init(key):\n",
    "        return (\n",
    "            num_batch,\n",
    "            jax.random.permutation(key, data_idxs) if shuffle else data_idxs,\n",
    "        )\n",
    "\n",
    "    def get_batch(i=0, idxs=data_idxs):\n",
    "        ret_idx = jax.lax.dynamic_slice_in_dim(idxs, i * batch_size, batch_size)\n",
    "        return jax.lax.index_take(data, (ret_idx,), axes=(0,))\n",
    "\n",
    "    return init, get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bce54cb-d22a-43b8-b296-6067484552d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Count Accuracy #\n",
    "##################\n",
    "\n",
    "\n",
    "def count_accuracy(data, true_counts, guide, batch_size=1000):\n",
    "    global prng_key\n",
    "    assert data.shape[0] == true_counts.shape[0], \"Size mismatch.\"\n",
    "    assert data.shape[0] % batch_size == 0, \"Input size must be multiple of batch_size.\"\n",
    "\n",
    "    def eval_guide(key, data, params):\n",
    "        data_chmp = genjax.choice_map({\"obs\": data})\n",
    "        return guide.simulate(key, (data_chmp, *params))\n",
    "\n",
    "    batch_eval_guide = jax.vmap(eval_guide, in_axes=(0, 0, None))\n",
    "\n",
    "    @jax.jit\n",
    "    def evaluate_count_accuracy(key, params):\n",
    "        def evaluate_batch(counts, batch_id):\n",
    "            data_batch = jax.lax.dynamic_slice_in_dim(\n",
    "                data, batch_id * batch_size, batch_size\n",
    "            )\n",
    "            true_counts_batch = jax.lax.dynamic_slice_in_dim(\n",
    "                true_counts, batch_id * batch_size, batch_size\n",
    "            )\n",
    "            data_chmp = genjax.choice_map({\"obs\": data_batch})\n",
    "            # evaluate guide\n",
    "            keys = jax.random.split(jax.random.fold_in(key, batch_id), batch_size)\n",
    "            tr = batch_eval_guide(keys, data_batch, params)\n",
    "            z_where = [tr[f\"z_where_{i}\"] for i in range(3)]\n",
    "            z_pres = [tr[f\"z_pres_{i}\"] for i in range(3)]\n",
    "            # compute stats\n",
    "            inferred_counts = sum(z for z in z_pres)\n",
    "            true_counts_m = jax.nn.one_hot(true_counts_batch, 3)\n",
    "            inferred_counts_m = jax.nn.one_hot(inferred_counts, 4)\n",
    "            counts += (true_counts_m.T @ inferred_counts_m).astype(int)\n",
    "            error_ind = 1 - (true_counts_batch == inferred_counts).astype(int)\n",
    "            # error_ix = error_ind.nonzero()[0]\n",
    "            # error_latent = jnp.take(latents_to_tensor((z_where, z_pres)), error_ix, 0)\n",
    "            return counts, error_ind\n",
    "\n",
    "        counts = jnp.zeros((3, 4), dtype=int)\n",
    "        counts, error_indices = jax.lax.scan(\n",
    "            evaluate_batch, counts, jnp.arange(data.shape[0] // batch_size)\n",
    "        )\n",
    "\n",
    "        acc = jnp.sum(jnp.diag(counts)).astype(float) / data.shape[0]\n",
    "        error_indices = jnp.concatenate(\n",
    "            error_indices\n",
    "        )  # .nonzero()[0]  # <- not JIT compilable\n",
    "        return acc, counts, error_indices\n",
    "\n",
    "    return evaluate_count_accuracy\n",
    "\n",
    "\n",
    "# Combine z_pres and z_where (as returned by the model and guide) into\n",
    "# a single tensor, with size:\n",
    "# [batch_size, num_steps, z_where_size + z_pres_size]\n",
    "def latents_to_tensor(z):\n",
    "    return jnp.stack(\n",
    "        [\n",
    "            jnp.concatenate((z_where, z_pres.reshape(-1, 1)), 1)\n",
    "            for z_where, z_pres in zip(*z)\n",
    "        ]\n",
    "    ).transpose(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3660daf7-584d-4fd9-a26b-371d32fb5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Visualization  #\n",
    "##################\n",
    "\n",
    "\n",
    "def bounding_box(z_where, x_size):\n",
    "    \"\"\"This doesn't take into account interpolation, but it's close\n",
    "    enough to be usable.\"\"\"\n",
    "    w = x_size / z_where.s\n",
    "    h = x_size / z_where.s\n",
    "    xtrans = -z_where.x / z_where.s * x_size / 2.0\n",
    "    ytrans = -z_where.y / z_where.s * x_size / 2.0\n",
    "    x = (x_size - w) / 2 + xtrans  # origin is top left\n",
    "    y = (x_size - h) / 2 + ytrans\n",
    "    return (x, y), w, h\n",
    "\n",
    "\n",
    "z_obj = namedtuple(\"z\", [\"s\", \"x\", \"y\", \"pres\"])\n",
    "\n",
    "\n",
    "# Map a tensor of latents (as produced by latents_to_tensor) to a list\n",
    "# of z_obj named tuples.\n",
    "def tensor_to_objs(latents):\n",
    "    return [[z_obj._make(step) for step in z] for z in latents]\n",
    "\n",
    "\n",
    "def visualize_model(model, guide):\n",
    "    def reconstruct_digits(key, data, params):\n",
    "        decoder, rnn, encoder, predict = params\n",
    "        data_chmp = genjax.choice_map({\"obs\": data})\n",
    "        key1, key2 = jax.random.split(key)\n",
    "        tr = guide.simulate(key1, (data_chmp, rnn, encoder, predict))\n",
    "        _, tr = model.importance(key2, tr, (decoder,))\n",
    "        reconstruction = tr.get_retval()\n",
    "        z_where = [tr[f\"z_where_{i}\"] for i in range(3)]\n",
    "        z_pres = [tr[f\"z_pres_{i}\"] for i in range(3)]\n",
    "        return reconstruction, (z_where, z_pres)\n",
    "\n",
    "    batch_reconstruct_digits = jax.jit(\n",
    "        jax.vmap(reconstruct_digits, in_axes=(0, 0, None))\n",
    "    )\n",
    "\n",
    "    def visualize(key, params, examples_to_viz):\n",
    "        keys = jax.random.split(key, examples_to_viz.shape[0])\n",
    "        recons, z = batch_reconstruct_digits(keys, examples_to_viz, params)\n",
    "        z_wheres = tensor_to_objs(latents_to_tensor(z))\n",
    "        draw_many(examples_to_viz.reshape(-1, 50, 50), z_wheres, title=\"Original\")\n",
    "        draw_many(recons, z_wheres, title=\"Reconstruction\")\n",
    "\n",
    "    return visualize\n",
    "\n",
    "\n",
    "def colors(k):\n",
    "    return [\"r\", \"g\", \"b\"][k % 3]\n",
    "\n",
    "\n",
    "def draw_one(img, z):\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img, cmap=\"gray_r\")\n",
    "    for k, z in enumerate(z):\n",
    "        if z.pres > 0:\n",
    "            (x, y), w, h = bounding_box(z, img.shape[0])\n",
    "            plt.gca().add_patch(\n",
    "                Rectangle(\n",
    "                    (x, y), w, h, linewidth=1, edgecolor=colors(k), facecolor=\"none\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "def draw_many(imgs, zs, title):\n",
    "    plt.figure(figsize=(8, 1.9))\n",
    "    plt.title(title)\n",
    "    plt.tick_params(left=False, labelleft=False, bottom=False, labelbottom=False)\n",
    "    plt.box(False)\n",
    "    for i, (img, z) in enumerate(zip(imgs, zs)):\n",
    "        plt.subplot(1, len(imgs), i + 1)\n",
    "        draw_one(img, z)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da48a46a-fdb1-4b8d-b4e5-d96d27b898d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (decoder, rnn, encoder, predict)\n",
    "evaluate_accuracy = count_accuracy(mnist, true_counts, guide, batch_size=1000)\n",
    "\n",
    "visualize_examples = mnist[5:10]\n",
    "visualize = visualize_model(model, guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaf743cf-aa9e-44db-9078-6a89f1d26f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(key, n=1, num_epochs=200, batch_size=64, learning_rate=1.0e-4):\n",
    "    def svi_update(model, guide, optimiser):\n",
    "        def batch_updater(key, params, opt_state, data_batch):\n",
    "            def grads(key, params, data):\n",
    "                (decoder, rnn, encoder, predict) = params\n",
    "                data = genjax.choice_map({\"obs\": data})\n",
    "                objective = grasp.iwae_elbo(model, guide, data, n)\n",
    "                loss, (\n",
    "                    (decoder_grads,),\n",
    "                    (_, rnn_grads, encoder_grads, predict_grads),\n",
    "                ) = objective.value_and_grad_estimate(\n",
    "                    key, ((decoder,), (data, rnn, encoder, predict))\n",
    "                )\n",
    "                return loss, (decoder_grads, rnn_grads, encoder_grads, predict_grads)\n",
    "\n",
    "            sub_keys = jax.random.split(key, len(data_batch))\n",
    "            loss, (decoder_grads, rnn_grads, encoder_grads, predict_grads) = jax.vmap(\n",
    "                grads, in_axes=(0, None, 0)\n",
    "            )(sub_keys, params, data_batch)\n",
    "\n",
    "            grads = jtu.tree_map(\n",
    "                lambda v: -1.0 * jnp.mean(v, axis=0),\n",
    "                (decoder_grads, rnn_grads, encoder_grads, predict_grads),\n",
    "            )\n",
    "            updates, opt_state = optimiser.update(grads, opt_state, params)\n",
    "            params = optax.apply_updates(params, updates)\n",
    "            loss = jnp.mean(loss)\n",
    "            return params, opt_state, loss\n",
    "\n",
    "        return batch_updater\n",
    "\n",
    "    adam = optax.adam(learning_rate)\n",
    "    svi_updater = svi_update(model, guide, adam)\n",
    "    train_init, train_fetch = data_loader(jnp.array(mnist), batch_size)\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    num_batch, train_idx = train_init(sub_key)\n",
    "\n",
    "    @jax.jit\n",
    "    def epoch_train(opt_state, params, key, train_idx):\n",
    "        def body_fn(carry, xs):\n",
    "            idx, params, opt_state, loss = carry\n",
    "            updater_key = jax.random.fold_in(key, idx)\n",
    "            batch = train_fetch(idx, train_idx)\n",
    "            params, opt_state, loss = svi_updater(updater_key, params, opt_state, batch)\n",
    "            idx += 1\n",
    "            return (idx, params, opt_state, loss), loss\n",
    "\n",
    "        idx = 0\n",
    "        (_, params, opt_state, _), losses = jax.lax.scan(\n",
    "            body_fn, (idx, params, opt_state, 0.0), None, length=num_batch\n",
    "        )\n",
    "        return params, opt_state, losses\n",
    "\n",
    "    # Train.\n",
    "    params = (decoder, rnn, encoder, predict)\n",
    "    opt_state = adam.init(params)\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    wall_clock_times = []\n",
    "\n",
    "    # Warm up.\n",
    "    _ = epoch_train(opt_state, params, key, train_idx)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    acc_time = 0.0\n",
    "    for i in range(0, num_epochs + 1):\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        num_batch, train_idx = train_init(sub_key)\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        start = time.perf_counter() - t0\n",
    "        params, opt_state, loss = epoch_train(opt_state, params, sub_key, train_idx)\n",
    "        stop = time.perf_counter() - t0\n",
    "        acc_time += stop - start\n",
    "        wall_clock_times.append(acc_time)\n",
    "        print(\n",
    "            f\"Epoch={i}, total_epoch_step_time={acc_time:.2f}, loss={jnp.mean(loss):.2f}\"\n",
    "        )\n",
    "        losses.append(jnp.mean(loss))\n",
    "        acc, counts, error_ix = evaluate_accuracy(sub_key, params[1:])\n",
    "        accuracy.append(acc)\n",
    "        print(\"accuracy={}, counts={}\".format(acc, counts))\n",
    "\n",
    "    return losses, accuracy, wall_clock_times, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bee83598-7119-4e04-992d-8a4fa160768e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, total_epoch_step_time=1.48, loss=38.13\n",
      "accuracy=0.2362833321094513, counts=[[11234  7325  1347    42]\n",
      " [17038  2939    43     0]\n",
      " [19176   852     4     0]]\n",
      "Epoch=1, total_epoch_step_time=2.85, loss=435.44\n",
      "accuracy=0.22671666741371155, counts=[[11583  7753   610     2]\n",
      " [17995  2019     6     0]\n",
      " [19585   446     1     0]]\n",
      "Epoch=2, total_epoch_step_time=4.25, loss=442.03\n",
      "accuracy=0.22384999692440033, counts=[[11877  7647   423     1]\n",
      " [18462  1554     4     0]\n",
      " [19738   294     0     0]]\n",
      "Epoch=3, total_epoch_step_time=5.60, loss=446.76\n",
      "accuracy=0.23155000805854797, counts=[[12704  6953   290     1]\n",
      " [18827  1189     4     0]\n",
      " [19842   190     0     0]]\n",
      "Epoch=4, total_epoch_step_time=7.00, loss=451.33\n",
      "accuracy=0.24040000140666962, counts=[[13534  6227   185     2]\n",
      " [19127   890     3     0]\n",
      " [19882   150     0     0]]\n",
      "Epoch=5, total_epoch_step_time=8.50, loss=455.64\n",
      "accuracy=0.25369998812675476, counts=[[14573  5295    80     0]\n",
      " [19370   649     1     0]\n",
      " [19905   127     0     0]]\n",
      "Epoch=6, total_epoch_step_time=10.01, loss=458.20\n",
      "accuracy=0.2676333487033844, counts=[[15517  4387    44     0]\n",
      " [19478   541     1     0]\n",
      " [19934    98     0     0]]\n",
      "Epoch=7, total_epoch_step_time=11.48, loss=459.27\n",
      "accuracy=0.2788333296775818, counts=[[16389  3540    19     0]\n",
      " [19679   341     0     0]\n",
      " [19954    78     0     0]]\n",
      "Epoch=8, total_epoch_step_time=13.11, loss=459.63\n",
      "accuracy=0.2815000116825104, counts=[[16504  3434    10     0]\n",
      " [19633   386     1     0]\n",
      " [19957    75     0     0]]\n",
      "Epoch=9, total_epoch_step_time=14.77, loss=459.70\n",
      "accuracy=0.2833833396434784, counts=[[16675  3263    10     0]\n",
      " [19691   328     1     0]\n",
      " [19965    67     0     0]]\n",
      "Epoch=10, total_epoch_step_time=16.36, loss=459.80\n",
      "accuracy=0.28691667318344116, counts=[[16960  2984     4     0]\n",
      " [19765   255     0     0]\n",
      " [19979    53     0     0]]\n",
      "Epoch=11, total_epoch_step_time=17.92, loss=459.91\n",
      "accuracy=0.2949666678905487, counts=[[17510  2434     4     0]\n",
      " [19832   188     0     0]\n",
      " [19964    68     0     0]]\n",
      "Epoch=12, total_epoch_step_time=19.49, loss=459.97\n",
      "accuracy=0.29463332891464233, counts=[[17434  2510     4     0]\n",
      " [19776   244     0     0]\n",
      " [19966    66     0     0]]\n",
      "Epoch=13, total_epoch_step_time=20.96, loss=459.96\n",
      "accuracy=0.29413333535194397, counts=[[17467  2470    11     0]\n",
      " [19839   181     0     0]\n",
      " [19960    72     0     0]]\n",
      "Epoch=14, total_epoch_step_time=22.28, loss=459.95\n",
      "accuracy=0.28788334131240845, counts=[[17133  2810     5     0]\n",
      " [19879   140     1     0]\n",
      " [19975    57     0     0]]\n",
      "Epoch=15, total_epoch_step_time=23.62, loss=460.00\n",
      "accuracy=0.28983333706855774, counts=[[17295  2650     3     0]\n",
      " [19925    95     0     0]\n",
      " [19973    59     0     0]]\n",
      "Epoch=16, total_epoch_step_time=24.96, loss=460.02\n",
      "accuracy=0.28208333253860474, counts=[[16810  3124    14     0]\n",
      " [19905   115     0     0]\n",
      " [19971    61     0     0]]\n",
      "Epoch=17, total_epoch_step_time=26.29, loss=460.04\n",
      "accuracy=0.28091666102409363, counts=[[16732  3211     5     0]\n",
      " [19897   123     0     0]\n",
      " [19968    64     0     0]]\n",
      "Epoch=18, total_epoch_step_time=27.62, loss=460.08\n",
      "accuracy=0.2765333354473114, counts=[[16466  3475     7     0]\n",
      " [19894   126     0     0]\n",
      " [19977    55     0     0]]\n",
      "Epoch=19, total_epoch_step_time=28.95, loss=460.08\n",
      "accuracy=0.2728833258152008, counts=[[16248  3691     9     0]\n",
      " [19895   125     0     0]\n",
      " [19971    61     0     0]]\n",
      "Epoch=20, total_epoch_step_time=30.28, loss=460.08\n",
      "accuracy=0.2744666635990143, counts=[[16377  3563     8     0]\n",
      " [19928    91     1     0]\n",
      " [19965    67     0     0]]\n",
      "Epoch=21, total_epoch_step_time=31.61, loss=460.10\n",
      "accuracy=0.2639999985694885, counts=[[15712  4227     9     0]\n",
      " [19892   128     0     0]\n",
      " [19972    60     0     0]]\n",
      "Epoch=22, total_epoch_step_time=32.94, loss=460.12\n",
      "accuracy=0.2634499967098236, counts=[[15716  4223     9     0]\n",
      " [19929    91     0     0]\n",
      " [19956    76     0     0]]\n",
      "Epoch=23, total_epoch_step_time=34.28, loss=460.07\n",
      "accuracy=0.26056668162345886, counts=[[15529  4413     6     0]\n",
      " [19915   105     0     0]\n",
      " [19965    67     0     0]]\n",
      "Epoch=24, total_epoch_step_time=35.61, loss=460.07\n",
      "accuracy=0.2603166699409485, counts=[[15536  4404     8     0]\n",
      " [19936    83     1     0]\n",
      " [19977    55     0     0]]\n",
      "Epoch=25, total_epoch_step_time=36.94, loss=460.09\n",
      "accuracy=0.2672500014305115, counts=[[15956  3989     3     0]\n",
      " [19941    79     0     0]\n",
      " [19985    47     0     0]]\n",
      "Epoch=26, total_epoch_step_time=38.28, loss=460.09\n",
      "accuracy=0.2628333270549774, counts=[[15700  4236    12     0]\n",
      " [19950    70     0     0]\n",
      " [19979    53     0     0]]\n",
      "Epoch=27, total_epoch_step_time=39.79, loss=460.10\n",
      "accuracy=0.2644500136375427, counts=[[15792  4145    11     0]\n",
      " [19945    75     0     0]\n",
      " [19969    63     0     0]]\n",
      "Epoch=28, total_epoch_step_time=41.51, loss=460.12\n",
      "accuracy=0.26846668124198914, counts=[[16054  3884    10     0]\n",
      " [19966    54     0     0]\n",
      " [19976    56     0     0]]\n",
      "Epoch=29, total_epoch_step_time=43.20, loss=460.12\n",
      "accuracy=0.27016666531562805, counts=[[16138  3799    11     0]\n",
      " [19948    72     0     0]\n",
      " [19980    52     0     0]]\n",
      "Epoch=30, total_epoch_step_time=44.76, loss=460.12\n",
      "accuracy=0.2641333341598511, counts=[[15781  4160     7     0]\n",
      " [19953    67     0     0]\n",
      " [19978    54     0     0]]\n",
      "Epoch=31, total_epoch_step_time=46.35, loss=460.13\n",
      "accuracy=0.2697499990463257, counts=[[16122  3819     7     0]\n",
      " [19957    63     0     0]\n",
      " [19983    49     0     0]]\n",
      "Epoch=32, total_epoch_step_time=47.97, loss=460.15\n",
      "accuracy=0.27353334426879883, counts=[[16358  3586     4     0]\n",
      " [19966    54     0     0]\n",
      " [19966    66     0     0]]\n",
      "Epoch=33, total_epoch_step_time=49.55, loss=460.10\n",
      "accuracy=0.26774999499320984, counts=[[16004  3939     5     0]\n",
      " [19959    61     0     0]\n",
      " [19985    47     0     0]]\n",
      "Epoch=34, total_epoch_step_time=51.13, loss=460.11\n",
      "accuracy=0.27584999799728394, counts=[[16471  3471     6     0]\n",
      " [19940    80     0     0]\n",
      " [19969    63     0     0]]\n",
      "Epoch=35, total_epoch_step_time=52.77, loss=460.08\n",
      "accuracy=0.27276667952537537, counts=[[16310  3631     7     0]\n",
      " [19964    56     0     0]\n",
      " [19971    61     0     0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>losses, accuracy, wall_clock_times = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> train_idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>):                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>key, sub_key = jax.random.split(key)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 7 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>r_loss, r_acc, r_times, params = train(                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>sub_key, learning_rate=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0e-4</span>, n=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, batch_size=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">64</span>, num_epochs=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">40</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>)                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Save run.</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">71</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">68 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>num_batch, train_idx = train_init(sub_key)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">69 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>key, sub_key = jax.random.split(key)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">70 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>start = time.perf_counter() - t0                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>71 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>params, opt_state, loss = epoch_train(opt_state, params, sub_key, train_idx)        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">72 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>stop = time.perf_counter() - t0                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">73 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>acc_time += stop - start                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">74 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>wall_clock_times.append(acc_time)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/equinox/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">732</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_unflatten_module</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 729 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(dynamic_field_values), aux                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 730 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 731 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 732 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_unflatten_module</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>[<span style=\"color: #808000; text-decoration-color: #808000\">\"Module\"</span>], aux: _FlattenedData, dynamic_field_values):    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 733 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># This doesn't go via `__init__`. A user may have done something nontrivial there,</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 734 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># and the field values may be dummy values as used in various places throughout JAX.</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 735 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># See also</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0mlosses, accuracy, wall_clock_times = \u001b[94mNone\u001b[0m, \u001b[94mNone\u001b[0m, \u001b[94mNone\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[94mfor\u001b[0m train_idx \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[94m0\u001b[0m, \u001b[94m5\u001b[0m):                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   \u001b[0mkey, sub_key = jax.random.split(key)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 7 \u001b[2m│   \u001b[0mr_loss, r_acc, r_times, params = train(                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   │   \u001b[0msub_key, learning_rate=\u001b[94m1.0e-4\u001b[0m, n=\u001b[94m1\u001b[0m, batch_size=\u001b[94m64\u001b[0m, num_epochs=\u001b[94m40\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Save run.\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtrain\u001b[0m:\u001b[94m71\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m68 \u001b[0m\u001b[2m│   │   \u001b[0mnum_batch, train_idx = train_init(sub_key)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m69 \u001b[0m\u001b[2m│   │   \u001b[0mkey, sub_key = jax.random.split(key)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m70 \u001b[0m\u001b[2m│   │   \u001b[0mstart = time.perf_counter() - t0                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m71 \u001b[2m│   │   \u001b[0mparams, opt_state, loss = epoch_train(opt_state, params, sub_key, train_idx)        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m72 \u001b[0m\u001b[2m│   │   \u001b[0mstop = time.perf_counter() - t0                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m73 \u001b[0m\u001b[2m│   │   \u001b[0macc_time += stop - start                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m74 \u001b[0m\u001b[2m│   │   \u001b[0mwall_clock_times.append(acc_time)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/equinox/\u001b[0m\u001b[1;33m_module.py\u001b[0m:\u001b[94m732\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_unflatten_module\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 729 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mtuple\u001b[0m(dynamic_field_values), aux                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 730 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 731 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 732 \u001b[94mdef\u001b[0m \u001b[92m_unflatten_module\u001b[0m(\u001b[96mcls\u001b[0m: \u001b[96mtype\u001b[0m[\u001b[33m\"\u001b[0m\u001b[33mModule\u001b[0m\u001b[33m\"\u001b[0m], aux: _FlattenedData, dynamic_field_values):    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 733 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# This doesn't go via `__init__`. A user may have done something nontrivial there,\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 734 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# and the field values may be dummy values as used in various places throughout JAX.\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 735 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# See also\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Run with different random seeds.\n",
    "losses, accuracy, wall_clock_times = None, None, None\n",
    "for train_idx in range(0, 5):\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    r_loss, r_acc, r_times, params = train(\n",
    "        sub_key, learning_rate=1.0e-4, n=1, batch_size=64, num_epochs=40\n",
    "    )\n",
    "    # Save run.\n",
    "    arr = np.array([r_loss, r_acc, r_times])\n",
    "    df = pd.DataFrame(\n",
    "        arr.T, columns=[\"ELBO loss\", \"Accuracy\", \"Epoch wall clock times\"]\n",
    "    )\n",
    "    df.to_csv(\n",
    "        f\"./training_runs/grasp_air_reinforce_epochs_41_mccoy_prior_{train_idx}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    if losses is None:\n",
    "        losses = r_loss\n",
    "        accuracy = r_acc\n",
    "        wall_clock_times = r_times\n",
    "\n",
    "    else:\n",
    "        losses = np.vstack((losses, r_loss))\n",
    "        accuracy = np.vstack((accuracy, r_acc))\n",
    "        wall_clock_times = np.vstack((wall_clock_times, r_times))\n",
    "\n",
    "arr = np.array([losses, accuracy, wall_clock_times])\n",
    "mean_arr = jnp.mean(arr, axis=1)\n",
    "std_arr = jnp.std(arr, axis=1)\n",
    "df_arr = jnp.vstack((mean_arr, std_arr))\n",
    "df = pd.DataFrame(\n",
    "    df_arr.T,\n",
    "    columns=[\n",
    "        \"Mean ELBO loss\",\n",
    "        \"Mean accuracy\",\n",
    "        \"Mean epoch wall clock times\",\n",
    "        \"Std ELBO loss\",\n",
    "        \"Std accuracy\",\n",
    "        \"Std epoch wall clock times\",\n",
    "    ],\n",
    ")\n",
    "df.to_csv(\"./training_runs/grasp_air_reinforce_epochs_41_mccoy_prior.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b57d1b-155d-4a25-a8f1-b1c37375f95a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, total_epoch_step_time=39.76, loss=449.72\n",
      "accuracy=0.2502666711807251, counts=[[14965  4977     6     0]\n",
      " [19970    50     0     0]\n",
      " [19990    41     1     0]]\n",
      "Epoch=1, total_epoch_step_time=78.91, loss=460.11\n",
      "accuracy=0.2626500129699707, counts=[[15693  4245    10     0]\n",
      " [19954    66     0     0]\n",
      " [19973    59     0     0]]\n",
      "Epoch=2, total_epoch_step_time=118.45, loss=460.12\n",
      "accuracy=0.233800008893013, counts=[[13974  5967     7     0]\n",
      " [19966    54     0     0]\n",
      " [19960    72     0     0]]\n",
      "Epoch=3, total_epoch_step_time=158.71, loss=459.98\n",
      "accuracy=0.22325000166893005, counts=[[13335  6598    15     0]\n",
      " [19960    60     0     0]\n",
      " [19975    57     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Run with different random seeds.\n",
    "losses, accuracy, wall_clock_times = None, None, None\n",
    "for train_idx in range(0, 5):\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    r_loss, r_acc, r_times, params = train(\n",
    "        sub_key, learning_rate=1.0e-4, n=2, batch_size=1, num_epochs=40\n",
    "    )\n",
    "    # Save run.\n",
    "    arr = np.array([r_loss, r_acc, r_times])\n",
    "    df = pd.DataFrame(\n",
    "        arr.T, columns=[\"ELBO loss\", \"Accuracy\", \"Epoch wall clock times\"]\n",
    "    )\n",
    "    df.to_csv(\n",
    "        f\"./training_runs/grasp_air_iwae_2_reinforce_epochs_41_mccoy_prior_{train_idx}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    if losses is None:\n",
    "        losses = r_loss\n",
    "        accuracy = r_acc\n",
    "        wall_clock_times = r_times\n",
    "\n",
    "    else:\n",
    "        losses = np.vstack((losses, r_loss))\n",
    "        accuracy = np.vstack((accuracy, r_acc))\n",
    "        wall_clock_times = np.vstack((wall_clock_times, r_times))\n",
    "\n",
    "arr = np.array([losses, accuracy, wall_clock_times])\n",
    "mean_arr = jnp.mean(arr, axis=1)\n",
    "std_arr = jnp.std(arr, axis=1)\n",
    "df_arr = jnp.vstack((mean_arr, std_arr))\n",
    "df = pd.DataFrame(\n",
    "    df_arr.T,\n",
    "    columns=[\n",
    "        \"Mean ELBO loss\",\n",
    "        \"Mean accuracy\",\n",
    "        \"Mean epoch wall clock times\",\n",
    "        \"Std ELBO loss\",\n",
    "        \"Std accuracy\",\n",
    "        \"Std epoch wall clock times\",\n",
    "    ],\n",
    ")\n",
    "df.to_csv(\n",
    "    \"./training_runs/grasp_air_iwae_2_reinforce_epochs_41_mccoy_prior.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
