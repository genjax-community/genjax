{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pyro\n",
    "import pyro.contrib.examples.multi_mnist as multi_mnist\n",
    "from pyro.infer import (\n",
    "    SVI,\n",
    "    RenyiELBO,\n",
    "    TraceGraph_ELBO,\n",
    "    TraceEnum_ELBO,\n",
    "    ReweightedWakeSleep,\n",
    ")\n",
    "from pyro.optim import Adam\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from pyro_air import AIR, make_prior, get_per_param_lr, count_accuracy, visualize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Benchmark Configs\n",
    "#####################\n",
    "seed = 123456\n",
    "use_cuda = torch.cuda.is_available()\n",
    "batch_size = 64\n",
    "num_epoches = 41\n",
    "\n",
    "z_pres_prior = 0.01\n",
    "learning_rate = 1e-4\n",
    "baseline_lr = 1e-1\n",
    "elbo = TraceGraph_ELBO()\n",
    "# explicitly list out all configurable options\n",
    "air_model_args = dict(\n",
    "    num_steps=3,\n",
    "    x_size=50,\n",
    "    window_size=28,\n",
    "    z_what_size=50,\n",
    "    rnn_hidden_size=256,\n",
    "    encoder_net=[200],\n",
    "    decoder_net=[200],\n",
    "    predict_net=[200],\n",
    "    embed_net=None,\n",
    "    bl_predict_net=[200],\n",
    "    non_linearity=\"ReLU\",\n",
    "    decoder_output_bias=-2,\n",
    "    decoder_output_use_sigmoid=True,\n",
    "    use_masking=True,\n",
    "    use_baselines=True,\n",
    "    baseline_scalar=None,\n",
    "    scale_prior_mean=3.0,\n",
    "    scale_prior_sd=0.2,\n",
    "    pos_prior_mean=0.0,\n",
    "    pos_prior_sd=1.0,\n",
    "    likelihood_sd=0.3,\n",
    "    use_cuda=use_cuda,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Initial Setup\n",
    "#####################\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "z_pres_prior_fn = lambda t: [0.008, 5.12e-07, 3.2768e-11][t]\n",
    "\n",
    "X, Y = multi_mnist.load(\"data/air/.data\")\n",
    "X = (torch.from_numpy(X).float() / 255.0).to(device)\n",
    "visualize_examples = X[5:10]\n",
    "# Using float to allow comparison with values sampled from\n",
    "# Bernoulli.\n",
    "true_counts = torch.tensor([len(objs) for objs in Y], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if seed is not None:\n",
    "    pyro.set_rng_seed(seed)\n",
    "pyro.distributions.enable_validation(False)\n",
    "pyro.clear_param_store()  # just in case\n",
    "\n",
    "air = AIR(**air_model_args)\n",
    "adam = Adam(get_per_param_lr(learning_rate, baseline_lr))\n",
    "svi = SVI(air.model, air.guide, adam, loss=elbo)\n",
    "\n",
    "all_loss = []\n",
    "all_accuracy = []\n",
    "time_per_epoch = []\n",
    "\n",
    "for i in range(num_epoches):\n",
    "    start_time = time.perf_counter()\n",
    "    # technically this might step over slightly more than 1 epoch...\n",
    "    losses = []\n",
    "    for j in range(int(np.ceil(X.size(0) / batch_size))):\n",
    "        losses.append(\n",
    "            svi.step(X, batch_size=batch_size, z_pres_prior_p=z_pres_prior_fn)\n",
    "        )\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    accuracy, counts, error_z, error_ix = count_accuracy(X, true_counts, air, 1000)\n",
    "\n",
    "    all_loss.append(np.mean(losses) / X.size(0))\n",
    "    all_accuracy.append(accuracy)\n",
    "    time_per_epoch.append(end_time - start_time)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch={i}, current_epoch_step_time={time_per_epoch[-1]:.2f}, loss={all_loss[-1]:.2f}\"\n",
    "    )\n",
    "    if i % 5 == 0:\n",
    "        print(f\"accuracy={accuracy}, counts={counts}\")\n",
    "        visualize_model(visualize_examples, air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wall_clock_times = np.cumsum(time_per_epoch)\n",
    "arr = np.array([all_loss, all_accuracy, wall_clock_times])\n",
    "df = pd.DataFrame(arr.T, columns=[\"ELBO Loss\", \"Accuracy\", \"Epoch wall clock times\"])\n",
    "df.to_csv(\n",
    "    \"./training_runs/pyro_trace_graph_elbo_baselines_bsize64_mccoy_prior.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
