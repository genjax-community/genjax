{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pyro\n",
    "import pyro.contrib.examples.multi_mnist as multi_mnist\n",
    "from pyro.infer import (\n",
    "    SVI,\n",
    "    RenyiELBO,\n",
    "    Trace_ELBO,\n",
    "    TraceGraph_ELBO,\n",
    "    TraceEnum_ELBO,\n",
    "    ReweightedWakeSleep,\n",
    ")\n",
    "from pyro.optim import Adam\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from pyro_air import AIR, make_prior, get_per_param_lr, count_accuracy, visualize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Benchmark Configs\n",
    "#####################\n",
    "seed = 123456\n",
    "use_cuda = torch.cuda.is_available()\n",
    "batch_size = 1\n",
    "num_epoches = 6\n",
    "\n",
    "z_pres_prior = 0.01\n",
    "learning_rate = 1e-4\n",
    "baseline_lr = 1e-1\n",
    "elbo = RenyiELBO(num_particles=2)\n",
    "# explicitly list out all configurable options\n",
    "air_model_args = dict(\n",
    "    num_steps=3,\n",
    "    x_size=50,\n",
    "    window_size=28,\n",
    "    z_what_size=50,\n",
    "    rnn_hidden_size=256,\n",
    "    encoder_net=[200],\n",
    "    decoder_net=[200],\n",
    "    predict_net=[200],\n",
    "    embed_net=None,\n",
    "    bl_predict_net=[200],\n",
    "    non_linearity=\"ReLU\",\n",
    "    decoder_output_bias=-2,\n",
    "    decoder_output_use_sigmoid=True,\n",
    "    use_masking=True,\n",
    "    use_baselines=False,\n",
    "    baseline_scalar=None,\n",
    "    scale_prior_mean=3.0,\n",
    "    scale_prior_sd=0.2,\n",
    "    pos_prior_mean=0.0,\n",
    "    pos_prior_sd=1.0,\n",
    "    likelihood_sd=0.3,\n",
    "    use_cuda=use_cuda,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Initial Setup\n",
    "#####################\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "z_pres_prior_fn = lambda t: [0.05, 0.05**2.3, 0.05 ** (5)][t]\n",
    "\n",
    "X, Y = multi_mnist.load(\"data/air/.data\")\n",
    "X = (torch.from_numpy(X).float() / 255.0).to(device)\n",
    "visualize_examples = X[5:10]\n",
    "# Using float to allow comparison with values sampled from\n",
    "# Bernoulli.\n",
    "true_counts = torch.tensor([len(objs) for objs in Y], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/femtomc/miniconda3/envs/pyro/lib/python3.10/site-packages/pyro/util.py:544: UserWarning: z_pres_0Found sample sites configured for enumeration:, z_pres_1Found sample sites configured for enumeration:, z_pres_2\n",
      "If you want to enumerate sites, you need to use TraceEnum_ELBO instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ac_losses, ac_accuracy, ac_wall_clock_times = None, None, None\n",
    "for train_idx in range(0, 5):\n",
    "    pyro.distributions.enable_validation(False)\n",
    "    pyro.clear_param_store()  # just in case\n",
    "\n",
    "    air = AIR(**air_model_args)\n",
    "    adam = Adam(get_per_param_lr(learning_rate, baseline_lr))\n",
    "    svi = SVI(air.model, air.guide, adam, loss=elbo)\n",
    "\n",
    "    all_loss = []\n",
    "    all_accuracy = []\n",
    "    time_per_epoch = []\n",
    "\n",
    "    for i in range(num_epoches):\n",
    "        start_time = time.perf_counter()\n",
    "        # technically this might step over slightly more than 1 epoch...\n",
    "        losses = []\n",
    "        for j in range(int(np.ceil(X.size(0) / batch_size))):\n",
    "            losses.append(\n",
    "                svi.step(X, batch_size=batch_size, z_pres_prior_p=z_pres_prior_fn)\n",
    "            )\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        accuracy, counts, error_z, error_ix = count_accuracy(X, true_counts, air, 1000)\n",
    "\n",
    "        all_loss.append(np.mean(losses) / X.size(0))\n",
    "        all_accuracy.append(accuracy)\n",
    "        time_per_epoch.append(end_time - start_time)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch={i}, current_epoch_step_time={time_per_epoch[-1]:.2f}, loss={all_loss[-1]:.2f}\"\n",
    "        )\n",
    "        print(f\"accuracy={accuracy}, counts={counts}\")\n",
    "\n",
    "    if ac_losses is None:\n",
    "        ac_losses = all_loss\n",
    "        ac_accuracy = all_accuracy\n",
    "        ac_wall_clock_times = np.cumsum(time_per_epoch)\n",
    "\n",
    "    else:\n",
    "        ac_losses = np.vstack((ac_losses, all_loss))\n",
    "        ac_accuracy = np.vstack((ac_accuracy, all_accuracy))\n",
    "        ac_wall_clock_times = np.vstack(\n",
    "            (ac_wall_clock_times, np.cumsum(time_per_epoch))\n",
    "        )\n",
    "\n",
    "    # Save run.\n",
    "    wall_clock_times = np.cumsum(time_per_epoch)\n",
    "    arr = np.array([all_loss, all_accuracy, wall_clock_times])\n",
    "    df = pd.DataFrame(\n",
    "        arr.T, columns=[\"ELBO loss\", \"Accuracy\", \"Epoch wall clock times\"]\n",
    "    )\n",
    "    df.to_csv(\n",
    "        f\"./training_runs/pyro_air_renyi_epochs_6_mccoy_prior_{train_idx}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "arr = np.array([ac_losses, ac_accuracy, ac_wall_clock_times])\n",
    "mean_arr = np.mean(arr, axis=1)\n",
    "std_arr = np.std(arr, axis=1)\n",
    "df_arr = np.vstack((mean_arr, std_arr))\n",
    "df = pd.DataFrame(\n",
    "    df_arr.T,\n",
    "    columns=[\n",
    "        \"Mean ELBO loss\",\n",
    "        \"Mean accuracy\",\n",
    "        \"Mean epoch wall clock times\",\n",
    "        \"Std ELBO loss\",\n",
    "        \"Std accuracy\",\n",
    "        \"Std epoch wall clock times\",\n",
    "    ],\n",
    ")\n",
    "df.to_csv(\n",
    "    \"./training_runs/pyro_air_rws_epochs_6_mccoy_prior.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
