{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4de0133f-4e97-401c-b216-e0bc64664444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import time\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from collections import namedtuple\n",
    "import pyro\n",
    "import optax\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "import pyro.contrib.examples.multi_mnist as multi_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from matplotlib import rcParams\n",
    "from scipy.interpolate import griddata\n",
    "import genjax\n",
    "from genjax import grasp\n",
    "\n",
    "# import sys\n",
    "# sys.setrecursionlimit(10000)\n",
    "\n",
    "console = genjax.pretty()\n",
    "\n",
    "key = jax.random.PRNGKey(314159)\n",
    "sns.set_theme(style=\"white\")\n",
    "font_path = (\n",
    "    \"/home/femtomc/.local/share/fonts/Unknown Vendor/TrueType/Lato/Lato_Bold.ttf\"\n",
    ")\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "custom_font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rcParams[\"font.family\"] = custom_font_name\n",
    "\n",
    "key = jax.random.PRNGKey(314159)\n",
    "label_fontsize = 70  # Set the desired font size here\n",
    "\n",
    "smoke_test = \"CI\" in os.environ\n",
    "assert pyro.__version__.startswith(\"1.8.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4985e835-14c9-43f0-8652-34da112dd6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size 160\u001b[0m\u001b[1;36m0x1600\u001b[0m\u001b[39m with \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inpath = \"./data/air/.data\"\n",
    "X_np, Y = multi_mnist.load(inpath)\n",
    "X_np = X_np.astype(np.float32)\n",
    "X_np /= 255.0\n",
    "mnist = jnp.array(X_np)\n",
    "true_counts = jnp.array([len(objs) for objs in Y])\n",
    "\n",
    "\n",
    "def show_images(imgs, path):\n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "    for i, img in enumerate(imgs):\n",
    "        ax = plt.subplot(1, len(imgs), i + 1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.imshow(img, cmap=\"gray_r\")\n",
    "    fig.savefig(\"./img/multimnist_sample.pdf\", format=\"pdf\")\n",
    "\n",
    "\n",
    "show_images(mnist[9:10], \"./img/multimnist_sample.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65227bc6-fd5e-486d-9cdc-0bfdf6cbde95",
   "metadata": {},
   "source": [
    "## Defining the variational ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78d35c-3e79-4ea7-95d9-82106cb22ad7",
   "metadata": {},
   "source": [
    "### Utilities / learnable pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38987718-1631-423e-8b70-95a469742beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from genjax import Pytree\n",
    "import equinox as eqx\n",
    "from genjax.typing import Any\n",
    "from genjax.typing import Tuple\n",
    "from genjax.typing import FloatArray\n",
    "from genjax.typing import Int\n",
    "from genjax.typing import IntArray\n",
    "from genjax.typing import PRNGKey\n",
    "from genjax.typing import typecheck\n",
    "\n",
    "# Utilities for defining the model and the guide.\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Decoder(Pytree):\n",
    "    dense_1: Any\n",
    "    dense_2: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense_1, self.dense_2), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key1, key2):\n",
    "        dense_1 = eqx.nn.Linear(50, 200, key=key1)\n",
    "        dense_2 = eqx.nn.Linear(200, 400, key=key2)\n",
    "        return Decoder(dense_1, dense_2)\n",
    "\n",
    "    def __call__(self, z_what):\n",
    "        v = self.dense_1(z_what)\n",
    "        v = jax.nn.leaky_relu(v)\n",
    "        v = self.dense_2(v)\n",
    "        return jax.nn.sigmoid(v)\n",
    "\n",
    "\n",
    "# Create our decoder.\n",
    "key, sub_key1, sub_key2 = jax.random.split(key, 3)\n",
    "decoder = Decoder.new(sub_key1, sub_key2)\n",
    "\n",
    "# Create our RNN for the guide.\n",
    "key, sub_key = jax.random.split(key)\n",
    "rnn = eqx.nn.LSTMCell(2554, 256, key=sub_key)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Encoder(Pytree):\n",
    "    dense_1: Any\n",
    "    dense_2: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense_1, self.dense_2), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key1, key2):\n",
    "        dense_1 = eqx.nn.Linear(400, 200, key=key1)\n",
    "        dense_2 = eqx.nn.Linear(200, 100, key=key2)\n",
    "        return Encoder(dense_1, dense_2)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        v = self.dense_1(data)\n",
    "        v = jax.nn.leaky_relu(v)\n",
    "        v = self.dense_2(v)\n",
    "        return v[0:50], jax.nn.softplus(v[50:])\n",
    "\n",
    "\n",
    "key, sub_key1, sub_key2 = jax.random.split(key, 3)\n",
    "encoder = Encoder.new(sub_key1, sub_key2)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Predict(Pytree):\n",
    "    dense: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense,), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key):\n",
    "        dense = eqx.nn.Linear(256, 7, key=key)\n",
    "        return Predict(dense)\n",
    "\n",
    "    def __call__(self, h):\n",
    "        a = self.dense(h)\n",
    "        z_pres_p = jax.nn.sigmoid(a[0:1])\n",
    "        z_where_loc = a[1:4]\n",
    "        z_where_scale = jax.nn.softplus(a[4:])\n",
    "        return z_pres_p, z_where_loc, z_where_scale\n",
    "\n",
    "\n",
    "key, sub_key = jax.random.split(key)\n",
    "predict = Predict.new(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82446361-62cd-4cec-a8aa-d76b477603d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######\n",
    "# STN #\n",
    "#######\n",
    "\n",
    "# modified from https://github.com/kevinzakka/spatial-transformer-network/blob/master/stn/transformer.py\n",
    "\n",
    "\n",
    "def affine_grid_generator(height, width, theta):\n",
    "    \"\"\"\n",
    "    This function returns a sampling grid, which when\n",
    "    used with the bilinear sampler on the input feature\n",
    "    map, will create an output feature map that is an\n",
    "    affine transformation [1] of the input feature map.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - height: desired height of grid/output. Used\n",
    "      to downsample or upsample.\n",
    "\n",
    "    - width: desired width of grid/output. Used\n",
    "      to downsample or upsample.\n",
    "\n",
    "    - theta: affine transform matrices of shape (num_batch, 2, 3).\n",
    "      For each image in the batch, we have 6 theta parameters of\n",
    "      the form (2x3) that define the affine transformation T.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - normalized grid (-1, 1) of shape (num_batch, 2, H, W).\n",
    "      The 2nd dimension has 2 components: (x, y) which are the\n",
    "      sampling points of the original image for each point in the\n",
    "      target image.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    [1]: the affine transformation allows cropping, translation,\n",
    "         and isotropic scaling.\n",
    "    \"\"\"\n",
    "    num_batch = theta.shape[0]\n",
    "\n",
    "    # create normalized 2D grid\n",
    "    x = jnp.linspace(-1.0, 1.0, width)\n",
    "    y = jnp.linspace(-1.0, 1.0, height)\n",
    "    x_t, y_t = jnp.meshgrid(x, y)\n",
    "\n",
    "    # flatten\n",
    "    x_t_flat = jnp.reshape(x_t, [-1])\n",
    "    y_t_flat = jnp.reshape(y_t, [-1])\n",
    "\n",
    "    # reshape to [x_t, y_t , 1] - (homogeneous form)\n",
    "    ones = jnp.ones_like(x_t_flat)\n",
    "    sampling_grid = jnp.stack([x_t_flat, y_t_flat, ones])\n",
    "\n",
    "    # repeat grid num_batch times\n",
    "    sampling_grid = jnp.expand_dims(sampling_grid, axis=0)\n",
    "    sampling_grid = jnp.tile(sampling_grid, [num_batch, 1, 1])\n",
    "\n",
    "    # transform the sampling grid - batch multiply\n",
    "    batch_grids = jnp.matmul(theta, sampling_grid)\n",
    "    # batch grid has shape (num_batch, 2, H*W)\n",
    "\n",
    "    # reshape to (num_batch, 2, H, W)\n",
    "    batch_grids = jnp.reshape(batch_grids, [num_batch, 2, height, width])\n",
    "\n",
    "    return batch_grids\n",
    "\n",
    "\n",
    "def bilinear_sampler(img, x, y):\n",
    "    \"\"\"\n",
    "    Performs bilinear sampling of the input images according to the\n",
    "    normalized coordinates provided by the sampling grid. Note that\n",
    "    the sampling is done identically for each channel of the input.\n",
    "\n",
    "    To test if the function works properly, output image should be\n",
    "    identical to input image when theta is initialized to identity\n",
    "    transform.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - img: batch of images in (B, H, W, C) layout.\n",
    "    - grid: x, y which is the output of affine_grid_generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - out: interpolated images according to grids. Same size as grid.\n",
    "    \"\"\"\n",
    "    H = jnp.shape(img)[1]\n",
    "    W = jnp.shape(img)[2]\n",
    "    max_y = H - 1\n",
    "    max_x = W - 1\n",
    "    zero = jnp.zeros([], dtype=int)\n",
    "\n",
    "    # rescale x and y to [0, W-1/H-1]\n",
    "    x = 0.5 * ((x + 1.0) * max_x - 1)\n",
    "    y = 0.5 * ((y + 1.0) * max_y - 1)\n",
    "\n",
    "    # grab 4 nearest corner points for each (x_i, y_i)\n",
    "    x0 = jnp.floor(x).astype(int)\n",
    "    x1 = x0 + 1\n",
    "    y0 = jnp.floor(y).astype(int)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    # clip to range [0, H-1/W-1] to not violate img boundaries\n",
    "    x0 = jnp.clip(x0, zero, max_x)\n",
    "    x1 = jnp.clip(x1, zero, max_x)\n",
    "    y0 = jnp.clip(y0, zero, max_y)\n",
    "    y1 = jnp.clip(y1, zero, max_y)\n",
    "\n",
    "    # get pixel value at corner coords\n",
    "    Ia = get_pixel_value(img, x0, y0)\n",
    "    Ib = get_pixel_value(img, x0, y1)\n",
    "    Ic = get_pixel_value(img, x1, y0)\n",
    "    Id = get_pixel_value(img, x1, y1)\n",
    "\n",
    "    # recast as float for delta calculation\n",
    "    x0 = x0.astype(float)\n",
    "    x1 = x1.astype(float)\n",
    "    y0 = y0.astype(float)\n",
    "    y1 = y1.astype(float)\n",
    "\n",
    "    # calculate deltas\n",
    "    wa = (x1 - x) * (y1 - y)\n",
    "    wb = (x1 - x) * (y - y0)\n",
    "    wc = (x - x0) * (y1 - y)\n",
    "    wd = (x - x0) * (y - y0)\n",
    "\n",
    "    # add dimension for addition\n",
    "    wa = jnp.expand_dims(wa, axis=3)\n",
    "    wb = jnp.expand_dims(wb, axis=3)\n",
    "    wc = jnp.expand_dims(wc, axis=3)\n",
    "    wd = jnp.expand_dims(wd, axis=3)\n",
    "\n",
    "    # compute output\n",
    "    out = wa * Ia + wb * Ib + wc * Ic + wd * Id\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_pixel_value(img, x, y):\n",
    "    \"\"\"\n",
    "    Utility function to get pixel value for coordinate\n",
    "    vectors x and y from a  4D tensor image.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - img: tensor of shape (B, H, W, C)\n",
    "    - x: flattened tensor of shape (B*H*W,)\n",
    "    - y: flattened tensor of shape (B*H*W,)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - output: tensor of shape (B, H, W, C)\n",
    "    \"\"\"\n",
    "    batch_size, height, width = jnp.shape(x)\n",
    "\n",
    "    batch_idx = jnp.arange(0, batch_size)\n",
    "    batch_idx = jnp.reshape(batch_idx, (batch_size, 1, 1))\n",
    "    b = jnp.tile(batch_idx, (1, height, width))\n",
    "\n",
    "    indices = jnp.stack([b, y, x], 3)\n",
    "\n",
    "    return gather_nd(img, indices)\n",
    "\n",
    "\n",
    "# from: https://github.com/google/jax/discussions/6119\n",
    "def gather_nd_unbatched(params, indices):\n",
    "    return params[tuple(jnp.moveaxis(indices, -1, 0))]\n",
    "\n",
    "\n",
    "def gather_nd(params, indices, batch=False):\n",
    "    if not batch:\n",
    "        return gather_nd_unbatched(params, indices)\n",
    "    else:\n",
    "        return vmap(gather_nd_unbatched, (0, 0), 0)(params, indices)\n",
    "\n",
    "\n",
    "def expand_z_where(z_where):\n",
    "    # Takes 3-dimensional vectors, and massages them into 2x3 matrices with elements like so:\n",
    "    # [s,x,y] -> [[s,0,x],\n",
    "    #             [0,s,y]]\n",
    "    n = 1\n",
    "    expansion_indices = jnp.array([1, 0, 2, 0, 1, 3])\n",
    "    z_where = jnp.expand_dims(z_where, axis=0)\n",
    "    out = jnp.concatenate((jnp.broadcast_to(jnp.zeros([1, 1]), (n, 1)), z_where), 1)\n",
    "    return jnp.reshape(out[:, expansion_indices], (n, 2, 3))\n",
    "\n",
    "\n",
    "def object_to_image(z_where, obj):\n",
    "    n = 1\n",
    "    theta = expand_z_where(z_where)\n",
    "    grid = affine_grid_generator(50, 50, theta)\n",
    "    x_s = grid[:, 0, :, :]\n",
    "    y_s = grid[:, 1, :, :]\n",
    "    out = bilinear_sampler(jnp.reshape(obj, (n, 20, 20, 1)), x_s, y_s)\n",
    "    return jnp.reshape(out, (50, 50))\n",
    "\n",
    "\n",
    "def z_where_inv(z_where):\n",
    "    # Take a batch of z_where vectors, and compute their \"inverse\".\n",
    "    # That is, for each row compute:\n",
    "    # [s,x,y] -> [1/s,-x/s,-y/s]\n",
    "    # These are the parameters required to perform the inverse of the\n",
    "    # spatial transform performed in the generative model.\n",
    "    n = 1\n",
    "    out = jnp.array([1, *(-z_where[1:])])\n",
    "    out = out / z_where[0]\n",
    "    return out\n",
    "\n",
    "\n",
    "def image_to_object(z_where, image):\n",
    "    n = 1\n",
    "    theta_inv = expand_z_where(z_where_inv(z_where))\n",
    "    grid = affine_grid_generator(20, 20, theta_inv)\n",
    "    x_s = grid[:, 0, :, :]\n",
    "    y_s = grid[:, 1, :, :]\n",
    "    out = bilinear_sampler(jnp.reshape(image, (n, 50, 50, 1)), x_s, y_s)\n",
    "    return jnp.reshape(out, (400,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6179494f-ccc0-449f-8fcc-7bb48b4783e9",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60196b16-596f-4b7d-b040-85b8a2808423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########\n",
    "# Model #\n",
    "#########\n",
    "\n",
    "# Fixed constants.\n",
    "z_where_prior_loc = jnp.array([3.0, 0.0, 0.0])\n",
    "z_where_prior_scale = jnp.array([0.2, 1.0, 1.0])\n",
    "z_what_prior_loc = jnp.zeros(50, dtype=float)\n",
    "z_what_prior_scale = jnp.ones(50, dtype=float)\n",
    "z_pres_prior = [0.05, 0.05**2.3, 0.05 ** (5)]\n",
    "eps = 1e-4\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def step(\n",
    "    t: Int,\n",
    "    decoder: Decoder,\n",
    "    prev_x: FloatArray,\n",
    "    prev_z_pres: IntArray,\n",
    "):\n",
    "    z_pres = grasp.flip_mvd(z_pres_prior[t]) @ f\"z_pres_{t}\"\n",
    "    z_pres = jnp.array([z_pres.astype(int)])\n",
    "    z_where = (\n",
    "        grasp.mv_normal_diag_reparam(z_where_prior_loc, z_where_prior_scale)\n",
    "        @ f\"z_where_{t}\"\n",
    "    )\n",
    "    z_what = (\n",
    "        grasp.mv_normal_diag_reparam(z_what_prior_loc, z_what_prior_scale)\n",
    "        @ f\"z_what_{t}\"\n",
    "    )\n",
    "    y_att = decoder(z_what)\n",
    "    y = object_to_image(z_where, y_att)\n",
    "    x = prev_x + (y * z_pres)\n",
    "    return x, z_pres\n",
    "\n",
    "\n",
    "# TODO: Make sure that this works, where t is a static int.\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def model(decoder: Decoder):\n",
    "    x = jnp.zeros((50, 50), dtype=float)\n",
    "    z_pres = jnp.ones(1, dtype=int)\n",
    "    for t in range(3):\n",
    "        x, z_pres = step.inline(t, decoder, x, z_pres)\n",
    "    obs = grasp.mv_normal_diag_reparam(x, 0.3 * jnp.ones_like(x)) @ \"obs\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee69ad5-2136-4933-ad71-42f01483dab6",
   "metadata": {},
   "source": [
    "#### Samples from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41747dee-44a0-4cd6-8087-4ce4d526fcee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size 160\u001b[0m\u001b[1;36m0x1600\u001b[0m\u001b[39m with \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr = jax.jit(model.simulate)(key, (decoder,))\n",
    "tr.strip()[\"obs\"]\n",
    "show_images([tr.strip()[\"obs\"]], \"./img/untrained_decoder_sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8394159-926b-4607-8df0-bbcc49657ae0",
   "metadata": {},
   "source": [
    "### Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33dd2fbf-df45-4e48-ac82-9d005ffaab01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########\n",
    "# Guide #\n",
    "#########\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def guide_step(\n",
    "    t: Int,\n",
    "    rnn: eqx.nn.LSTMCell,\n",
    "    encoder: Encoder,\n",
    "    predict: Predict,\n",
    "    data,\n",
    "    prev: Tuple,\n",
    "):\n",
    "    (prev_z_where, prev_z_what, prev_z_pres, prev_h, prev_c) = prev\n",
    "    rnn_input = jnp.concatenate([data, prev_z_where, prev_z_what, prev_z_pres])\n",
    "    h, c = rnn(rnn_input, (prev_h, prev_c))\n",
    "    z_pres_p, z_where_loc, z_where_scale = predict(h)\n",
    "    if t < 2:\n",
    "        z_pres = (\n",
    "            grasp.flip_mvd((eps + (z_pres_p[0] * prev_z_pres[0])) / (1 + 1.01 * eps))\n",
    "            @ f\"z_pres_{t}\"\n",
    "        )\n",
    "    else:\n",
    "        z_pres = (\n",
    "            grasp.flip_enum((eps + (z_pres_p[0] * prev_z_pres[0])) / (1 + 1.01 * eps))\n",
    "            @ f\"z_pres_{t}\"\n",
    "        )\n",
    "    z_pres = jnp.array([z_pres.astype(int)])\n",
    "    z_where = grasp.mv_normal_diag_reparam(z_where_loc, z_where_scale) @ f\"z_where_{t}\"\n",
    "    x_att = image_to_object(z_where, data)\n",
    "    z_what_loc, z_what_scale = encoder(x_att)\n",
    "    z_what = grasp.mv_normal_diag_reparam(z_what_loc, z_what_scale) @ f\"z_what_{t}\"\n",
    "    return z_where, z_what, z_pres, h, c\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def guide(\n",
    "    data: genjax.ChoiceMap,\n",
    "    rnn: eqx.nn.LSTMCell,\n",
    "    encoder: Encoder,\n",
    "    predict: Predict,\n",
    "):\n",
    "    h = jnp.zeros(256)\n",
    "    c = jnp.zeros(256)\n",
    "    z_pres = jnp.ones(1)\n",
    "    z_where = jnp.zeros(3)\n",
    "    z_what = jnp.zeros(50)\n",
    "    img = data[\"obs\"]\n",
    "    img_arr = img.flatten()\n",
    "\n",
    "    for t in range(3):\n",
    "        (z_where, z_what, z_pres, h, c) = guide_step.inline(\n",
    "            t, rnn, encoder, predict, img_arr, (z_where, z_what, z_pres, h, c)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89bc83-29fc-4e0e-a47d-dab2acf0c920",
   "metadata": {},
   "source": [
    "#### Samples from the guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2984c5cc-2b4c-40f5-ad0c-a2c3d1508f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HierarchicalChoiceMap(trie=Trie(inner={'z_pres_1': ValueChoiceMap(value=Array(False, dtype=bool)), 'z_pres_2': ValueChoiceMap(value=Array(False, dtype=bool)), 'z_what_2': ValueChoiceMap(value=Array([-0.7563535 , -0.5560635 , -0.9204618 , -0.61099297,  1.014627  ,\n",
       "       -0.01130345, -0.9693465 ,  0.55129814,  0.36503673,  1.4565327 ,\n",
       "       -0.4586871 , -0.9269917 ,  0.24080203, -1.198578  , -0.07862899,\n",
       "        0.01840574, -0.26913756,  0.14130455, -0.6308354 ,  0.18834774,\n",
       "        0.254622  , -0.06821783,  0.6445953 ,  0.25769955, -2.19528   ,\n",
       "       -1.1944966 ,  0.25967628,  0.9230258 , -0.51576495,  0.54903054,\n",
       "       -0.55522805, -0.04275857, -0.29936537,  1.2488425 ,  0.15674056,\n",
       "       -1.3280201 ,  1.0915332 ,  1.7575338 , -1.954208  , -1.0189402 ,\n",
       "       -0.38184005,  0.9597785 , -0.2884629 ,  0.20048147, -0.4347161 ,\n",
       "        0.16963404,  0.20817302,  0.7766751 , -0.26632208,  0.788477  ],      dtype=float32)), 'z_pres_0': ValueChoiceMap(value=Array(True, dtype=bool)), 'z_where_2': ValueChoiceMap(value=Array([1.44559   , 0.09122826, 0.39324838], dtype=float32)), 'z_where_0': ValueChoiceMap(value=Array([0.09956367, 0.09166238, 0.32089818], dtype=float32)), 'z_what_1': ValueChoiceMap(value=Array([ 0.28533778,  0.23240612,  1.1141031 , -1.4708029 , -1.2096852 ,\n",
       "        0.1109131 ,  1.096025  ,  0.24259521,  0.04918501,  0.19510692,\n",
       "       -0.3246457 , -0.97456014, -0.6143923 ,  0.31112543, -0.7887806 ,\n",
       "        0.5744175 ,  0.42786384, -0.44608492,  0.00485791,  0.92352664,\n",
       "        1.4681247 , -0.46926802, -0.03972865,  0.6573736 ,  0.72535384,\n",
       "        0.3554429 , -0.8276328 ,  0.2890175 ,  0.9251094 ,  0.82354915,\n",
       "        0.3087606 ,  0.07287456,  0.70088756, -0.11380291, -0.7555343 ,\n",
       "       -0.22621061, -0.59625006,  1.7082508 , -1.6051453 , -0.64945155,\n",
       "        0.2881873 ,  0.30688164, -0.22641243, -0.5690918 , -0.91161823,\n",
       "        1.6785119 ,  0.12905215,  0.16686247,  0.09736616,  0.7763717 ],      dtype=float32)), 'z_where_1': ValueChoiceMap(value=Array([ 1.3117653,  0.5462594, -0.6296631], dtype=float32)), 'z_what_0': ValueChoiceMap(value=Array([ 0.47881928, -0.6001495 , -0.07596396, -0.46712643, -0.6377853 ,\n",
       "        0.4880015 , -0.0026071 , -0.0648842 ,  0.68812644,  0.55307406,\n",
       "        1.4098706 , -1.0631292 , -0.40985143,  1.1942633 , -0.6337316 ,\n",
       "        0.90972066, -0.7271465 , -0.3805505 , -0.08980705, -0.8501938 ,\n",
       "        0.43871439,  0.5818898 ,  0.29893732,  0.57461274, -0.11380556,\n",
       "        0.41587007,  0.20875463,  0.9551446 ,  0.2335587 ,  0.05214904,\n",
       "        0.95153826,  0.15101334,  0.06873246,  0.2672779 ,  0.7856569 ,\n",
       "       -1.0018222 , -0.40071332,  0.05744316, -0.86725295, -0.23935616,\n",
       "        0.37568498,  0.7159259 , -0.02495935,  0.5464951 ,  0.6715891 ,\n",
       "       -1.0317073 ,  0.23442937, -0.37587446,  0.4990818 ,  0.46639284],      dtype=float32))}))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_chm = genjax.choice_map({\"obs\": jnp.ones((50, 50))})\n",
    "tr = jax.jit(guide.simulate)(key, (data_chm, rnn, encoder, predict))\n",
    "tr.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b2f0a-dee4-470d-8bfa-c71a9e466690",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32a7cd-d44b-46dd-bea2-8ddac55aa88a",
   "metadata": {},
   "source": [
    "### Make sure grads are working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc1805-57c9-4c44-8ace-2b0fa068c9c7",
   "metadata": {},
   "source": [
    "#### Define ELBO objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "435472dd-c312-4f5f-8fc4-f2c0125491ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Expectation(prog=ADEVProgram(source=<function elbo.<locals>.elbo_loss at 0x7fb49c120a60>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = genjax.choice_map({\"obs\": jnp.ones((50, 50))})\n",
    "objective = grasp.elbo(model, guide, data)\n",
    "objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860fc0c2-6adb-4d7d-8ab1-0c1fccc16a65",
   "metadata": {},
   "source": [
    "#### Go go grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1ec3a5-e506-41bb-9a97-0c13bcbfb108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jitted = jax.jit(objective.value_and_grad_estimate)\n",
    "loss, ((decoder_grads,), (_, rnn_grads, encoder_grads, predict_grads)) = jitted(\n",
    "    key, ((decoder,), (data, rnn, encoder, predict))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817c347c-fdff-4822-9091-2d58887f5baa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-13631.814, dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf5b4af-8df8-4bca-b0f2-c576dd0ba659",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdf9c5ed-4369-4a68-8ce8-af7754576fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_loader(\n",
    "    data,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "):\n",
    "    N = len(data)\n",
    "    data_idxs = np.arange(N)\n",
    "    num_batch = int(np.ceil(N // batch_size))\n",
    "\n",
    "    def init(key):\n",
    "        return (\n",
    "            num_batch,\n",
    "            jax.random.permutation(key, data_idxs) if shuffle else data_idxs,\n",
    "        )\n",
    "\n",
    "    def get_batch(i=0, idxs=data_idxs):\n",
    "        ret_idx = jax.lax.dynamic_slice_in_dim(idxs, i * batch_size, batch_size)\n",
    "        return jax.lax.index_take(data, (ret_idx,), axes=(0,))\n",
    "\n",
    "    return init, get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bce54cb-d22a-43b8-b296-6067484552d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Count Accuracy #\n",
    "##################\n",
    "\n",
    "\n",
    "def count_accuracy(data, true_counts, guide, batch_size=1000):\n",
    "    global prng_key\n",
    "    assert data.shape[0] == true_counts.shape[0], \"Size mismatch.\"\n",
    "    assert data.shape[0] % batch_size == 0, \"Input size must be multiple of batch_size.\"\n",
    "\n",
    "    def eval_guide(key, data, params):\n",
    "        data_chmp = genjax.choice_map({\"obs\": data})\n",
    "        return guide.simulate(key, (data_chmp, *params))\n",
    "\n",
    "    batch_eval_guide = jax.jit(jax.vmap(eval_guide, in_axes=(0, 0, None)))\n",
    "\n",
    "    @jax.jit\n",
    "    def evaluate_count_accuracy(key, params):\n",
    "        def evaluate_batch(counts, batch_id):\n",
    "            data_batch = jax.lax.dynamic_slice_in_dim(\n",
    "                data, batch_id * batch_size, batch_size\n",
    "            )\n",
    "            true_counts_batch = jax.lax.dynamic_slice_in_dim(\n",
    "                true_counts, batch_id * batch_size, batch_size\n",
    "            )\n",
    "            data_chmp = genjax.choice_map({\"obs\": data_batch})\n",
    "            # evaluate guide\n",
    "            keys = jax.random.split(jax.random.fold_in(key, batch_id), batch_size)\n",
    "            tr = batch_eval_guide(keys, data_batch, params)\n",
    "            z_where = [tr[f\"z_where_{i}\"] for i in range(3)]\n",
    "            z_pres = [tr[f\"z_pres_{i}\"] for i in range(3)]\n",
    "            # compute stats\n",
    "            inferred_counts = sum(z for z in z_pres)\n",
    "            true_counts_m = jax.nn.one_hot(true_counts_batch, 3)\n",
    "            inferred_counts_m = jax.nn.one_hot(inferred_counts, 4)\n",
    "            counts += (true_counts_m.T @ inferred_counts_m).astype(int)\n",
    "            error_ind = 1 - (true_counts_batch == inferred_counts).astype(int)\n",
    "            # error_ix = error_ind.nonzero()[0]\n",
    "            # error_latent = jnp.take(latents_to_tensor((z_where, z_pres)), error_ix, 0)\n",
    "            return counts, error_ind\n",
    "\n",
    "        counts = jnp.zeros((3, 4), dtype=int)\n",
    "        counts, error_indices = jax.lax.scan(\n",
    "            evaluate_batch, counts, jnp.arange(data.shape[0] // batch_size)\n",
    "        )\n",
    "\n",
    "        acc = jnp.sum(jnp.diag(counts)).astype(float) / data.shape[0]\n",
    "        error_indices = jnp.concatenate(\n",
    "            error_indices\n",
    "        )  # .nonzero()[0]  # <- not JIT compilable\n",
    "        return acc, counts, error_indices\n",
    "\n",
    "    return evaluate_count_accuracy\n",
    "\n",
    "\n",
    "# Combine z_pres and z_where (as returned by the model and guide) into\n",
    "# a single tensor, with size:\n",
    "# [batch_size, num_steps, z_where_size + z_pres_size]\n",
    "def latents_to_tensor(z):\n",
    "    return jnp.stack(\n",
    "        [\n",
    "            jnp.concatenate((z_where, z_pres.reshape(-1, 1)), 1)\n",
    "            for z_where, z_pres in zip(*z)\n",
    "        ]\n",
    "    ).transpose(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3660daf7-584d-4fd9-a26b-371d32fb5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Visualization  #\n",
    "##################\n",
    "\n",
    "\n",
    "def bounding_box(z_where, x_size):\n",
    "    \"\"\"This doesn't take into account interpolation, but it's close\n",
    "    enough to be usable.\"\"\"\n",
    "    w = x_size / z_where.s\n",
    "    h = x_size / z_where.s\n",
    "    xtrans = -z_where.x / z_where.s * x_size / 2.0\n",
    "    ytrans = -z_where.y / z_where.s * x_size / 2.0\n",
    "    x = (x_size - w) / 2 + xtrans  # origin is top left\n",
    "    y = (x_size - h) / 2 + ytrans\n",
    "    return (x, y), w, h\n",
    "\n",
    "\n",
    "z_obj = namedtuple(\"z\", [\"s\", \"x\", \"y\", \"pres\"])\n",
    "\n",
    "\n",
    "# Map a tensor of latents (as produced by latents_to_tensor) to a list\n",
    "# of z_obj named tuples.\n",
    "def tensor_to_objs(latents):\n",
    "    return [[z_obj._make(step) for step in z] for z in latents]\n",
    "\n",
    "\n",
    "def visualize_model(model, guide):\n",
    "    def reconstruct_digits(key, data, params):\n",
    "        decoder, rnn, encoder, predict = params\n",
    "        data_chmp = genjax.choice_map({\"obs\": data})\n",
    "        key1, key2 = jax.random.split(key)\n",
    "        tr = guide.simulate(key1, (data_chmp, rnn, encoder, predict))\n",
    "        _, tr = model.importance(key2, tr, (decoder,))\n",
    "        reconstruction = tr.get_retval()\n",
    "        z_where = [tr[f\"z_where_{i}\"] for i in range(3)]\n",
    "        z_pres = [tr[f\"z_pres_{i}\"] for i in range(3)]\n",
    "        return reconstruction, (z_where, z_pres)\n",
    "\n",
    "    batch_reconstruct_digits = jax.jit(\n",
    "        jax.vmap(reconstruct_digits, in_axes=(0, 0, None))\n",
    "    )\n",
    "\n",
    "    def visualize(key, params, examples_to_viz):\n",
    "        keys = jax.random.split(key, examples_to_viz.shape[0])\n",
    "        recons, z = batch_reconstruct_digits(keys, examples_to_viz, params)\n",
    "        z_wheres = tensor_to_objs(latents_to_tensor(z))\n",
    "        draw_many(examples_to_viz.reshape(-1, 50, 50), z_wheres, title=\"Original\")\n",
    "        draw_many(recons, z_wheres, title=\"Reconstruction\")\n",
    "\n",
    "    return visualize\n",
    "\n",
    "\n",
    "def colors(k):\n",
    "    return [\"r\", \"g\", \"b\"][k % 3]\n",
    "\n",
    "\n",
    "def draw_one(img, z):\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img, cmap=\"gray_r\")\n",
    "    for k, z in enumerate(z):\n",
    "        if z.pres > 0:\n",
    "            (x, y), w, h = bounding_box(z, img.shape[0])\n",
    "            plt.gca().add_patch(\n",
    "                Rectangle(\n",
    "                    (x, y), w, h, linewidth=1, edgecolor=colors(k), facecolor=\"none\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "def draw_many(imgs, zs, title):\n",
    "    plt.figure(figsize=(8, 1.9))\n",
    "    plt.title(title)\n",
    "    plt.tick_params(left=False, labelleft=False, bottom=False, labelbottom=False)\n",
    "    plt.box(False)\n",
    "    for i, (img, z) in enumerate(zip(imgs, zs)):\n",
    "        plt.subplot(1, len(imgs), i + 1)\n",
    "        draw_one(img, z)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da48a46a-fdb1-4b8d-b4e5-d96d27b898d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (decoder, rnn, encoder, predict)\n",
    "evaluate_accuracy = count_accuracy(mnist, true_counts, guide, batch_size=1000)\n",
    "\n",
    "visualize_examples = mnist[5:10]\n",
    "visualize = visualize_model(model, guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaf743cf-aa9e-44db-9078-6a89f1d26f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(key, n=1, num_epochs=200, batch_size=64, learning_rate=1.0e-3):\n",
    "    def svi_update(model, guide, optimiser):\n",
    "        def batch_updater(key, params, opt_state, data_batch):\n",
    "            def grads(key, params, data):\n",
    "                (decoder, rnn, encoder, predict) = params\n",
    "                data = genjax.choice_map({\"obs\": data})\n",
    "                objective = grasp.iwae_elbo(model, guide, data, n)\n",
    "                loss, (\n",
    "                    (decoder_grads,),\n",
    "                    (_, rnn_grads, encoder_grads, predict_grads),\n",
    "                ) = objective.value_and_grad_estimate(\n",
    "                    key, ((decoder,), (data, rnn, encoder, predict))\n",
    "                )\n",
    "                return loss, (decoder_grads, rnn_grads, encoder_grads, predict_grads)\n",
    "\n",
    "            sub_keys = jax.random.split(key, len(data_batch))\n",
    "            loss, (decoder_grads, rnn_grads, encoder_grads, predict_grads) = jax.vmap(\n",
    "                grads, in_axes=(0, None, 0)\n",
    "            )(sub_keys, params, data_batch)\n",
    "\n",
    "            grads = jtu.tree_map(\n",
    "                lambda v: -1.0 * jnp.mean(v, axis=0),\n",
    "                (decoder_grads, rnn_grads, encoder_grads, predict_grads),\n",
    "            )\n",
    "            updates, opt_state = optimiser.update(grads, opt_state, params)\n",
    "            params = optax.apply_updates(params, updates)\n",
    "            loss = jnp.mean(loss)\n",
    "            return params, opt_state, loss\n",
    "\n",
    "        return batch_updater\n",
    "\n",
    "    adam = optax.adam(learning_rate)\n",
    "    svi_updater = svi_update(model, guide, adam)\n",
    "\n",
    "    @jax.jit\n",
    "    def epoch_train(opt_state, params, key, train_idx):\n",
    "        def body_fn(carry, xs):\n",
    "            idx, params, opt_state, loss = carry\n",
    "            updater_key = jax.random.fold_in(key, idx)\n",
    "            batch = train_fetch(idx, train_idx)\n",
    "            params, opt_state, loss = svi_updater(updater_key, params, opt_state, batch)\n",
    "            idx += 1\n",
    "            return (idx, params, opt_state, loss), loss\n",
    "\n",
    "        idx = 0\n",
    "        (_, params, opt_state, _), losses = jax.lax.scan(\n",
    "            body_fn, (idx, params, opt_state, 0.0), None, length=num_batch\n",
    "        )\n",
    "        return params, opt_state, losses\n",
    "\n",
    "    # Train.\n",
    "    params = (decoder, rnn, encoder, predict)\n",
    "    opt_state = adam.init(params)\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    acc_time = 0.0\n",
    "    wall_clock_times = []\n",
    "    train_init, train_fetch = data_loader(jnp.array(mnist), batch_size)\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    num_batch, train_idx = train_init(sub_key)\n",
    "\n",
    "    # Warm up.\n",
    "    _ = epoch_train(opt_state, params, key, train_idx)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    acc_time = 0.0\n",
    "    for i in range(0, num_epochs + 1):\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        num_batch, train_idx = train_init(sub_key)\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        start = time.perf_counter() - t0\n",
    "        params, opt_state, loss = epoch_train(opt_state, params, sub_key, train_idx)\n",
    "        stop = time.perf_counter() - t0\n",
    "        acc_time += stop - start\n",
    "        losses.append(jnp.mean(loss))\n",
    "        wall_clock_times.append(acc_time)\n",
    "        acc, counts, error_ix = evaluate_accuracy(sub_key, params[1:])\n",
    "        accuracy.append(acc)\n",
    "        print(\n",
    "            f\"Epoch={i}, total_epoch_step_time={acc_time:.2f}, loss={jnp.mean(loss):.2f}\"\n",
    "        )\n",
    "        print(\"accuracy={}, counts={}\".format(acc, counts))\n",
    "\n",
    "    return losses, accuracy, wall_clock_times, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24322557-5242-4358-91c8-ca0dd0cf4b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, total_epoch_step_time=1.83, loss=-7.51\n",
      "accuracy=0.22339999675750732, counts=[[11258  8022   665     3]\n",
      " [17857  2144    19     0]\n",
      " [19569   461     2     0]]\n",
      "Epoch=1, total_epoch_step_time=3.69, loss=402.57\n",
      "accuracy=0.22243332862854004, counts=[[11556  7740   646     6]\n",
      " [18214  1790    16     0]\n",
      " [19615   417     0     0]]\n",
      "Epoch=2, total_epoch_step_time=5.54, loss=422.66\n",
      "accuracy=0.22503334283828735, counts=[[11898  7317   724     9]\n",
      " [18399  1604    17     0]\n",
      " [19604   428     0     0]]\n",
      "Epoch=3, total_epoch_step_time=7.49, loss=440.87\n",
      "accuracy=0.23783333599567413, counts=[[12764  6589   585    10]\n",
      " [18497  1506    17     0]\n",
      " [19649   383     0     0]]\n",
      "Epoch=4, total_epoch_step_time=9.44, loss=453.24\n",
      "accuracy=0.24801667034626007, counts=[[13498  6013   430     7]\n",
      " [18627  1383    10     0]\n",
      " [19667   365     0     0]]\n",
      "Epoch=5, total_epoch_step_time=11.30, loss=456.91\n",
      "accuracy=0.25665000081062317, counts=[[14204  5449   294     1]\n",
      " [18817  1195     8     0]\n",
      " [19713   319     0     0]]\n",
      "Epoch=6, total_epoch_step_time=13.27, loss=458.20\n",
      "accuracy=0.2707666754722595, counts=[[15175  4591   180     2]\n",
      " [18945  1071     4     0]\n",
      " [19707   325     0     0]]\n",
      "Epoch=7, total_epoch_step_time=15.14, loss=459.10\n",
      "accuracy=0.287200003862381, counts=[[16029  3777   142     0]\n",
      " [18810  1200    10     0]\n",
      " [19587   442     3     0]]\n",
      "Epoch=8, total_epoch_step_time=17.11, loss=459.77\n",
      "accuracy=0.3140333294868469, counts=[[16492  3309   145     2]\n",
      " [17651  2318    51     0]\n",
      " [18245  1755    32     0]]\n",
      "Epoch=9, total_epoch_step_time=19.06, loss=472.88\n",
      "accuracy=0.5804166793823242, counts=[[16472  3270   204     2]\n",
      " [ 2040  7624  9269  1087]\n",
      " [  297  1790 10729  7216]]\n",
      "Epoch=10, total_epoch_step_time=20.99, loss=517.90\n",
      "accuracy=0.8637499809265137, counts=[[18004  1932    12     0]\n",
      " [  495 16407  3105    13]\n",
      " [   10  2192 17414   416]]\n",
      "Epoch=11, total_epoch_step_time=22.93, loss=546.83\n",
      "accuracy=0.9135833382606506, counts=[[19233   714     1     0]\n",
      " [  332 17008  2676     4]\n",
      " [    3  1280 18574   175]]\n",
      "Epoch=12, total_epoch_step_time=24.85, loss=566.56\n",
      "accuracy=0.9345166683197021, counts=[[19674   274     0     0]\n",
      " [  230 17435  2353     2]\n",
      " [    0   971 18962    99]]\n",
      "Epoch=13, total_epoch_step_time=26.85, loss=580.85\n",
      "accuracy=0.9462000131607056, counts=[[19807   141     0     0]\n",
      " [  162 17844  2013     1]\n",
      " [    0   855 19121    56]]\n",
      "Epoch=14, total_epoch_step_time=28.85, loss=588.93\n",
      "accuracy=0.9541333317756653, counts=[[19857    91     0     0]\n",
      " [  134 18218  1667     1]\n",
      " [    0   818 19173    41]]\n",
      "Epoch=15, total_epoch_step_time=30.80, loss=595.86\n",
      "accuracy=0.9601666927337646, counts=[[19897    51     0     0]\n",
      " [  114 18590  1315     1]\n",
      " [    1   883 19123    25]]\n",
      "Epoch=16, total_epoch_step_time=32.75, loss=600.74\n",
      "accuracy=0.9631833434104919, counts=[[19906    42     0     0]\n",
      " [   79 18687  1252     2]\n",
      " [    0   811 19198    23]]\n",
      "Epoch=17, total_epoch_step_time=34.68, loss=605.04\n",
      "accuracy=0.9683666825294495, counts=[[19922    26     0     0]\n",
      " [   67 19105   847     1]\n",
      " [    0   943 19075    14]]\n",
      "Epoch=18, total_epoch_step_time=36.62, loss=608.60\n",
      "accuracy=0.9701833724975586, counts=[[19924    24     0     0]\n",
      " [   57 19015   948     0]\n",
      " [    0   744 19272    16]]\n",
      "Epoch=19, total_epoch_step_time=38.52, loss=611.54\n",
      "accuracy=0.9730666875839233, counts=[[19924    24     0     0]\n",
      " [   55 19307   658     0]\n",
      " [    0   866 19153    13]]\n",
      "Epoch=20, total_epoch_step_time=40.47, loss=613.95\n",
      "accuracy=0.9738500118255615, counts=[[19927    21     0     0]\n",
      " [   43 19242   735     0]\n",
      " [    0   760 19262    10]]\n",
      "Epoch=21, total_epoch_step_time=42.47, loss=616.08\n",
      "accuracy=0.9751333594322205, counts=[[19930    18     0     0]\n",
      " [   39 19336   645     0]\n",
      " [    0   779 19242    11]]\n",
      "Epoch=22, total_epoch_step_time=44.66, loss=617.88\n",
      "accuracy=0.9774500131607056, counts=[[19934    14     0     0]\n",
      " [   32 19446   542     0]\n",
      " [    0   757 19267     8]]\n",
      "Epoch=23, total_epoch_step_time=46.68, loss=619.51\n",
      "accuracy=0.9781166911125183, counts=[[19936    12     0     0]\n",
      " [   32 19422   566     0]\n",
      " [    0   693 19329    10]]\n",
      "Epoch=24, total_epoch_step_time=48.71, loss=620.89\n",
      "accuracy=0.9782666563987732, counts=[[19935    13     0     0]\n",
      " [   36 19437   547     0]\n",
      " [    0   700 19324     8]]\n",
      "Epoch=25, total_epoch_step_time=50.71, loss=622.33\n",
      "accuracy=0.9796500205993652, counts=[[19939     9     0     0]\n",
      " [   26 19475   519     0]\n",
      " [    0   657 19365    10]]\n",
      "Epoch=26, total_epoch_step_time=52.96, loss=623.43\n",
      "accuracy=0.9796333312988281, counts=[[19931    17     0     0]\n",
      " [   20 19453   547     0]\n",
      " [    0   629 19394     9]]\n",
      "Epoch=27, total_epoch_step_time=55.48, loss=624.53\n",
      "accuracy=0.9806666970252991, counts=[[19940     8     0     0]\n",
      " [   28 19506   486     0]\n",
      " [    0   632 19394     6]]\n",
      "Epoch=28, total_epoch_step_time=57.71, loss=625.54\n",
      "accuracy=0.9800500273704529, counts=[[19940     8     0     0]\n",
      " [   15 19562   443     0]\n",
      " [    0   724 19301     7]]\n",
      "Epoch=29, total_epoch_step_time=59.79, loss=626.44\n",
      "accuracy=0.9812833666801453, counts=[[19938    10     0     0]\n",
      " [   13 19553   454     0]\n",
      " [    0   638 19386     8]]\n",
      "Epoch=30, total_epoch_step_time=62.07, loss=627.30\n",
      "accuracy=0.9814333319664001, counts=[[19942     6     0     0]\n",
      " [   18 19503   499     0]\n",
      " [    0   584 19441     7]]\n",
      "Epoch=31, total_epoch_step_time=64.08, loss=628.06\n",
      "accuracy=0.9815999865531921, counts=[[19937    11     0     0]\n",
      " [   11 19515   494     0]\n",
      " [    0   581 19444     7]]\n",
      "Epoch=32, total_epoch_step_time=66.16, loss=628.75\n",
      "accuracy=0.9819499850273132, counts=[[19939     9     0     0]\n",
      " [   15 19530   475     0]\n",
      " [    0   578 19448     6]]\n",
      "Epoch=33, total_epoch_step_time=68.12, loss=629.45\n",
      "accuracy=0.9819333553314209, counts=[[19941     7     0     0]\n",
      " [   17 19513   490     0]\n",
      " [    0   565 19462     5]]\n",
      "Epoch=34, total_epoch_step_time=70.06, loss=630.14\n",
      "accuracy=0.9826333522796631, counts=[[19943     5     0     0]\n",
      " [   16 19530   474     0]\n",
      " [    0   541 19485     6]]\n",
      "Epoch=35, total_epoch_step_time=71.94, loss=630.68\n",
      "accuracy=0.9820833206176758, counts=[[19940     8     0     0]\n",
      " [   14 19582   424     0]\n",
      " [    0   621 19403     8]]\n",
      "Epoch=36, total_epoch_step_time=73.88, loss=631.26\n",
      "accuracy=0.9825833439826965, counts=[[19945     3     0     0]\n",
      " [    5 19522   493     0]\n",
      " [    0   538 19488     6]]\n",
      "Epoch=37, total_epoch_step_time=75.99, loss=631.80\n",
      "accuracy=0.9827666878700256, counts=[[19943     5     0     0]\n",
      " [    7 19597   416     0]\n",
      " [    0   599 19426     7]]\n",
      "Epoch=38, total_epoch_step_time=78.20, loss=632.36\n",
      "accuracy=0.9828500151634216, counts=[[19940     8     0     0]\n",
      " [    9 19559   452     0]\n",
      " [    0   552 19472     8]]\n",
      "Epoch=39, total_epoch_step_time=80.33, loss=632.77\n",
      "accuracy=0.9831333160400391, counts=[[19940     8     0     0]\n",
      " [    8 19607   405     0]\n",
      " [    0   583 19441     8]]\n",
      "Epoch=40, total_epoch_step_time=82.26, loss=633.20\n",
      "accuracy=0.9828833341598511, counts=[[19945     3     0     0]\n",
      " [    8 19609   402     1]\n",
      " [    0   606 19419     7]]\n",
      "Epoch=0, total_epoch_step_time=1.84, loss=-4.03\n",
      "accuracy=0.2227500081062317, counts=[[11237  7989   712    10]\n",
      " [17876  2128    16     0]\n",
      " [19596   436     0     0]]\n",
      "Epoch=1, total_epoch_step_time=4.06, loss=402.94\n",
      "accuracy=0.22558332979679108, counts=[[11589  7609   745     5]\n",
      " [18055  1944    21     0]\n",
      " [19551   479     2     0]]\n",
      "Epoch=2, total_epoch_step_time=6.00, loss=423.11\n",
      "accuracy=0.22830000519752502, counts=[[11944  7222   774     8]\n",
      " [18255  1753    12     0]\n",
      " [19483   548     1     0]]\n",
      "Epoch=3, total_epoch_step_time=7.96, loss=441.47\n",
      "accuracy=0.2384166717529297, counts=[[12693  6659   587     9]\n",
      " [18389  1612    19     0]\n",
      " [19523   509     0     0]]\n",
      "Epoch=4, total_epoch_step_time=9.89, loss=453.42\n",
      "accuracy=0.25058335065841675, counts=[[13524  5910   509     5]\n",
      " [18491  1510    19     0]\n",
      " [19585   446     1     0]]\n",
      "Epoch=5, total_epoch_step_time=11.84, loss=456.99\n",
      "accuracy=0.2615833282470703, counts=[[14307  5362   278     1]\n",
      " [18622  1386    12     0]\n",
      " [19586   444     2     0]]\n",
      "Epoch=6, total_epoch_step_time=13.74, loss=458.31\n",
      "accuracy=0.2726333439350128, counts=[[15111  4620   216     1]\n",
      " [18765  1247     8     0]\n",
      " [19572   460     0     0]]\n",
      "Epoch=7, total_epoch_step_time=15.64, loss=459.23\n",
      "accuracy=0.29170000553131104, counts=[[15894  3887   167     0]\n",
      " [18399  1606    15     0]\n",
      " [19185   845     2     0]]\n",
      "Epoch=8, total_epoch_step_time=17.60, loss=460.43\n",
      "accuracy=0.42126667499542236, counts=[[16224  3337   373    14]\n",
      " [10546  5782  2254  1438]\n",
      " [ 7042  5253  3270  4467]]\n",
      "Epoch=9, total_epoch_step_time=19.48, loss=487.13\n",
      "accuracy=0.7103999853134155, counts=[[16693  3148   107     0]\n",
      " [ 1247 10690  7922   161]\n",
      " [  107  2306 15241  2378]]\n",
      "Epoch=10, total_epoch_step_time=21.37, loss=522.67\n",
      "accuracy=0.8591333627700806, counts=[[18531  1414     3     0]\n",
      " [  488 16806  2713    13]\n",
      " [    4  3213 16211   604]]\n",
      "Epoch=11, total_epoch_step_time=23.26, loss=545.29\n",
      "accuracy=0.9162499904632568, counts=[[19369   578     1     0]\n",
      " [  305 17701  2007     7]\n",
      " [    4  1730 17905   393]]\n",
      "Epoch=12, total_epoch_step_time=25.14, loss=559.98\n",
      "accuracy=0.9350500106811523, counts=[[19675   273     0     0]\n",
      " [  240 18043  1733     4]\n",
      " [    0  1247 18385   400]]\n",
      "Epoch=13, total_epoch_step_time=27.02, loss=574.12\n",
      "accuracy=0.9492499828338623, counts=[[19813   135     0     0]\n",
      " [  176 18538  1303     3]\n",
      " [    1  1078 18604   349]]\n",
      "Epoch=14, total_epoch_step_time=28.89, loss=583.54\n",
      "accuracy=0.9578666687011719, counts=[[19853    95     0     0]\n",
      " [  138 18837  1042     3]\n",
      " [    0   954 18782   296]]\n",
      "Epoch=15, total_epoch_step_time=30.83, loss=590.96\n",
      "accuracy=0.9652166962623596, counts=[[19899    49     0     0]\n",
      " [  108 19093   816     3]\n",
      " [    1   832 18921   278]]\n",
      "Epoch=16, total_epoch_step_time=32.71, loss=596.50\n",
      "accuracy=0.9664166569709778, counts=[[19911    37     0     0]\n",
      " [  100 19112   806     2]\n",
      " [    0   703 18962   367]]\n",
      "Epoch=17, total_epoch_step_time=34.60, loss=600.92\n",
      "accuracy=0.9685166478157043, counts=[[19907    41     0     0]\n",
      " [   83 19248   687     2]\n",
      " [    0   685 18956   391]]\n",
      "Epoch=18, total_epoch_step_time=36.47, loss=604.34\n",
      "accuracy=0.9691666960716248, counts=[[19922    26     0     0]\n",
      " [   78 19433   507     2]\n",
      " [    0   776 18795   461]]\n",
      "Epoch=19, total_epoch_step_time=38.35, loss=607.29\n",
      "accuracy=0.9708333611488342, counts=[[19921    27     0     0]\n",
      " [   58 19475   485     2]\n",
      " [    1   725 18854   452]]\n",
      "Epoch=20, total_epoch_step_time=40.24, loss=609.97\n",
      "accuracy=0.9699000120162964, counts=[[19929    19     0     0]\n",
      " [   56 19544   418     2]\n",
      " [    0   665 18721   646]]\n",
      "Epoch=21, total_epoch_step_time=42.14, loss=612.28\n",
      "accuracy=0.9706500172615051, counts=[[19932    16     0     0]\n",
      " [   43 19518   457     2]\n",
      " [    0   633 18789   610]]\n",
      "Epoch=22, total_epoch_step_time=44.04, loss=614.47\n",
      "accuracy=0.9716166853904724, counts=[[19932    16     0     0]\n",
      " [   33 19650   335     2]\n",
      " [    0   719 18715   598]]\n",
      "Epoch=23, total_epoch_step_time=45.93, loss=616.36\n",
      "accuracy=0.9711499810218811, counts=[[19932    16     0     0]\n",
      " [   38 19693   287     2]\n",
      " [    0   785 18644   603]]\n",
      "Epoch=24, total_epoch_step_time=47.99, loss=618.07\n",
      "accuracy=0.9718166589736938, counts=[[19934    14     0     0]\n",
      " [   39 19655   324     2]\n",
      " [    0   641 18720   671]]\n",
      "Epoch=25, total_epoch_step_time=50.17, loss=619.53\n",
      "accuracy=0.9714333415031433, counts=[[19937    11     0     0]\n",
      " [   36 19664   318     2]\n",
      " [    0   659 18685   688]]\n",
      "Epoch=26, total_epoch_step_time=52.20, loss=620.91\n",
      "accuracy=0.9717167019844055, counts=[[19935    13     0     0]\n",
      " [   27 19735   256     2]\n",
      " [    0   690 18633   709]]\n",
      "Epoch=27, total_epoch_step_time=54.38, loss=622.27\n",
      "accuracy=0.9711666703224182, counts=[[19934    14     0     0]\n",
      " [   23 19708   287     2]\n",
      " [    0   650 18628   754]]\n",
      "Epoch=28, total_epoch_step_time=56.59, loss=623.45\n",
      "accuracy=0.9722166657447815, counts=[[19943     5     0     0]\n",
      " [   30 19753   236     1]\n",
      " [    0   714 18637   681]]\n",
      "Epoch=29, total_epoch_step_time=58.69, loss=624.47\n",
      "accuracy=0.971916675567627, counts=[[19941     7     0     0]\n",
      " [   27 19753   238     2]\n",
      " [    0   689 18621   722]]\n",
      "Epoch=30, total_epoch_step_time=60.80, loss=625.54\n",
      "accuracy=0.9724667072296143, counts=[[19936    12     0     0]\n",
      " [   23 19785   210     2]\n",
      " [    0   728 18627   677]]\n",
      "Epoch=31, total_epoch_step_time=62.94, loss=626.43\n",
      "accuracy=0.973633348941803, counts=[[19938    10     0     0]\n",
      " [   23 19740   255     2]\n",
      " [    0   614 18740   678]]\n",
      "Epoch=32, total_epoch_step_time=65.38, loss=627.39\n",
      "accuracy=0.9729000329971313, counts=[[19942     6     0     0]\n",
      " [   15 19773   230     2]\n",
      " [    0   611 18659   762]]\n",
      "Epoch=33, total_epoch_step_time=67.88, loss=628.25\n",
      "accuracy=0.9725833535194397, counts=[[19940     8     0     0]\n",
      " [   22 19778   218     2]\n",
      " [    0   634 18637   761]]\n",
      "Epoch=34, total_epoch_step_time=70.46, loss=628.97\n",
      "accuracy=0.9728167057037354, counts=[[19938    10     0     0]\n",
      " [   19 19804   195     2]\n",
      " [    0   661 18627   744]]\n",
      "Epoch=35, total_epoch_step_time=72.76, loss=629.70\n",
      "accuracy=0.97243332862854, counts=[[19937    11     0     0]\n",
      " [   12 19816   190     2]\n",
      " [    0   671 18593   768]]\n",
      "Epoch=36, total_epoch_step_time=75.13, loss=630.32\n",
      "accuracy=0.9744499921798706, counts=[[19945     3     0     0]\n",
      " [   17 19816   187     0]\n",
      " [    0   651 18706   675]]\n",
      "Epoch=37, total_epoch_step_time=77.29, loss=630.94\n",
      "accuracy=0.9733166694641113, counts=[[19942     6     0     0]\n",
      " [   19 19794   205     2]\n",
      " [    0   629 18663   740]]\n",
      "Epoch=38, total_epoch_step_time=79.36, loss=631.53\n",
      "accuracy=0.9740833640098572, counts=[[19940     8     0     0]\n",
      " [   13 19815   190     2]\n",
      " [    0   655 18690   687]]\n",
      "Epoch=39, total_epoch_step_time=81.45, loss=632.09\n",
      "accuracy=0.9730499982833862, counts=[[19946     2     0     0]\n",
      " [   19 19825   174     2]\n",
      " [    0   687 18612   733]]\n",
      "Epoch=40, total_epoch_step_time=83.63, loss=632.55\n",
      "accuracy=0.9741666913032532, counts=[[19945     3     0     0]\n",
      " [    8 19818   192     2]\n",
      " [    0   574 18687   771]]\n",
      "Epoch=0, total_epoch_step_time=1.97, loss=-16.99\n",
      "accuracy=0.22263333201408386, counts=[[11249  8033   661     5]\n",
      " [17896  2106    18     0]\n",
      " [19592   437     3     0]]\n",
      "Epoch=1, total_epoch_step_time=4.20, loss=402.17\n",
      "accuracy=0.2230333387851715, counts=[[11573  7720   646     9]\n",
      " [18194  1807    19     0]\n",
      " [19612   418     2     0]]\n",
      "Epoch=2, total_epoch_step_time=6.25, loss=422.14\n",
      "accuracy=0.2271166741847992, counts=[[11965  7274   701     8]\n",
      " [18337  1661    22     0]\n",
      " [19581   450     1     0]]\n",
      "Epoch=3, total_epoch_step_time=8.13, loss=440.23\n",
      "accuracy=0.23793333768844604, counts=[[12681  6633   629     5]\n",
      " [18414  1594    12     0]\n",
      " [19608   423     1     0]]\n",
      "Epoch=4, total_epoch_step_time=10.18, loss=453.01\n",
      "accuracy=0.2502666711807251, counts=[[13550  5963   426     9]\n",
      " [18550  1463     7     0]\n",
      " [19606   423     3     0]]\n",
      "Epoch=5, total_epoch_step_time=12.31, loss=456.96\n",
      "accuracy=0.25851666927337646, counts=[[14269  5383   291     5]\n",
      " [18768  1242    10     0]\n",
      " [19706   326     0     0]]\n",
      "Epoch=6, total_epoch_step_time=14.46, loss=458.20\n",
      "accuracy=0.2705833315849304, counts=[[15153  4620   174     1]\n",
      " [18931  1082     7     0]\n",
      " [19686   346     0     0]]\n",
      "Epoch=7, total_epoch_step_time=16.52, loss=459.09\n",
      "accuracy=0.2868500053882599, counts=[[15970  3866   111     1]\n",
      " [18774  1240     6     0]\n",
      " [19548   483     1     0]]\n",
      "Epoch=8, total_epoch_step_time=18.52, loss=459.79\n",
      "accuracy=0.3141833245754242, counts=[[16433  3357   158     0]\n",
      " [17579  2390    50     1]\n",
      " [18256  1747    28     1]]\n",
      "Epoch=9, total_epoch_step_time=20.57, loss=474.58\n",
      "accuracy=0.5490666627883911, counts=[[16374  3333   238     3]\n",
      " [ 1875  7063  9607  1475]\n",
      " [  246  1688  9507  8591]]\n",
      "Epoch=10, total_epoch_step_time=22.59, loss=517.50\n",
      "accuracy=0.8495000004768372, counts=[[17966  1975     7     0]\n",
      " [  566 15908  3523    23]\n",
      " [   11  2228 17096   697]]\n",
      "Epoch=11, total_epoch_step_time=24.74, loss=545.80\n",
      "accuracy=0.9075999855995178, counts=[[19228   718     2     0]\n",
      " [  359 16953  2704     4]\n",
      " [    3  1391 18275   363]]\n",
      "Epoch=12, total_epoch_step_time=26.83, loss=562.62\n",
      "accuracy=0.9350666999816895, counts=[[19653   295     0     0]\n",
      " [  235 17646  2135     4]\n",
      " [    1   968 18805   258]]\n",
      "Epoch=13, total_epoch_step_time=28.88, loss=577.95\n",
      "accuracy=0.9509333372116089, counts=[[19806   142     0     0]\n",
      " [  190 18428  1400     2]\n",
      " [    3  1100 18822   107]]\n",
      "Epoch=14, total_epoch_step_time=31.05, loss=587.62\n",
      "accuracy=0.9594333171844482, counts=[[19864    84     0     0]\n",
      " [  147 18802  1070     1]\n",
      " [    0  1069 18900    63]]\n",
      "Epoch=15, total_epoch_step_time=32.94, loss=593.66\n",
      "accuracy=0.9647833704948425, counts=[[19884    64     0     0]\n",
      " [  106 19019   894     1]\n",
      " [    0   992 18984    56]]\n",
      "Epoch=16, total_epoch_step_time=34.82, loss=598.30\n",
      "accuracy=0.9684000015258789, counts=[[19908    40     0     0]\n",
      " [   96 19071   851     2]\n",
      " [    0   871 19125    36]]\n",
      "Epoch=17, total_epoch_step_time=36.69, loss=602.18\n",
      "accuracy=0.9711999893188477, counts=[[19930    18     0     0]\n",
      " [   76 19327   616     1]\n",
      " [    0   996 19015    21]]\n",
      "Epoch=18, total_epoch_step_time=38.55, loss=605.61\n",
      "accuracy=0.9727333188056946, counts=[[19923    25     0     0]\n",
      " [   66 19327   626     1]\n",
      " [    0   893 19114    25]]\n",
      "Epoch=19, total_epoch_step_time=40.42, loss=608.50\n",
      "accuracy=0.9753333330154419, counts=[[19935    13     0     0]\n",
      " [   57 19329   633     1]\n",
      " [    0   757 19256    19]]\n",
      "Epoch=20, total_epoch_step_time=42.44, loss=611.17\n",
      "accuracy=0.9768333435058594, counts=[[19933    15     0     0]\n",
      " [   39 19456   524     1]\n",
      " [    0   796 19221    15]]\n",
      "Epoch=21, total_epoch_step_time=44.47, loss=613.56\n",
      "accuracy=0.9782333374023438, counts=[[19939     9     0     0]\n",
      " [   42 19547   430     1]\n",
      " [    0   813 19208    11]]\n",
      "Epoch=22, total_epoch_step_time=46.36, loss=615.57\n",
      "accuracy=0.9786166548728943, counts=[[19931    17     0     0]\n",
      " [   39 19488   492     1]\n",
      " [    0   722 19298    12]]\n",
      "Epoch=23, total_epoch_step_time=48.21, loss=617.25\n",
      "accuracy=0.9800500273704529, counts=[[19939     9     0     0]\n",
      " [   45 19555   419     1]\n",
      " [    0   715 19309     8]]\n",
      "Epoch=24, total_epoch_step_time=50.07, loss=618.71\n",
      "accuracy=0.9794999957084656, counts=[[19937    11     0     0]\n",
      " [   36 19595   388     1]\n",
      " [    0   783 19238    11]]\n",
      "Epoch=25, total_epoch_step_time=52.03, loss=620.16\n",
      "accuracy=0.9802500009536743, counts=[[19940     8     0     0]\n",
      " [   36 19584   399     1]\n",
      " [    0   730 19291    11]]\n",
      "Epoch=26, total_epoch_step_time=54.01, loss=621.46\n",
      "accuracy=0.9815999865531921, counts=[[19942     6     0     0]\n",
      " [   26 19540   454     0]\n",
      " [    0   608 19414    10]]\n",
      "Epoch=27, total_epoch_step_time=56.15, loss=622.72\n",
      "accuracy=0.9824333190917969, counts=[[19936    12     0     0]\n",
      " [   16 19668   335     1]\n",
      " [    0   683 19342     7]]\n",
      "Epoch=28, total_epoch_step_time=58.24, loss=623.88\n",
      "accuracy=0.9811833500862122, counts=[[19939     9     0     0]\n",
      " [   17 19640   362     1]\n",
      " [    0   735 19292     5]]\n",
      "Epoch=29, total_epoch_step_time=60.25, loss=624.90\n",
      "accuracy=0.9826666712760925, counts=[[19936    12     0     0]\n",
      " [   16 19655   349     0]\n",
      " [    0   657 19369     6]]\n",
      "Epoch=30, total_epoch_step_time=62.12, loss=626.00\n",
      "accuracy=0.982283353805542, counts=[[19940     8     0     0]\n",
      " [   21 19671   328     0]\n",
      " [    0   697 19326     9]]\n",
      "Epoch=31, total_epoch_step_time=63.99, loss=626.92\n",
      "accuracy=0.9819499850273132, counts=[[19943     5     0     0]\n",
      " [   22 19680   317     1]\n",
      " [    0   732 19294     6]]\n",
      "Epoch=32, total_epoch_step_time=66.12, loss=627.69\n",
      "accuracy=0.9830000400543213, counts=[[19940     8     0     0]\n",
      " [   21 19625   373     1]\n",
      " [    0   610 19415     7]]\n",
      "Epoch=33, total_epoch_step_time=67.98, loss=628.48\n",
      "accuracy=0.9829666614532471, counts=[[19930    18     0     0]\n",
      " [   14 19742   264     0]\n",
      " [    0   721 19306     5]]\n",
      "Epoch=34, total_epoch_step_time=69.98, loss=629.24\n",
      "accuracy=0.9835000038146973, counts=[[19944     4     0     0]\n",
      " [   21 19737   261     1]\n",
      " [    0   698 19329     5]]\n",
      "Epoch=35, total_epoch_step_time=71.85, loss=629.97\n",
      "accuracy=0.9835000038146973, counts=[[19933    15     0     0]\n",
      " [   15 19694   310     1]\n",
      " [    0   643 19383     6]]\n",
      "Epoch=36, total_epoch_step_time=73.85, loss=630.58\n",
      "accuracy=0.9836500287055969, counts=[[19937    11     0     0]\n",
      " [   14 19734   271     1]\n",
      " [    0   679 19348     5]]\n",
      "Epoch=37, total_epoch_step_time=75.72, loss=631.19\n",
      "accuracy=0.9834499955177307, counts=[[19940     8     0     0]\n",
      " [   11 19775   233     1]\n",
      " [    0   736 19292     4]]\n",
      "Epoch=38, total_epoch_step_time=77.74, loss=631.75\n",
      "accuracy=0.9848333597183228, counts=[[19942     6     0     0]\n",
      " [   13 19758   249     0]\n",
      " [    0   637 19390     5]]\n",
      "Epoch=39, total_epoch_step_time=79.64, loss=632.27\n",
      "accuracy=0.9849666953086853, counts=[[19938    10     0     0]\n",
      " [   13 19732   274     1]\n",
      " [    0   596 19428     8]]\n",
      "Epoch=40, total_epoch_step_time=81.76, loss=632.79\n",
      "accuracy=0.9846667051315308, counts=[[19938    10     0     0]\n",
      " [   13 19717   289     1]\n",
      " [    0   600 19425     7]]\n",
      "Epoch=0, total_epoch_step_time=1.84, loss=-9.71\n",
      "accuracy=0.22321666777133942, counts=[[11342  7904   698     4]\n",
      " [17948  2051    21     0]\n",
      " [19601   431     0     0]]\n",
      "Epoch=1, total_epoch_step_time=3.82, loss=402.87\n",
      "accuracy=0.2230166643857956, counts=[[11508  7766   666     8]\n",
      " [18136  1871    13     0]\n",
      " [19602   428     2     0]]\n",
      "Epoch=2, total_epoch_step_time=5.63, loss=422.71\n",
      "accuracy=0.22921666502952576, counts=[[12038  7218   682    10]\n",
      " [18284  1715    21     0]\n",
      " [19572   460     0     0]]\n",
      "Epoch=3, total_epoch_step_time=7.56, loss=440.68\n",
      "accuracy=0.23454999923706055, counts=[[12464  6893   581    10]\n",
      " [18393  1609    18     0]\n",
      " [19611   421     0     0]]\n",
      "Epoch=4, total_epoch_step_time=9.84, loss=453.12\n",
      "accuracy=0.24639999866485596, counts=[[13425  6114   404     5]\n",
      " [18655  1358     7     0]\n",
      " [19630   401     1     0]]\n",
      "Epoch=5, total_epoch_step_time=11.94, loss=457.01\n",
      "accuracy=0.25876668095588684, counts=[[14256  5443   247     2]\n",
      " [18739  1270    11     0]\n",
      " [19695   337     0     0]]\n",
      "Epoch=6, total_epoch_step_time=13.86, loss=458.21\n",
      "accuracy=0.2697666585445404, counts=[[14966  4794   187     1]\n",
      " [18797  1219     4     0]\n",
      " [19665   366     1     0]]\n",
      "Epoch=7, total_epoch_step_time=15.76, loss=459.15\n",
      "accuracy=0.2838999927043915, counts=[[15749  4059   139     1]\n",
      " [18728  1285     7     0]\n",
      " [19513   519     0     0]]\n",
      "Epoch=8, total_epoch_step_time=17.67, loss=459.76\n",
      "accuracy=0.3125666677951813, counts=[[16291  3477   179     1]\n",
      " [17533  2428    59     0]\n",
      " [18232  1765    35     0]]\n",
      "Epoch=9, total_epoch_step_time=19.60, loss=474.95\n",
      "accuracy=0.4771166741847992, counts=[[16205  3524   217     2]\n",
      " [ 1866  5913  9275  2966]\n",
      " [  241  1032  6509 12250]]\n",
      "Epoch=10, total_epoch_step_time=21.54, loss=520.97\n",
      "accuracy=0.8088833689689636, counts=[[17830  2107    11     0]\n",
      " [  494 13111  6374    41]\n",
      " [   15  1593 17592   832]]\n",
      "Epoch=11, total_epoch_step_time=23.58, loss=548.50\n",
      "accuracy=0.8513833284378052, counts=[[19118   830     0     0]\n",
      " [  327 13164  6519    10]\n",
      " [    4   850 18801   377]]\n",
      "Epoch=12, total_epoch_step_time=25.79, loss=566.34\n",
      "accuracy=0.877833366394043, counts=[[19596   352     0     0]\n",
      " [  265 14089  5664     2]\n",
      " [    1   894 18985   152]]\n",
      "Epoch=13, total_epoch_step_time=27.93, loss=579.89\n",
      "accuracy=0.8921166658401489, counts=[[19781   167     0     0]\n",
      " [  176 14505  5337     2]\n",
      " [    0   716 19241    75]]\n",
      "Epoch=14, total_epoch_step_time=30.06, loss=588.47\n",
      "accuracy=0.9026666879653931, counts=[[19857    91     0     0]\n",
      " [  160 15032  4827     1]\n",
      " [    0   700 19271    61]]\n",
      "Epoch=15, total_epoch_step_time=32.17, loss=594.09\n",
      "accuracy=0.9113500118255615, counts=[[19883    65     0     0]\n",
      " [  143 15481  4394     2]\n",
      " [    0   678 19317    37]]\n",
      "Epoch=16, total_epoch_step_time=34.20, loss=598.30\n",
      "accuracy=0.9174667000770569, counts=[[19896    52     0     0]\n",
      " [  104 15832  4083     1]\n",
      " [    0   673 19320    39]]\n",
      "Epoch=17, total_epoch_step_time=36.07, loss=602.09\n",
      "accuracy=0.9239333271980286, counts=[[19922    26     0     0]\n",
      " [   88 16056  3875     1]\n",
      " [    0   544 19458    30]]\n",
      "Epoch=18, total_epoch_step_time=37.95, loss=605.38\n",
      "accuracy=0.9317833185195923, counts=[[19924    24     0     0]\n",
      " [   58 16560  3401     1]\n",
      " [    0   588 19423    21]]\n",
      "Epoch=19, total_epoch_step_time=39.81, loss=608.29\n",
      "accuracy=0.93913334608078, counts=[[19928    20     0     0]\n",
      " [   67 17108  2845     0]\n",
      " [    0   706 19312    14]]\n",
      "Epoch=20, total_epoch_step_time=41.67, loss=610.76\n",
      "accuracy=0.9381333589553833, counts=[[19925    23     0     0]\n",
      " [   57 16883  3080     0]\n",
      " [    0   537 19480    15]]\n",
      "Epoch=21, total_epoch_step_time=43.55, loss=613.02\n",
      "accuracy=0.9474499821662903, counts=[[19935    13     0     0]\n",
      " [   53 17530  2437     0]\n",
      " [    0   636 19382    14]]\n",
      "Epoch=22, total_epoch_step_time=45.41, loss=615.14\n",
      "accuracy=0.9563500285148621, counts=[[19936    12     0     0]\n",
      " [   59 17987  1974     0]\n",
      " [    0   561 19458    13]]\n",
      "Epoch=23, total_epoch_step_time=47.28, loss=617.12\n",
      "accuracy=0.963200032711029, counts=[[19940     8     0     0]\n",
      " [   36 18390  1594     0]\n",
      " [    0   557 19462    13]]\n",
      "Epoch=24, total_epoch_step_time=49.15, loss=618.87\n",
      "accuracy=0.9671666622161865, counts=[[19937    11     0     0]\n",
      " [   40 18735  1245     0]\n",
      " [    0   665 19358     9]]\n",
      "Epoch=25, total_epoch_step_time=51.03, loss=620.54\n",
      "accuracy=0.9694833159446716, counts=[[19934    14     0     0]\n",
      " [   31 18821  1168     0]\n",
      " [    0   608 19414    10]]\n",
      "Epoch=26, total_epoch_step_time=52.95, loss=621.91\n",
      "accuracy=0.9706166982650757, counts=[[19930    18     0     0]\n",
      " [   32 18901  1087     0]\n",
      " [    0   616 19406    10]]\n",
      "Epoch=27, total_epoch_step_time=55.18, loss=623.20\n",
      "accuracy=0.9732000231742859, counts=[[19941     7     0     0]\n",
      " [   25 19044   950     1]\n",
      " [    0   618 19407     7]]\n",
      "Epoch=28, total_epoch_step_time=57.32, loss=624.41\n",
      "accuracy=0.9742000102996826, counts=[[19935    13     0     0]\n",
      " [   26 19075   918     1]\n",
      " [    0   582 19442     8]]\n",
      "Epoch=29, total_epoch_step_time=59.50, loss=625.46\n",
      "accuracy=0.9783833622932434, counts=[[19937    11     0     0]\n",
      " [   19 19309   692     0]\n",
      " [    0   569 19457     6]]\n",
      "Epoch=30, total_epoch_step_time=61.40, loss=626.78\n",
      "accuracy=0.9802833199501038, counts=[[19943     5     0     0]\n",
      " [   20 19440   560     0]\n",
      " [    0   592 19434     6]]\n",
      "Epoch=31, total_epoch_step_time=63.38, loss=627.80\n",
      "accuracy=0.9822333455085754, counts=[[19938    10     0     0]\n",
      " [   20 19561   439     0]\n",
      " [    1   589 19435     7]]\n",
      "Epoch=32, total_epoch_step_time=65.28, loss=628.73\n",
      "accuracy=0.9827166795730591, counts=[[19942     6     0     0]\n",
      " [   20 19577   423     0]\n",
      " [    0   580 19444     8]]\n",
      "Epoch=33, total_epoch_step_time=67.16, loss=629.51\n",
      "accuracy=0.983916699886322, counts=[[19943     5     0     0]\n",
      " [   10 19586   424     0]\n",
      " [    0   518 19506     8]]\n",
      "Epoch=34, total_epoch_step_time=69.07, loss=630.34\n",
      "accuracy=0.9832167029380798, counts=[[19939     9     0     0]\n",
      " [   13 19650   357     0]\n",
      " [    0   623 19404     5]]\n",
      "Epoch=35, total_epoch_step_time=70.97, loss=630.84\n",
      "accuracy=0.9832000136375427, counts=[[19942     6     0     0]\n",
      " [   18 19646   356     0]\n",
      " [    0   621 19404     7]]\n",
      "Epoch=36, total_epoch_step_time=72.86, loss=631.50\n",
      "accuracy=0.9834499955177307, counts=[[19942     6     0     0]\n",
      " [   15 19645   360     0]\n",
      " [    0   606 19420     6]]\n",
      "Epoch=37, total_epoch_step_time=74.76, loss=632.14\n",
      "accuracy=0.9834499955177307, counts=[[19937    11     0     0]\n",
      " [   16 19684   320     0]\n",
      " [    0   641 19386     5]]\n",
      "Epoch=38, total_epoch_step_time=76.72, loss=632.69\n",
      "accuracy=0.9831500053405762, counts=[[19940     8     0     0]\n",
      " [   14 19586   420     0]\n",
      " [    0   563 19463     6]]\n",
      "Epoch=39, total_epoch_step_time=78.64, loss=633.17\n",
      "accuracy=0.9839833378791809, counts=[[19943     5     0     0]\n",
      " [   10 19682   328     0]\n",
      " [    0   614 19414     4]]\n",
      "Epoch=40, total_epoch_step_time=80.60, loss=633.65\n",
      "accuracy=0.9844000339508057, counts=[[19944     4     0     0]\n",
      " [   12 19659   349     0]\n",
      " [    0   565 19461     6]]\n",
      "Epoch=0, total_epoch_step_time=1.82, loss=-26.56\n",
      "accuracy=0.22093333303928375, counts=[[11287  7992   665     4]\n",
      " [18031  1969    20     0]\n",
      " [19585   447     0     0]]\n",
      "Epoch=1, total_epoch_step_time=3.65, loss=402.09\n",
      "accuracy=0.22226667404174805, counts=[[11550  7699   694     5]\n",
      " [18214  1785    21     0]\n",
      " [19603   428     1     0]]\n",
      "Epoch=2, total_epoch_step_time=5.50, loss=422.16\n",
      "accuracy=0.22654999792575836, counts=[[11884  7374   683     7]\n",
      " [18293  1707    20     0]\n",
      " [19575   455     2     0]]\n",
      "Epoch=3, total_epoch_step_time=7.35, loss=440.19\n",
      "accuracy=0.23598334193229675, counts=[[12664  6683   593     8]\n",
      " [18511  1495    14     0]\n",
      " [19606   426     0     0]]\n",
      "Epoch=4, total_epoch_step_time=9.21, loss=452.82\n",
      "accuracy=0.2458166629076004, counts=[[13371  6136   435     6]\n",
      " [18631  1378    11     0]\n",
      " [19649   383     0     0]]\n",
      "Epoch=5, total_epoch_step_time=11.08, loss=456.85\n",
      "accuracy=0.25671666860580444, counts=[[14236  5445   264     3]\n",
      " [18844  1166    10     0]\n",
      " [19701   330     1     0]]\n",
      "Epoch=6, total_epoch_step_time=12.97, loss=458.12\n",
      "accuracy=0.2695833444595337, counts=[[15030  4723   195     0]\n",
      " [18869  1144     7     0]\n",
      " [19695   336     1     0]]\n",
      "Epoch=7, total_epoch_step_time=15.16, loss=459.07\n",
      "accuracy=0.2810499966144562, counts=[[15817  4000   131     0]\n",
      " [18970  1046     4     0]\n",
      " [19583   449     0     0]]\n",
      "Epoch=8, total_epoch_step_time=17.40, loss=459.75\n",
      "accuracy=0.3081666827201843, counts=[[16452  3351   143     2]\n",
      " [17969  2029    22     0]\n",
      " [18731  1292     9     0]]\n",
      "Epoch=9, total_epoch_step_time=19.45, loss=468.88\n",
      "accuracy=0.4130000174045563, counts=[[16163  3499   281     5]\n",
      " [ 2730  5144  6580  5566]\n",
      " [  456  1123  3473 14980]]\n",
      "Epoch=10, total_epoch_step_time=21.48, loss=510.11\n",
      "accuracy=0.8226667046546936, counts=[[17917  2019    12     0]\n",
      " [  621 14610  4758    31]\n",
      " [   21  1948 16833  1230]]\n",
      "Epoch=11, total_epoch_step_time=23.47, loss=539.27\n",
      "accuracy=0.8953500390052795, counts=[[19197   751     0     0]\n",
      " [  344 16556  3112     8]\n",
      " [    2  1488 17968   574]]\n",
      "Epoch=12, total_epoch_step_time=25.46, loss=556.88\n",
      "accuracy=0.9199666976928711, counts=[[19676   271     1     0]\n",
      " [  265 17089  2660     6]\n",
      " [    2  1029 18433   568]]\n",
      "Epoch=13, total_epoch_step_time=27.75, loss=573.50\n",
      "accuracy=0.9400500059127808, counts=[[19793   154     1     0]\n",
      " [  169 17848  1998     5]\n",
      " [    2   850 18762   418]]\n",
      "Epoch=14, total_epoch_step_time=29.89, loss=584.07\n",
      "accuracy=0.9513333439826965, counts=[[19892    56     0     0]\n",
      " [  131 18425  1462     2]\n",
      " [    1   920 18763   348]]\n",
      "Epoch=15, total_epoch_step_time=31.88, loss=591.24\n",
      "accuracy=0.956166684627533, counts=[[19897    51     0     0]\n",
      " [  113 18499  1407     1]\n",
      " [    0   725 18974   333]]\n",
      "Epoch=16, total_epoch_step_time=33.80, loss=597.14\n",
      "accuracy=0.9619500041007996, counts=[[19912    36     0     0]\n",
      " [   76 18825  1118     1]\n",
      " [    0   740 18980   312]]\n",
      "Epoch=17, total_epoch_step_time=36.03, loss=601.66\n",
      "accuracy=0.9641000032424927, counts=[[19920    28     0     0]\n",
      " [   71 18877  1071     1]\n",
      " [    0   676 19049   307]]\n",
      "Epoch=18, total_epoch_step_time=37.96, loss=605.38\n",
      "accuracy=0.966450035572052, counts=[[19928    20     0     0]\n",
      " [   74 19009   934     3]\n",
      " [    0   620 19050   362]]\n",
      "Epoch=19, total_epoch_step_time=40.16, loss=608.51\n",
      "accuracy=0.9693999886512756, counts=[[19933    15     0     0]\n",
      " [   62 19208   749     1]\n",
      " [    0   684 19023   325]]\n",
      "Epoch=20, total_epoch_step_time=42.36, loss=611.42\n",
      "accuracy=0.9707666635513306, counts=[[19935    13     0     0]\n",
      " [   57 19307   654     2]\n",
      " [    0   759 19004   269]]\n",
      "Epoch=21, total_epoch_step_time=44.51, loss=614.02\n",
      "accuracy=0.9724667072296143, counts=[[19932    16     0     0]\n",
      " [   37 19361   622     0]\n",
      " [    0   763 19055   214]]\n",
      "Epoch=22, total_epoch_step_time=46.66, loss=616.27\n",
      "accuracy=0.9731000065803528, counts=[[19933    15     0     0]\n",
      " [   40 19324   655     1]\n",
      " [    0   631 19129   272]]\n",
      "Epoch=23, total_epoch_step_time=48.79, loss=618.09\n",
      "accuracy=0.9743666648864746, counts=[[19941     7     0     0]\n",
      " [   36 19455   528     1]\n",
      " [    0   693 19066   273]]\n",
      "Epoch=24, total_epoch_step_time=50.95, loss=619.78\n",
      "accuracy=0.9747166633605957, counts=[[19940     8     0     0]\n",
      " [   22 19396   601     1]\n",
      " [    0   553 19147   332]]\n",
      "Epoch=25, total_epoch_step_time=53.10, loss=621.24\n",
      "accuracy=0.9762499928474426, counts=[[19936    12     0     0]\n",
      " [   26 19548   445     1]\n",
      " [    0   672 19091   269]]\n",
      "Epoch=26, total_epoch_step_time=55.11, loss=622.61\n",
      "accuracy=0.9758333563804626, counts=[[19936    12     0     0]\n",
      " [   26 19523   471     0]\n",
      " [    0   659 19091   282]]\n",
      "Epoch=27, total_epoch_step_time=57.27, loss=623.86\n",
      "accuracy=0.9772000312805176, counts=[[19942     6     0     0]\n",
      " [   22 19523   474     1]\n",
      " [    0   583 19167   282]]\n",
      "Epoch=28, total_epoch_step_time=59.44, loss=625.01\n",
      "accuracy=0.9757000207901001, counts=[[19936    12     0     0]\n",
      " [   16 19464   540     0]\n",
      " [    0   561 19142   329]]\n",
      "Epoch=29, total_epoch_step_time=61.68, loss=626.06\n",
      "accuracy=0.9766333699226379, counts=[[19940     8     0     0]\n",
      " [   25 19628   367     0]\n",
      " [    0   683 19030   319]]\n",
      "Epoch=30, total_epoch_step_time=63.70, loss=626.91\n",
      "accuracy=0.976983368396759, counts=[[19946     2     0     0]\n",
      " [   15 19597   408     0]\n",
      " [    0   586 19076   370]]\n",
      "Epoch=31, total_epoch_step_time=65.58, loss=627.76\n",
      "accuracy=0.9777500033378601, counts=[[19943     5     0     0]\n",
      " [   12 19662   346     0]\n",
      " [    0   688 19060   284]]\n",
      "Epoch=32, total_epoch_step_time=67.46, loss=628.60\n",
      "accuracy=0.9766666889190674, counts=[[19943     5     0     0]\n",
      " [   18 19573   427     2]\n",
      " [    0   549 19084   399]]\n",
      "Epoch=33, total_epoch_step_time=69.33, loss=629.34\n",
      "accuracy=0.9770833253860474, counts=[[19942     6     0     0]\n",
      " [   12 19708   300     0]\n",
      " [    0   759 18975   298]]\n",
      "Epoch=34, total_epoch_step_time=71.21, loss=630.06\n",
      "accuracy=0.9778500199317932, counts=[[19939     9     0     0]\n",
      " [   16 19618   386     0]\n",
      " [    0   532 19114   386]]\n",
      "Epoch=35, total_epoch_step_time=73.09, loss=630.67\n",
      "accuracy=0.9783833622932434, counts=[[19944     4     0     0]\n",
      " [   13 19670   337     0]\n",
      " [    0   608 19089   335]]\n",
      "Epoch=36, total_epoch_step_time=74.97, loss=631.17\n",
      "accuracy=0.9779166579246521, counts=[[19940     8     0     0]\n",
      " [   13 19670   337     0]\n",
      " [    0   589 19065   378]]\n",
      "Epoch=37, total_epoch_step_time=76.84, loss=631.80\n",
      "accuracy=0.9775333404541016, counts=[[19943     5     0     0]\n",
      " [   12 19631   377     0]\n",
      " [    1   552 19078   401]]\n",
      "Epoch=38, total_epoch_step_time=78.72, loss=632.23\n",
      "accuracy=0.978516697883606, counts=[[19942     6     0     0]\n",
      " [    8 19679   333     0]\n",
      " [    0   578 19090   364]]\n",
      "Epoch=39, total_epoch_step_time=80.60, loss=632.66\n",
      "accuracy=0.9777833223342896, counts=[[19945     3     0     0]\n",
      " [    9 19688   323     0]\n",
      " [    0   603 19034   395]]\n",
      "Epoch=40, total_epoch_step_time=82.48, loss=633.14\n",
      "accuracy=0.9788166880607605, counts=[[19940     8     0     0]\n",
      " [    6 19680   334     0]\n",
      " [    0   554 19109   369]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Run with different random seeds.\n",
    "losses, accuracy, wall_clock_times = None, None, None\n",
    "for train_idx in range(0, 5):\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    r_loss, r_acc, r_times, params = train(\n",
    "        sub_key, learning_rate=1.0e-4, n=1, batch_size=64, num_epochs=40\n",
    "    )\n",
    "    # Save run.\n",
    "    arr = np.array([r_loss, r_acc, r_times])\n",
    "    df = pd.DataFrame(\n",
    "        arr.T, columns=[\"ELBO loss\", \"Accuracy\", \"Epoch wall clock times\"]\n",
    "    )\n",
    "    df.to_csv(\n",
    "        f\"./training_runs/grasp_air_hybrid_mvd_enum_epochs_41_mccoy_prior_{train_idx}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    if losses is None:\n",
    "        losses = r_loss\n",
    "        accuracy = r_acc\n",
    "        wall_clock_times = r_times\n",
    "\n",
    "    else:\n",
    "        losses = np.vstack((losses, r_loss))\n",
    "        accuracy = np.vstack((accuracy, r_acc))\n",
    "        wall_clock_times = np.vstack((wall_clock_times, r_times))\n",
    "\n",
    "arr = np.array([losses, accuracy, wall_clock_times])\n",
    "mean_arr = jnp.mean(arr, axis=1)\n",
    "std_arr = jnp.std(arr, axis=1)\n",
    "df_arr = jnp.vstack((mean_arr, std_arr))\n",
    "df = pd.DataFrame(\n",
    "    df_arr.T,\n",
    "    columns=[\n",
    "        \"Mean ELBO loss\",\n",
    "        \"Mean accuracy\",\n",
    "        \"Mean epoch wall clock times\",\n",
    "        \"Std ELBO loss\",\n",
    "        \"Std accuracy\",\n",
    "        \"Std epoch wall clock times\",\n",
    "    ],\n",
    ")\n",
    "df.to_csv(\n",
    "    \"./training_runs/grasp_air_hybrid_mvd_enum_epochs_41_mccoy_prior.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "150b4bee-ddf2-4038-b26b-91cdff3a5b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, total_epoch_step_time=5.14, loss=280.16\n",
      "accuracy=0.23364999890327454, counts=[[11539  7426   949    34]\n",
      " [17469  2472    77     2]\n",
      " [19180   844     8     0]]\n",
      "Epoch=1, total_epoch_step_time=11.10, loss=430.17\n",
      "accuracy=0.25958332419395447, counts=[[11938  6887  1074    49]\n",
      " [16243  3513   257     7]\n",
      " [17483  2419   124     6]]\n",
      "Epoch=2, total_epoch_step_time=16.33, loss=454.02\n",
      "accuracy=0.41179999709129333, counts=[[12274  6335  1247    92]\n",
      " [ 8508  7845  2802   865]\n",
      " [ 5239  6738  4589  3466]]\n",
      "Epoch=3, total_epoch_step_time=21.71, loss=483.69\n",
      "accuracy=0.5365999937057495, counts=[[12799  6258   876    15]\n",
      " [ 2557  8106  8719   638]\n",
      " [  612  2365 11291  5764]]\n",
      "Epoch=4, total_epoch_step_time=27.04, loss=520.90\n",
      "accuracy=0.7125499844551086, counts=[[13702  5971   274     1]\n",
      " [ 1059 12598  6287    76]\n",
      " [  126  2023 16453  1430]]\n",
      "Epoch=5, total_epoch_step_time=32.23, loss=547.85\n",
      "accuracy=0.7738333344459534, counts=[[15220  4639    88     1]\n",
      " [  582 13239  6163    36]\n",
      " [   49  1301 17971   711]]\n",
      "Epoch=6, total_epoch_step_time=37.71, loss=565.35\n",
      "accuracy=0.8218833208084106, counts=[[16772  3153    23     0]\n",
      " [  432 13865  5714     9]\n",
      " [   12   952 18676   392]]\n",
      "Epoch=7, total_epoch_step_time=43.89, loss=579.73\n",
      "accuracy=0.8701000213623047, counts=[[17959  1984     5     0]\n",
      " [  324 15379  4311     6]\n",
      " [    9   977 18868   178]]\n",
      "Epoch=8, total_epoch_step_time=49.83, loss=589.56\n",
      "accuracy=0.900350034236908, counts=[[18643  1300     5     0]\n",
      " [  245 16328  3443     4]\n",
      " [    4   882 19050    96]]\n",
      "Epoch=9, total_epoch_step_time=55.68, loss=596.71\n",
      "accuracy=0.9140000343322754, counts=[[19045   903     0     0]\n",
      " [  232 16543  3243     2]\n",
      " [    2   707 19252    71]]\n",
      "Epoch=10, total_epoch_step_time=61.44, loss=601.88\n",
      "accuracy=0.9324333667755127, counts=[[19277   671     0     0]\n",
      " [  169 17512  2335     4]\n",
      " [    1   839 19157    35]]\n",
      "Epoch=11, total_epoch_step_time=67.28, loss=605.71\n",
      "accuracy=0.9374666810035706, counts=[[19403   545     0     0]\n",
      " [  158 17618  2244     0]\n",
      " [    1   783 19227    21]]\n",
      "Epoch=12, total_epoch_step_time=72.74, loss=609.20\n",
      "accuracy=0.9461333155632019, counts=[[19542   404     2     0]\n",
      " [  125 17965  1928     2]\n",
      " [    1   747 19261    23]]\n",
      "Epoch=13, total_epoch_step_time=78.18, loss=612.07\n",
      "accuracy=0.9515500068664551, counts=[[19596   352     0     0]\n",
      " [  105 18224  1691     0]\n",
      " [    0   742 19273    17]]\n",
      "Epoch=14, total_epoch_step_time=83.56, loss=614.53\n",
      "accuracy=0.9597499966621399, counts=[[19669   279     0     0]\n",
      " [   75 18578  1367     0]\n",
      " [    2   676 19338    16]]\n",
      "Epoch=15, total_epoch_step_time=89.66, loss=616.72\n",
      "accuracy=0.964983344078064, counts=[[19691   257     0     0]\n",
      " [   77 18916  1026     1]\n",
      " [    0   725 19292    15]]\n",
      "Epoch=16, total_epoch_step_time=95.42, loss=618.96\n",
      "accuracy=0.9666833281517029, counts=[[19738   210     0     0]\n",
      " [   79 18897  1044     0]\n",
      " [    0   655 19366    11]]\n",
      "Epoch=17, total_epoch_step_time=100.98, loss=620.85\n",
      "accuracy=0.9693999886512756, counts=[[19743   205     0     0]\n",
      " [   50 19113   857     0]\n",
      " [    0   711 19308    13]]\n",
      "Epoch=18, total_epoch_step_time=107.33, loss=622.39\n",
      "accuracy=0.9714166522026062, counts=[[19785   163     0     0]\n",
      " [   54 19248   718     0]\n",
      " [    0   771 19252     9]]\n",
      "Epoch=19, total_epoch_step_time=113.23, loss=623.78\n",
      "accuracy=0.9735666513442993, counts=[[19811   137     0     0]\n",
      " [   36 19232   752     0]\n",
      " [    0   647 19371    14]]\n",
      "Epoch=20, total_epoch_step_time=118.35, loss=624.97\n",
      "accuracy=0.9738500118255615, counts=[[19815   133     0     0]\n",
      " [   38 19278   704     0]\n",
      " [    0   684 19338    10]]\n",
      "Epoch=21, total_epoch_step_time=123.47, loss=626.01\n",
      "accuracy=0.9753833413124084, counts=[[19818   130     0     0]\n",
      " [   31 19278   711     0]\n",
      " [    0   596 19427     9]]\n",
      "Epoch=22, total_epoch_step_time=128.59, loss=627.14\n",
      "accuracy=0.9763000011444092, counts=[[19831   117     0     0]\n",
      " [   39 19379   602     0]\n",
      " [    0   656 19368     8]]\n",
      "Epoch=23, total_epoch_step_time=133.71, loss=628.07\n",
      "accuracy=0.9770500063896179, counts=[[19819   129     0     0]\n",
      " [   28 19521   471     0]\n",
      " [    0   740 19283     9]]\n",
      "Epoch=24, total_epoch_step_time=139.17, loss=628.99\n",
      "accuracy=0.9777333736419678, counts=[[19837   111     0     0]\n",
      " [   24 19387   609     0]\n",
      " [    0   586 19440     6]]\n",
      "Epoch=25, total_epoch_step_time=144.28, loss=629.81\n",
      "accuracy=0.9778167009353638, counts=[[19851    97     0     0]\n",
      " [   27 19421   572     0]\n",
      " [    0   627 19397     8]]\n",
      "Epoch=26, total_epoch_step_time=149.40, loss=630.64\n",
      "accuracy=0.9782000184059143, counts=[[19836   112     0     0]\n",
      " [   16 19448   556     0]\n",
      " [    0   618 19408     6]]\n",
      "Epoch=27, total_epoch_step_time=155.29, loss=631.29\n",
      "accuracy=0.978950023651123, counts=[[19837   111     0     0]\n",
      " [   22 19447   551     0]\n",
      " [    0   572 19453     7]]\n",
      "Epoch=28, total_epoch_step_time=160.94, loss=632.04\n",
      "accuracy=0.9794166684150696, counts=[[19845   103     0     0]\n",
      " [   18 19529   473     0]\n",
      " [    0   632 19391     9]]\n",
      "Epoch=29, total_epoch_step_time=166.44, loss=632.66\n",
      "accuracy=0.9796500205993652, counts=[[19862    86     0     0]\n",
      " [   12 19529   479     0]\n",
      " [    0   634 19388    10]]\n",
      "Epoch=30, total_epoch_step_time=171.72, loss=633.21\n",
      "accuracy=0.9803333282470703, counts=[[19861    87     0     0]\n",
      " [   15 19511   494     0]\n",
      " [    0   578 19448     6]]\n",
      "Epoch=31, total_epoch_step_time=177.80, loss=633.89\n",
      "accuracy=0.9800166487693787, counts=[[19870    78     0     0]\n",
      " [   16 19547   457     0]\n",
      " [    0   639 19384     9]]\n",
      "Epoch=32, total_epoch_step_time=185.21, loss=634.41\n",
      "accuracy=0.9804999828338623, counts=[[19862    86     0     0]\n",
      " [   12 19507   501     0]\n",
      " [    0   561 19461    10]]\n",
      "Epoch=33, total_epoch_step_time=191.22, loss=634.94\n",
      "accuracy=0.9809333682060242, counts=[[19866    82     0     0]\n",
      " [   13 19456   551     0]\n",
      " [    0   491 19534     7]]\n",
      "Epoch=34, total_epoch_step_time=197.17, loss=635.43\n",
      "accuracy=0.9808833599090576, counts=[[19876    72     0     0]\n",
      " [   18 19516   486     0]\n",
      " [    0   563 19461     8]]\n",
      "Epoch=35, total_epoch_step_time=202.46, loss=635.89\n",
      "accuracy=0.980650007724762, counts=[[19871    77     0     0]\n",
      " [   17 19493   510     0]\n",
      " [    0   550 19475     7]]\n",
      "Epoch=36, total_epoch_step_time=207.87, loss=636.36\n",
      "accuracy=0.9822500348091125, counts=[[19864    84     0     0]\n",
      " [   10 19574   436     0]\n",
      " [    0   529 19497     6]]\n",
      "Epoch=37, total_epoch_step_time=214.03, loss=636.78\n",
      "accuracy=0.9817166924476624, counts=[[19885    63     0     0]\n",
      " [   11 19597   412     0]\n",
      " [    0   603 19421     8]]\n",
      "Epoch=38, total_epoch_step_time=219.79, loss=637.14\n",
      "accuracy=0.9822333455085754, counts=[[19869    79     0     0]\n",
      " [   12 19568   440     0]\n",
      " [    0   525 19497    10]]\n",
      "Epoch=39, total_epoch_step_time=225.25, loss=637.51\n",
      "accuracy=0.9819499850273132, counts=[[19879    69     0     0]\n",
      " [   11 19602   407     0]\n",
      " [    0   589 19436     7]]\n",
      "Epoch=40, total_epoch_step_time=230.37, loss=637.88\n",
      "accuracy=0.9830333590507507, counts=[[19899    49     0     0]\n",
      " [    9 19563   448     0]\n",
      " [    0   504 19520     8]]\n",
      "Epoch=0, total_epoch_step_time=5.45, loss=278.46\n",
      "accuracy=0.23198333382606506, counts=[[11443  7509   961    35]\n",
      " [17474  2465    81     0]\n",
      " [19174   847    11     0]]\n",
      "Epoch=1, total_epoch_step_time=10.76, loss=429.75\n",
      "accuracy=0.2546166777610779, counts=[[11847  6916  1121    64]\n",
      " [16472  3331   209     8]\n",
      " [17676  2254    99     3]]\n",
      "Epoch=2, total_epoch_step_time=16.06, loss=453.30\n",
      "accuracy=0.39366668462753296, counts=[[12189  6491  1199    69]\n",
      " [ 9453  7370  2430   767]\n",
      " [ 6239  6758  4061  2974]]\n",
      "Epoch=3, total_epoch_step_time=21.65, loss=482.51\n",
      "accuracy=0.5123833417892456, counts=[[12346  6675   901    26]\n",
      " [ 2766  8138  8308   808]\n",
      " [  744  2493 10259  6536]]\n",
      "Epoch=4, total_epoch_step_time=27.01, loss=514.30\n",
      "accuracy=0.6929166913032532, counts=[[13237  6430   278     3]\n",
      " [ 1145 13245  5539    91]\n",
      " [  162  2881 15093  1896]]\n",
      "Epoch=5, total_epoch_step_time=32.51, loss=543.43\n",
      "accuracy=0.7816166877746582, counts=[[14687  5186    75     0]\n",
      " [  652 14901  4437    30]\n",
      " [   60  1729 17309   934]]\n",
      "Epoch=6, total_epoch_step_time=38.43, loss=564.14\n",
      "accuracy=0.8384333252906799, counts=[[16699  3226    23     0]\n",
      " [  474 15269  4263    14]\n",
      " [   42  1055 18338   597]]\n",
      "Epoch=7, total_epoch_step_time=44.16, loss=580.33\n",
      "accuracy=0.8882666826248169, counts=[[17949  1995     4     0]\n",
      " [  389 16765  2857     9]\n",
      " [   18  1218 18582   214]]\n",
      "Epoch=8, total_epoch_step_time=49.28, loss=590.02\n",
      "accuracy=0.9110333323478699, counts=[[18650  1296     2     0]\n",
      " [  310 17235  2472     3]\n",
      " [   10  1119 18777   126]]\n",
      "Epoch=9, total_epoch_step_time=55.62, loss=596.88\n",
      "accuracy=0.9267666935920715, counts=[[19007   939     2     0]\n",
      " [  257 17518  2242     3]\n",
      " [    3   861 19081    87]]\n",
      "Epoch=10, total_epoch_step_time=61.89, loss=601.81\n",
      "accuracy=0.9363000392913818, counts=[[19222   726     0     0]\n",
      " [  177 17829  2012     2]\n",
      " [    0   836 19127    69]]\n",
      "Epoch=11, total_epoch_step_time=68.42, loss=605.69\n",
      "accuracy=0.9518499970436096, counts=[[19435   513     0     0]\n",
      " [  154 18528  1338     0]\n",
      " [    0   834 19148    50]]\n",
      "Epoch=12, total_epoch_step_time=74.53, loss=609.30\n",
      "accuracy=0.961483359336853, counts=[[19517   431     0     0]\n",
      " [  131 19071   817     1]\n",
      " [    0   896 19101    35]]\n",
      "Epoch=13, total_epoch_step_time=80.18, loss=612.47\n",
      "accuracy=0.963699996471405, counts=[[19595   353     0     0]\n",
      " [  123 19066   831     0]\n",
      " [    0   838 19161    33]]\n",
      "Epoch=14, total_epoch_step_time=85.58, loss=615.12\n",
      "accuracy=0.9668000340461731, counts=[[19660   288     0     0]\n",
      " [   98 19074   847     1]\n",
      " [    1   716 19274    41]]\n",
      "Epoch=15, total_epoch_step_time=91.00, loss=617.26\n",
      "accuracy=0.968583345413208, counts=[[19707   241     0     0]\n",
      " [   85 19128   807     0]\n",
      " [    0   717 19280    35]]\n",
      "Epoch=16, total_epoch_step_time=96.12, loss=619.25\n",
      "accuracy=0.9712666869163513, counts=[[19719   229     0     0]\n",
      " [   77 19222   721     0]\n",
      " [    0   670 19335    27]]\n",
      "Epoch=17, total_epoch_step_time=101.24, loss=620.96\n",
      "accuracy=0.9745166897773743, counts=[[19750   197     1     0]\n",
      " [   53 19452   515     0]\n",
      " [    0   746 19269    17]]\n",
      "Epoch=18, total_epoch_step_time=106.36, loss=622.57\n",
      "accuracy=0.9752333164215088, counts=[[19790   158     0     0]\n",
      " [   43 19387   590     0]\n",
      " [    0   670 19337    25]]\n",
      "Epoch=19, total_epoch_step_time=111.48, loss=623.96\n",
      "accuracy=0.9757166504859924, counts=[[19778   170     0     0]\n",
      " [   46 19390   584     0]\n",
      " [    0   631 19375    26]]\n",
      "Epoch=20, total_epoch_step_time=116.60, loss=625.40\n",
      "accuracy=0.9764833450317383, counts=[[19810   138     0     0]\n",
      " [   29 19517   474     0]\n",
      " [    0   754 19262    16]]\n",
      "Epoch=21, total_epoch_step_time=122.06, loss=626.60\n",
      "accuracy=0.9766666889190674, counts=[[19810   138     0     0]\n",
      " [   26 19508   486     0]\n",
      " [    0   733 19282    17]]\n",
      "Epoch=22, total_epoch_step_time=127.30, loss=627.68\n",
      "accuracy=0.9777500033378601, counts=[[19810   138     0     0]\n",
      " [   33 19513   474     0]\n",
      " [    0   671 19342    19]]\n",
      "Epoch=23, total_epoch_step_time=133.05, loss=628.79\n",
      "accuracy=0.978950023651123, counts=[[19845   103     0     0]\n",
      " [   22 19591   407     0]\n",
      " [    0   716 19301    15]]\n",
      "Epoch=24, total_epoch_step_time=138.71, loss=629.63\n",
      "accuracy=0.9799000024795532, counts=[[19848   100     0     0]\n",
      " [   27 19597   396     0]\n",
      " [    0   669 19349    14]]\n",
      "Epoch=25, total_epoch_step_time=143.84, loss=630.52\n",
      "accuracy=0.9802833199501038, counts=[[19855    93     0     0]\n",
      " [   26 19570   424     0]\n",
      " [    0   624 19392    16]]\n",
      "Epoch=26, total_epoch_step_time=149.49, loss=631.26\n",
      "accuracy=0.9802166819572449, counts=[[19849    99     0     0]\n",
      " [   17 19619   384     0]\n",
      " [    0   669 19345    18]]\n",
      "Epoch=27, total_epoch_step_time=155.11, loss=632.04\n",
      "accuracy=0.9805166721343994, counts=[[19840   108     0     0]\n",
      " [   20 19568   431     1]\n",
      " [    0   595 19423    14]]\n",
      "Epoch=28, total_epoch_step_time=160.70, loss=632.74\n",
      "accuracy=0.9808000326156616, counts=[[19853    95     0     0]\n",
      " [   21 19586   413     0]\n",
      " [    0   607 19409    16]]\n",
      "Epoch=29, total_epoch_step_time=166.32, loss=633.37\n",
      "accuracy=0.9814833402633667, counts=[[19880    68     0     0]\n",
      " [   15 19652   353     0]\n",
      " [    0   659 19357    16]]\n",
      "Epoch=30, total_epoch_step_time=171.56, loss=634.03\n",
      "accuracy=0.9817500114440918, counts=[[19871    77     0     0]\n",
      " [   11 19641   368     0]\n",
      " [    0   625 19393    14]]\n",
      "Epoch=31, total_epoch_step_time=176.77, loss=634.54\n",
      "accuracy=0.9818000197410583, counts=[[19894    54     0     0]\n",
      " [   16 19700   304     0]\n",
      " [    0   702 19314    16]]\n",
      "Epoch=32, total_epoch_step_time=182.53, loss=634.99\n",
      "accuracy=0.9830999970436096, counts=[[19879    69     0     0]\n",
      " [   10 19682   328     0]\n",
      " [    0   595 19425    12]]\n",
      "Epoch=33, total_epoch_step_time=188.32, loss=635.53\n",
      "accuracy=0.9825500249862671, counts=[[19883    65     0     0]\n",
      " [   10 19660   350     0]\n",
      " [    0   611 19410    11]]\n",
      "Epoch=34, total_epoch_step_time=194.26, loss=636.05\n",
      "accuracy=0.9832167029380798, counts=[[19887    61     0     0]\n",
      " [    9 19660   351     0]\n",
      " [    0   577 19446     9]]\n",
      "Epoch=35, total_epoch_step_time=199.92, loss=636.45\n",
      "accuracy=0.9831666946411133, counts=[[19890    58     0     0]\n",
      " [    7 19679   334     0]\n",
      " [    0   599 19421    12]]\n",
      "Epoch=36, total_epoch_step_time=205.12, loss=636.83\n",
      "accuracy=0.9835166931152344, counts=[[19876    72     0     0]\n",
      " [   10 19650   360     0]\n",
      " [    0   533 19485    14]]\n",
      "Epoch=37, total_epoch_step_time=210.30, loss=637.22\n",
      "accuracy=0.9833333492279053, counts=[[19889    59     0     0]\n",
      " [    7 19683   330     0]\n",
      " [    0   587 19428    17]]\n",
      "Epoch=38, total_epoch_step_time=215.48, loss=637.62\n",
      "accuracy=0.983916699886322, counts=[[19899    49     0     0]\n",
      " [   14 19709   297     0]\n",
      " [    0   592 19427    13]]\n",
      "Epoch=39, total_epoch_step_time=220.65, loss=638.02\n",
      "accuracy=0.9836166501045227, counts=[[19887    61     0     0]\n",
      " [    7 19728   285     0]\n",
      " [    0   617 19402    13]]\n",
      "Epoch=40, total_epoch_step_time=225.83, loss=638.25\n",
      "accuracy=0.9842666983604431, counts=[[19894    54     0     0]\n",
      " [   12 19661   347     0]\n",
      " [    0   517 19501    14]]\n",
      "Epoch=0, total_epoch_step_time=5.54, loss=273.37\n",
      "accuracy=0.23608332872390747, counts=[[11567  7378   975    28]\n",
      " [17351  2590    78     1]\n",
      " [19140   884     8     0]]\n",
      "Epoch=1, total_epoch_step_time=11.15, loss=429.25\n",
      "accuracy=0.25718334317207336, counts=[[11844  6918  1115    71]\n",
      " [16301  3464   245    10]\n",
      " [17409  2497   123     3]]\n",
      "Epoch=2, total_epoch_step_time=16.35, loss=452.83\n",
      "accuracy=0.39419999718666077, counts=[[12090  6535  1246    77]\n",
      " [ 9276  7354  2597   793]\n",
      " [ 6022  6679  4208  3123]]\n",
      "Epoch=3, total_epoch_step_time=21.46, loss=481.32\n",
      "accuracy=0.5246666669845581, counts=[[12504  6477   942    25]\n",
      " [ 2930  8110  8303   677]\n",
      " [  729  2684 10866  5753]]\n",
      "Epoch=4, total_epoch_step_time=26.84, loss=510.11\n",
      "accuracy=0.7143499851226807, counts=[[13288  6372   286     2]\n",
      " [ 1168 14389  4401    62]\n",
      " [  182  3080 15184  1586]]\n",
      "Epoch=5, total_epoch_step_time=32.51, loss=538.33\n",
      "accuracy=0.8069666624069214, counts=[[14936  4943    67     2]\n",
      " [  642 16473  2889    16]\n",
      " [   61  2152 17009   810]]\n",
      "Epoch=6, total_epoch_step_time=38.21, loss=556.21\n",
      "accuracy=0.8669833540916443, counts=[[16676  3246    26     0]\n",
      " [  496 17675  1833    16]\n",
      " [   16  1969 17668   379]]\n",
      "Epoch=7, total_epoch_step_time=43.96, loss=572.22\n",
      "accuracy=0.9085333347320557, counts=[[17929  2011     8     0]\n",
      " [  334 18297  1385     4]\n",
      " [   17  1449 18286   280]]\n",
      "Epoch=8, total_epoch_step_time=49.08, loss=583.65\n",
      "accuracy=0.9288833141326904, counts=[[18544  1404     0     0]\n",
      " [  266 18714  1039     1]\n",
      " [    6  1308 18475   243]]\n",
      "Epoch=9, total_epoch_step_time=54.20, loss=591.83\n",
      "accuracy=0.9438333511352539, counts=[[18951   996     1     0]\n",
      " [  201 18882   935     2]\n",
      " [    0  1037 18797   198]]\n",
      "Epoch=10, total_epoch_step_time=60.01, loss=597.94\n",
      "accuracy=0.9518499970436096, counts=[[19224   724     0     0]\n",
      " [  163 19071   785     1]\n",
      " [    2  1066 18816   148]]\n",
      "Epoch=11, total_epoch_step_time=65.54, loss=602.89\n",
      "accuracy=0.9592166543006897, counts=[[19367   580     1     0]\n",
      " [  149 19172   698     1]\n",
      " [    1   870 19014   147]]\n",
      "Epoch=12, total_epoch_step_time=71.34, loss=606.83\n",
      "accuracy=0.9628666639328003, counts=[[19526   421     1     0]\n",
      " [  137 19443   437     3]\n",
      " [    0  1097 18803   132]]\n",
      "Epoch=13, total_epoch_step_time=76.68, loss=610.15\n",
      "accuracy=0.9663666486740112, counts=[[19575   373     0     0]\n",
      " [  106 19560   353     1]\n",
      " [    0  1094 18847    91]]\n",
      "Epoch=14, total_epoch_step_time=82.29, loss=612.94\n",
      "accuracy=0.9675500392913818, counts=[[19635   313     0     0]\n",
      " [   90 19417   512     1]\n",
      " [    0   912 19001   119]]\n",
      "Epoch=15, total_epoch_step_time=87.82, loss=615.11\n",
      "accuracy=0.971833348274231, counts=[[19706   242     0     0]\n",
      " [   62 19510   447     1]\n",
      " [    0   810 19094   128]]\n",
      "Epoch=16, total_epoch_step_time=93.38, loss=617.17\n",
      "accuracy=0.972599983215332, counts=[[19699   249     0     0]\n",
      " [   63 19527   429     1]\n",
      " [    0   799 19130   103]]\n",
      "Epoch=17, total_epoch_step_time=98.80, loss=618.88\n",
      "accuracy=0.9743500351905823, counts=[[19759   189     0     0]\n",
      " [   49 19628   343     0]\n",
      " [    0   860 19074    98]]\n",
      "Epoch=18, total_epoch_step_time=104.07, loss=620.41\n",
      "accuracy=0.9761000275611877, counts=[[19786   162     0     0]\n",
      " [   39 19553   428     0]\n",
      " [    0   687 19227   118]]\n",
      "Epoch=19, total_epoch_step_time=109.19, loss=621.90\n",
      "accuracy=0.9765166640281677, counts=[[19804   144     0     0]\n",
      " [   44 19648   328     0]\n",
      " [    0   788 19139   105]]\n",
      "Epoch=20, total_epoch_step_time=114.48, loss=623.27\n",
      "accuracy=0.9768000245094299, counts=[[19791   157     0     0]\n",
      " [   42 19672   305     1]\n",
      " [    0   783 19145   104]]\n",
      "Epoch=21, total_epoch_step_time=119.74, loss=624.57\n",
      "accuracy=0.977233350276947, counts=[[19815   133     0     0]\n",
      " [   35 19629   356     0]\n",
      " [    0   771 19190    71]]\n",
      "Epoch=22, total_epoch_step_time=125.42, loss=625.73\n",
      "accuracy=0.9782333374023438, counts=[[19822   126     0     0]\n",
      " [   27 19701   292     0]\n",
      " [    2   785 19171    74]]\n",
      "Epoch=23, total_epoch_step_time=130.93, loss=626.68\n",
      "accuracy=0.9789167046546936, counts=[[19810   138     0     0]\n",
      " [   34 19626   360     0]\n",
      " [    0   631 19299   102]]\n",
      "Epoch=24, total_epoch_step_time=136.12, loss=627.71\n",
      "accuracy=0.979283332824707, counts=[[19832   116     0     0]\n",
      " [   30 19647   343     0]\n",
      " [    1   672 19278    81]]\n",
      "Epoch=25, total_epoch_step_time=141.30, loss=628.70\n",
      "accuracy=0.9800500273704529, counts=[[19844   104     0     0]\n",
      " [   25 19642   352     1]\n",
      " [    0   625 19317    90]]\n",
      "Epoch=26, total_epoch_step_time=146.48, loss=629.52\n",
      "accuracy=0.9807000160217285, counts=[[19852    96     0     0]\n",
      " [   15 19780   225     0]\n",
      " [    0   755 19210    67]]\n",
      "Epoch=27, total_epoch_step_time=151.66, loss=630.33\n",
      "accuracy=0.9803667068481445, counts=[[19837   111     0     0]\n",
      " [   23 19716   280     1]\n",
      " [    0   681 19269    82]]\n",
      "Epoch=28, total_epoch_step_time=156.83, loss=631.02\n",
      "accuracy=0.9815166592597961, counts=[[19870    78     0     0]\n",
      " [   14 19729   277     0]\n",
      " [    0   650 19292    90]]\n",
      "Epoch=29, total_epoch_step_time=162.01, loss=631.75\n",
      "accuracy=0.980733335018158, counts=[[19833   115     0     0]\n",
      " [   13 19730   277     0]\n",
      " [    0   668 19281    83]]\n",
      "Epoch=30, total_epoch_step_time=167.18, loss=632.49\n",
      "accuracy=0.9821833372116089, counts=[[19883    65     0     0]\n",
      " [   11 19748   261     0]\n",
      " [    0   658 19300    74]]\n",
      "Epoch=31, total_epoch_step_time=172.36, loss=633.11\n",
      "accuracy=0.9813500046730042, counts=[[19865    83     0     0]\n",
      " [   12 19783   225     0]\n",
      " [    0   725 19233    74]]\n",
      "Epoch=32, total_epoch_step_time=177.53, loss=633.66\n",
      "accuracy=0.9822999835014343, counts=[[19876    72     0     0]\n",
      " [   21 19799   200     0]\n",
      " [    0   687 19263    82]]\n",
      "Epoch=33, total_epoch_step_time=182.70, loss=634.22\n",
      "accuracy=0.9820833206176758, counts=[[19881    67     0     0]\n",
      " [    7 19764   249     0]\n",
      " [    0   658 19280    94]]\n",
      "Epoch=34, total_epoch_step_time=187.88, loss=634.75\n",
      "accuracy=0.9831666946411133, counts=[[19873    75     0     0]\n",
      " [    6 19807   207     0]\n",
      " [    0   649 19310    73]]\n",
      "Epoch=35, total_epoch_step_time=193.06, loss=635.23\n",
      "accuracy=0.9819000363349915, counts=[[19878    70     0     0]\n",
      " [   13 19767   239     1]\n",
      " [    0   690 19269    73]]\n",
      "Epoch=36, total_epoch_step_time=198.23, loss=635.65\n",
      "accuracy=0.9830166697502136, counts=[[19880    68     0     0]\n",
      " [    8 19749   263     0]\n",
      " [    0   581 19352    99]]\n",
      "Epoch=37, total_epoch_step_time=203.40, loss=636.12\n",
      "accuracy=0.9826666712760925, counts=[[19890    58     0     0]\n",
      " [    6 19807   207     0]\n",
      " [    0   693 19263    76]]\n",
      "Epoch=38, total_epoch_step_time=208.58, loss=636.55\n",
      "accuracy=0.982783317565918, counts=[[19895    53     0     0]\n",
      " [   10 19818   192     0]\n",
      " [    0   708 19254    70]]\n",
      "Epoch=39, total_epoch_step_time=213.75, loss=636.85\n",
      "accuracy=0.9837999939918518, counts=[[19901    47     0     0]\n",
      " [    8 19772   240     0]\n",
      " [    0   600 19355    77]]\n",
      "Epoch=40, total_epoch_step_time=219.10, loss=637.21\n",
      "accuracy=0.9832833409309387, counts=[[19890    58     0     0]\n",
      " [    6 19812   202     0]\n",
      " [    0   664 19295    73]]\n",
      "Epoch=0, total_epoch_step_time=5.15, loss=275.82\n",
      "accuracy=0.23661667108535767, counts=[[11643  7419   850    36]\n",
      " [17394  2545    79     2]\n",
      " [19170   853     9     0]]\n",
      "Epoch=1, total_epoch_step_time=10.26, loss=429.68\n",
      "accuracy=0.25903332233428955, counts=[[11970  6826  1100    52]\n",
      " [16346  3444   217    13]\n",
      " [17622  2276   128     6]]\n",
      "Epoch=2, total_epoch_step_time=15.39, loss=453.18\n",
      "accuracy=0.4034833312034607, counts=[[12187  6501  1190    70]\n",
      " [ 9381  7670  2382   587]\n",
      " [ 6176  7084  4352  2420]]\n",
      "Epoch=3, total_epoch_step_time=20.50, loss=482.97\n",
      "accuracy=0.5417500138282776, counts=[[12620  6459   853    16]\n",
      " [ 2704  8512  8254   550]\n",
      " [  723  2609 11373  5327]]\n",
      "Epoch=4, total_epoch_step_time=25.61, loss=515.94\n",
      "accuracy=0.7211666703224182, counts=[[13252  6453   242     1]\n",
      " [ 1107 14490  4367    56]\n",
      " [  147  2787 15528  1570]]\n",
      "Epoch=5, total_epoch_step_time=31.35, loss=545.45\n",
      "accuracy=0.8117499947547913, counts=[[14623  5263    60     2]\n",
      " [  645 16587  2769    19]\n",
      " [   53  1949 17495   535]]\n",
      "Epoch=6, total_epoch_step_time=36.80, loss=564.93\n",
      "accuracy=0.8667500019073486, counts=[[16723  3211    14     0]\n",
      " [  471 17114  2428     7]\n",
      " [   28  1380 18168   456]]\n",
      "Epoch=7, total_epoch_step_time=42.13, loss=580.23\n",
      "accuracy=0.9025999903678894, counts=[[17992  1948     8     0]\n",
      " [  348 17513  2157     2]\n",
      " [   18  1088 18651   275]]\n",
      "Epoch=8, total_epoch_step_time=47.50, loss=589.37\n",
      "accuracy=0.9243333339691162, counts=[[18646  1299     3     0]\n",
      " [  277 18010  1732     1]\n",
      " [    4  1065 18804   159]]\n",
      "Epoch=9, total_epoch_step_time=52.77, loss=596.12\n",
      "accuracy=0.9382500052452087, counts=[[19031   917     0     0]\n",
      " [  225 18326  1466     3]\n",
      " [    6   976 18938   112]]\n",
      "Epoch=10, total_epoch_step_time=58.47, loss=601.10\n",
      "accuracy=0.9486833214759827, counts=[[19241   707     0     0]\n",
      " [  179 18743  1097     1]\n",
      " [    2   995 18937    98]]\n",
      "Epoch=11, total_epoch_step_time=64.79, loss=605.26\n",
      "accuracy=0.9523333311080933, counts=[[19392   556     0     0]\n",
      " [  139 18647  1233     1]\n",
      " [    0   843 19101    88]]\n",
      "Epoch=12, total_epoch_step_time=71.05, loss=608.82\n",
      "accuracy=0.9591166973114014, counts=[[19521   427     0     0]\n",
      " [  134 18957   926     3]\n",
      " [    0   906 19069    57]]\n",
      "Epoch=13, total_epoch_step_time=76.31, loss=611.84\n",
      "accuracy=0.9634667038917542, counts=[[19590   358     0     0]\n",
      " [  100 19026   893     1]\n",
      " [    1   777 19192    62]]\n",
      "Epoch=14, total_epoch_step_time=81.43, loss=614.19\n",
      "accuracy=0.9669166803359985, counts=[[19652   295     1     0]\n",
      " [   81 19127   811     1]\n",
      " [    0   750 19236    46]]\n",
      "Epoch=15, total_epoch_step_time=86.55, loss=616.22\n",
      "accuracy=0.9680833220481873, counts=[[19700   248     0     0]\n",
      " [   71 19390   558     1]\n",
      " [    0   995 18995    42]]\n",
      "Epoch=16, total_epoch_step_time=91.68, loss=617.93\n",
      "accuracy=0.9706500172615051, counts=[[19723   225     0     0]\n",
      " [   52 19355   612     1]\n",
      " [    0   833 19161    38]]\n",
      "Epoch=17, total_epoch_step_time=96.81, loss=619.64\n",
      "accuracy=0.9715499877929688, counts=[[19749   199     0     0]\n",
      " [   49 19304   665     2]\n",
      " [    0   753 19240    39]]\n",
      "Epoch=18, total_epoch_step_time=101.94, loss=621.14\n",
      "accuracy=0.973383367061615, counts=[[19792   156     0     0]\n",
      " [   58 19331   631     0]\n",
      " [    0   708 19280    44]]\n",
      "Epoch=19, total_epoch_step_time=107.07, loss=622.51\n",
      "accuracy=0.9732666611671448, counts=[[19760   188     0     0]\n",
      " [   44 19388   588     0]\n",
      " [    0   745 19248    39]]\n",
      "Epoch=20, total_epoch_step_time=112.20, loss=623.81\n",
      "accuracy=0.9741166830062866, counts=[[19811   137     0     0]\n",
      " [   39 19281   699     1]\n",
      " [    0   631 19355    46]]\n",
      "Epoch=21, total_epoch_step_time=117.33, loss=624.91\n",
      "accuracy=0.975516676902771, counts=[[19803   145     0     0]\n",
      " [   32 19408   580     0]\n",
      " [    0   668 19320    44]]\n",
      "Epoch=22, total_epoch_step_time=122.45, loss=626.09\n",
      "accuracy=0.9760833382606506, counts=[[19817   131     0     0]\n",
      " [   26 19375   618     1]\n",
      " [    0   621 19373    38]]\n",
      "Epoch=23, total_epoch_step_time=127.59, loss=627.07\n",
      "accuracy=0.9763333201408386, counts=[[19813   135     0     0]\n",
      " [   37 19441   542     0]\n",
      " [    0   671 19326    35]]\n",
      "Epoch=24, total_epoch_step_time=132.72, loss=627.92\n",
      "accuracy=0.9770333170890808, counts=[[19813   135     0     0]\n",
      " [   20 19374   626     0]\n",
      " [    0   553 19435    44]]\n",
      "Epoch=25, total_epoch_step_time=137.84, loss=628.97\n",
      "accuracy=0.9791499972343445, counts=[[19843   105     0     0]\n",
      " [   24 19548   448     0]\n",
      " [    0   641 19358    33]]\n",
      "Epoch=26, total_epoch_step_time=142.96, loss=629.74\n",
      "accuracy=0.9786999821662903, counts=[[19836   112     0     0]\n",
      " [   25 19488   507     0]\n",
      " [    0   601 19398    33]]\n",
      "Epoch=27, total_epoch_step_time=148.09, loss=630.48\n",
      "accuracy=0.9791666865348816, counts=[[19847   101     0     0]\n",
      " [   19 19508   493     0]\n",
      " [    0   600 19395    37]]\n",
      "Epoch=28, total_epoch_step_time=153.21, loss=631.19\n",
      "accuracy=0.9793000221252441, counts=[[19870    78     0     0]\n",
      " [   18 19600   402     0]\n",
      " [    0   711 19288    33]]\n",
      "Epoch=29, total_epoch_step_time=158.33, loss=631.93\n",
      "accuracy=0.9802166819572449, counts=[[19838   110     0     0]\n",
      " [   17 19547   455     1]\n",
      " [    0   570 19428    34]]\n",
      "Epoch=30, total_epoch_step_time=163.45, loss=632.61\n",
      "accuracy=0.9805999994277954, counts=[[19848   100     0     0]\n",
      " [   14 19619   387     0]\n",
      " [    0   633 19369    30]]\n",
      "Epoch=31, total_epoch_step_time=168.57, loss=633.17\n",
      "accuracy=0.9811833500862122, counts=[[19871    77     0     0]\n",
      " [   16 19648   356     0]\n",
      " [    0   646 19352    34]]\n",
      "Epoch=32, total_epoch_step_time=173.69, loss=633.73\n",
      "accuracy=0.9809666872024536, counts=[[19865    83     0     0]\n",
      " [   18 19628   374     0]\n",
      " [    0   630 19365    37]]\n",
      "Epoch=33, total_epoch_step_time=178.83, loss=634.32\n",
      "accuracy=0.9814333319664001, counts=[[19869    79     0     0]\n",
      " [   14 19619   387     0]\n",
      " [    0   593 19398    41]]\n",
      "Epoch=34, total_epoch_step_time=183.95, loss=634.83\n",
      "accuracy=0.9816166758537292, counts=[[19882    66     0     0]\n",
      " [   16 19636   367     1]\n",
      " [    0   617 19379    36]]\n",
      "Epoch=35, total_epoch_step_time=189.06, loss=635.22\n",
      "accuracy=0.9812833666801453, counts=[[19860    88     0     0]\n",
      " [   13 19596   411     0]\n",
      " [    0   578 19421    33]]\n",
      "Epoch=36, total_epoch_step_time=194.20, loss=635.76\n",
      "accuracy=0.9815333485603333, counts=[[19891    57     0     0]\n",
      " [   16 19587   417     0]\n",
      " [    0   584 19414    34]]\n",
      "Epoch=37, total_epoch_step_time=199.32, loss=636.21\n",
      "accuracy=0.98211669921875, counts=[[19871    77     0     0]\n",
      " [   12 19653   355     0]\n",
      " [    0   595 19403    34]]\n",
      "Epoch=38, total_epoch_step_time=204.45, loss=636.54\n",
      "accuracy=0.9817333221435547, counts=[[19876    72     0     0]\n",
      " [   10 19604   406     0]\n",
      " [    0   570 19424    38]]\n",
      "Epoch=39, total_epoch_step_time=209.57, loss=636.97\n",
      "accuracy=0.9825167059898376, counts=[[19884    64     0     0]\n",
      " [    9 19658   352     1]\n",
      " [    0   585 19409    38]]\n",
      "Epoch=40, total_epoch_step_time=214.70, loss=637.30\n",
      "accuracy=0.9826833605766296, counts=[[19875    73     0     0]\n",
      " [    9 19665   346     0]\n",
      " [    0   574 19421    37]]\n",
      "Epoch=0, total_epoch_step_time=5.15, loss=274.03\n",
      "accuracy=0.23483332991600037, counts=[[11429  7461  1008    50]\n",
      " [17283  2647    90     0]\n",
      " [19053   965    14     0]]\n",
      "Epoch=1, total_epoch_step_time=10.27, loss=429.59\n",
      "accuracy=0.2619999945163727, counts=[[11988  6727  1157    76]\n",
      " [16190  3571   252     7]\n",
      " [17182  2684   161     5]]\n",
      "Epoch=2, total_epoch_step_time=15.38, loss=453.68\n",
      "accuracy=0.39781665802001953, counts=[[11956  6608  1300    84]\n",
      " [ 8943  7524  2736   817]\n",
      " [ 5733  6723  4389  3187]]\n",
      "Epoch=3, total_epoch_step_time=20.49, loss=483.01\n",
      "accuracy=0.5262333154678345, counts=[[12363  6556  1007    22]\n",
      " [ 2669  8194  8508   649]\n",
      " [  703  2524 11017  5788]]\n",
      "Epoch=4, total_epoch_step_time=25.60, loss=518.21\n",
      "accuracy=0.7039999961853027, counts=[[13225  6395   328     0]\n",
      " [ 1050 12551  6353    66]\n",
      " [  111  2207 16464  1250]]\n",
      "Epoch=5, total_epoch_step_time=30.72, loss=547.68\n",
      "accuracy=0.767383337020874, counts=[[14637  5193   118     0]\n",
      " [  589 13481  5917    33]\n",
      " [   38  1651 17925   418]]\n",
      "Epoch=6, total_epoch_step_time=35.85, loss=565.13\n",
      "accuracy=0.8088499903678894, counts=[[16469  3456    23     0]\n",
      " [  429 13254  6315    22]\n",
      " [   21   888 18808   315]]\n",
      "Epoch=7, total_epoch_step_time=40.97, loss=579.26\n",
      "accuracy=0.8525333404541016, counts=[[17812  2133     3     0]\n",
      " [  349 14353  5312     6]\n",
      " [   13   868 18987   164]]\n",
      "Epoch=8, total_epoch_step_time=46.09, loss=590.10\n",
      "accuracy=0.8823833465576172, counts=[[18507  1440     1     0]\n",
      " [  295 15390  4330     5]\n",
      " [    8   894 19046    84]]\n",
      "Epoch=9, total_epoch_step_time=51.22, loss=597.14\n",
      "accuracy=0.9003999829292297, counts=[[18966   981     1     0]\n",
      " [  212 15828  3978     2]\n",
      " [    2   750 19230    50]]\n",
      "Epoch=10, total_epoch_step_time=56.34, loss=602.50\n",
      "accuracy=0.9134500026702881, counts=[[19211   737     0     0]\n",
      " [  188 16433  3397     2]\n",
      " [    2   839 19163    28]]\n",
      "Epoch=11, total_epoch_step_time=61.46, loss=606.57\n",
      "accuracy=0.9207500219345093, counts=[[19366   582     0     0]\n",
      " [  125 16530  3363     2]\n",
      " [    1   664 19349    18]]\n",
      "Epoch=12, total_epoch_step_time=66.58, loss=609.92\n",
      "accuracy=0.9323333501815796, counts=[[19509   439     0     0]\n",
      " [  123 17286  2611     0]\n",
      " [    0   871 19145    16]]\n",
      "Epoch=13, total_epoch_step_time=71.71, loss=612.61\n",
      "accuracy=0.9324166774749756, counts=[[19564   384     0     0]\n",
      " [  100 17001  2918     1]\n",
      " [    0   636 19380    16]]\n",
      "Epoch=14, total_epoch_step_time=76.83, loss=615.00\n",
      "accuracy=0.9444666504859924, counts=[[19677   271     0     0]\n",
      " [   78 17728  2214     0]\n",
      " [    0   758 19263    11]]\n",
      "Epoch=15, total_epoch_step_time=81.95, loss=617.29\n",
      "accuracy=0.9471666812896729, counts=[[19731   217     0     0]\n",
      " [   90 17779  2150     1]\n",
      " [    0   703 19320     9]]\n",
      "Epoch=16, total_epoch_step_time=87.07, loss=619.33\n",
      "accuracy=0.9538000226020813, counts=[[19728   218     2     0]\n",
      " [   65 18203  1752     0]\n",
      " [    0   727 19297     8]]\n",
      "Epoch=17, total_epoch_step_time=92.20, loss=621.02\n",
      "accuracy=0.960099995136261, counts=[[19773   175     0     0]\n",
      " [   50 18508  1462     0]\n",
      " [    0   699 19325     8]]\n",
      "Epoch=18, total_epoch_step_time=97.32, loss=622.57\n",
      "accuracy=0.9598333239555359, counts=[[19753   195     0     0]\n",
      " [   43 18460  1517     0]\n",
      " [    0   648 19377     7]]\n",
      "Epoch=19, total_epoch_step_time=102.44, loss=624.03\n",
      "accuracy=0.9682999849319458, counts=[[19774   174     0     0]\n",
      " [   44 19073   903     0]\n",
      " [    0   777 19251     4]]\n",
      "Epoch=20, total_epoch_step_time=107.57, loss=625.51\n",
      "accuracy=0.9725833535194397, counts=[[19815   133     0     0]\n",
      " [   44 19332   644     0]\n",
      " [    0   819 19208     5]]\n",
      "Epoch=21, total_epoch_step_time=112.72, loss=626.88\n",
      "accuracy=0.9738667011260986, counts=[[19804   144     0     0]\n",
      " [   39 19356   625     0]\n",
      " [    0   757 19272     3]]\n",
      "Epoch=22, total_epoch_step_time=117.84, loss=628.03\n",
      "accuracy=0.9760000109672546, counts=[[19820   128     0     0]\n",
      " [   23 19421   576     0]\n",
      " [    0   709 19319     4]]\n",
      "Epoch=23, total_epoch_step_time=122.97, loss=629.17\n",
      "accuracy=0.9763500094413757, counts=[[19822   126     0     0]\n",
      " [   21 19410   589     0]\n",
      " [    0   679 19349     4]]\n",
      "Epoch=24, total_epoch_step_time=128.09, loss=630.06\n",
      "accuracy=0.9772999882698059, counts=[[19837   111     0     0]\n",
      " [   30 19446   543     1]\n",
      " [    0   673 19355     4]]\n",
      "Epoch=25, total_epoch_step_time=133.21, loss=631.00\n",
      "accuracy=0.9774333238601685, counts=[[19824   124     0     0]\n",
      " [   26 19361   632     1]\n",
      " [    0   565 19461     6]]\n",
      "Epoch=26, total_epoch_step_time=138.33, loss=631.84\n",
      "accuracy=0.9783999919891357, counts=[[19834   114     0     0]\n",
      " [   22 19420   578     0]\n",
      " [    1   575 19450     6]]\n",
      "Epoch=27, total_epoch_step_time=143.46, loss=632.57\n",
      "accuracy=0.978950023651123, counts=[[19847   101     0     0]\n",
      " [   20 19553   447     0]\n",
      " [    0   688 19337     7]]\n",
      "Epoch=28, total_epoch_step_time=148.58, loss=633.33\n",
      "accuracy=0.9782833456993103, counts=[[19853    95     0     0]\n",
      " [   28 19611   381     0]\n",
      " [    0   793 19233     6]]\n",
      "Epoch=29, total_epoch_step_time=153.70, loss=633.87\n",
      "accuracy=0.9801166653633118, counts=[[19850    98     0     0]\n",
      " [   11 19461   548     0]\n",
      " [    0   529 19496     7]]\n",
      "Epoch=30, total_epoch_step_time=158.82, loss=634.44\n",
      "accuracy=0.9802666902542114, counts=[[19852    96     0     0]\n",
      " [   19 19578   423     0]\n",
      " [    0   643 19386     3]]\n",
      "Epoch=31, total_epoch_step_time=163.94, loss=635.03\n",
      "accuracy=0.9800166487693787, counts=[[19848   100     0     0]\n",
      " [   21 19481   518     0]\n",
      " [    0   557 19472     3]]\n",
      "Epoch=32, total_epoch_step_time=169.06, loss=635.51\n",
      "accuracy=0.9815333485603333, counts=[[19872    76     0     0]\n",
      " [   13 19558   449     0]\n",
      " [    0   567 19462     3]]\n",
      "Epoch=33, total_epoch_step_time=174.18, loss=635.99\n",
      "accuracy=0.9805999994277954, counts=[[19865    83     0     0]\n",
      " [   13 19540   467     0]\n",
      " [    0   596 19431     5]]\n",
      "Epoch=34, total_epoch_step_time=179.30, loss=636.38\n",
      "accuracy=0.981249988079071, counts=[[19876    72     0     0]\n",
      " [   11 19529   480     0]\n",
      " [    0   559 19470     3]]\n",
      "Epoch=35, total_epoch_step_time=184.42, loss=636.88\n",
      "accuracy=0.9819833636283875, counts=[[19863    85     0     0]\n",
      " [    7 19546   467     0]\n",
      " [    0   519 19510     3]]\n",
      "Epoch=36, total_epoch_step_time=189.54, loss=637.27\n",
      "accuracy=0.9824000000953674, counts=[[19875    73     0     0]\n",
      " [   11 19604   405     0]\n",
      " [    0   564 19465     3]]\n",
      "Epoch=37, total_epoch_step_time=194.66, loss=637.62\n",
      "accuracy=0.9828667044639587, counts=[[19880    68     0     0]\n",
      " [   13 19614   392     1]\n",
      " [    0   551 19478     3]]\n",
      "Epoch=38, total_epoch_step_time=199.78, loss=638.00\n",
      "accuracy=0.9826333522796631, counts=[[19883    65     0     0]\n",
      " [    6 19676   338     0]\n",
      " [    0   631 19399     2]]\n",
      "Epoch=39, total_epoch_step_time=204.90, loss=638.27\n",
      "accuracy=0.9832666516304016, counts=[[19897    51     0     0]\n",
      " [   14 19619   387     0]\n",
      " [    0   548 19480     4]]\n",
      "Epoch=40, total_epoch_step_time=210.02, loss=638.65\n",
      "accuracy=0.9828667044639587, counts=[[19892    56     0     0]\n",
      " [   17 19662   341     0]\n",
      " [    0   609 19418     5]]\n"
     ]
    }
   ],
   "source": [
    "# Run with different random seeds.\n",
    "losses, accuracy, wall_clock_times = None, None, None\n",
    "for train_idx in range(0, 5):\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    r_loss, r_acc, r_times, params = train(\n",
    "        sub_key, learning_rate=1.0e-4, n=2, batch_size=64, num_epochs=40\n",
    "    )\n",
    "    # Save run.\n",
    "    arr = np.array([r_loss, r_acc, r_times])\n",
    "    df = pd.DataFrame(\n",
    "        arr.T,\n",
    "        columns=[\"ELBO loss\", \"Accuracy\", \"Epoch wall clock times\"],\n",
    "    )\n",
    "    df.to_csv(\n",
    "        f\"./training_runs/grasp_air_iwae_2_hybrid_mvd_enum_epochs_41_mccoy_prior_{train_idx}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    if losses is None:\n",
    "        losses = r_loss\n",
    "        accuracy = r_acc\n",
    "        wall_clock_times = r_times\n",
    "    else:\n",
    "        losses = np.vstack((losses, r_loss))\n",
    "        accuracy = np.vstack((accuracy, r_acc))\n",
    "        wall_clock_times = np.vstack((wall_clock_times, r_times))\n",
    "\n",
    "arr = np.array([losses, accuracy, wall_clock_times])\n",
    "mean_arr = jnp.mean(arr, axis=1)\n",
    "std_arr = jnp.std(arr, axis=1)\n",
    "df_arr = jnp.vstack((mean_arr, std_arr))\n",
    "df = pd.DataFrame(\n",
    "    df_arr.T,\n",
    "    columns=[\n",
    "        \"Mean ELBO loss\",\n",
    "        \"Mean accuracy\",\n",
    "        \"Mean epoch wall clock times\",\n",
    "        \"Std ELBO loss\",\n",
    "        \"Std accuracy\",\n",
    "        \"Std epoch wall clock times\",\n",
    "    ],\n",
    ")\n",
    "df.to_csv(\n",
    "    \"./training_runs/grasp_air_iwae_2_hybrid_mvd_enum_epochs_41_mccoy_prior.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
