{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92511a8b-aa9f-45de-88c2-b9a6f49cf370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import time\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from collections import namedtuple\n",
    "import pyro\n",
    "import optax\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "import pyro.contrib.examples.multi_mnist as multi_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from matplotlib import rcParams\n",
    "from scipy.interpolate import griddata\n",
    "import genjax\n",
    "from genjax import grasp\n",
    "from genjax import Pytree\n",
    "import equinox as eqx\n",
    "from genjax.typing import Any\n",
    "from genjax.typing import Tuple\n",
    "from genjax.typing import FloatArray\n",
    "from genjax.typing import Int\n",
    "from genjax.typing import IntArray\n",
    "from genjax.typing import PRNGKey\n",
    "from genjax.typing import typecheck\n",
    "from genjax import choice_map\n",
    "\n",
    "from numpyro.examples.datasets import MNIST\n",
    "from numpyro.examples.datasets import load_dataset\n",
    "\n",
    "import genjax\n",
    "from genjax import grasp\n",
    "from genjax import gensp\n",
    "from genjax import select\n",
    "\n",
    "import adevjax\n",
    "\n",
    "console = genjax.pretty()\n",
    "key = jax.random.PRNGKey(314159)\n",
    "sns.set_theme(style=\"white\")\n",
    "font_path = (\n",
    "    \"/home/femtomc/.local/share/fonts/Unknown Vendor/TrueType/Lato/Lato_Bold.ttf\"\n",
    ")\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "custom_font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rcParams[\"font.family\"] = custom_font_name\n",
    "rcParams[\"figure.autolayout\"] = True\n",
    "label_fontsize = 70  # Set the desired font size here\n",
    "\n",
    "train_init, train_fetch = load_dataset(MNIST, batch_size=4096, split=\"train\")\n",
    "num_train, train_idx = train_init()\n",
    "data_batch = train_fetch(0)[0]\n",
    "batch_sizes = [64, 128, 256, 512, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f045ffa8-bcb2-4a6b-bd6d-9772870a424f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilities for defining the model and the guide.\n",
    "@dataclass\n",
    "class Decoder(Pytree):\n",
    "    dense_1: Any\n",
    "    dense_2: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense_1, self.dense_2), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key1, key2):\n",
    "        dense_1 = eqx.nn.Linear(10, 200, key=key1)\n",
    "        dense_2 = eqx.nn.Linear(200, 28 * 28, key=key2)\n",
    "        return Decoder(dense_1, dense_2)\n",
    "\n",
    "    def __call__(self, z_what):\n",
    "        v = self.dense_1(z_what)\n",
    "        v = jax.nn.leaky_relu(v)\n",
    "        v = self.dense_2(v)\n",
    "        return jax.nn.sigmoid(v)\n",
    "\n",
    "\n",
    "# Create our decoder.\n",
    "key, sub_key1, sub_key2 = jax.random.split(key, 3)\n",
    "decoder = Decoder.new(sub_key1, sub_key2)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Encoder(Pytree):\n",
    "    dense_1: Any\n",
    "    dense_2: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense_1, self.dense_2), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key1, key2):\n",
    "        dense_1 = eqx.nn.Linear(28 * 28, 200, key=key1)\n",
    "        dense_2 = eqx.nn.Linear(200, 20, key=key2)\n",
    "        return Encoder(dense_1, dense_2)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        v = self.dense_1(data)\n",
    "        v = jax.nn.leaky_relu(v)\n",
    "        v = self.dense_2(v)\n",
    "        return v[0:10], jax.nn.softplus(v[10:])\n",
    "\n",
    "\n",
    "key, sub_key1, sub_key2 = jax.random.split(key, 3)\n",
    "encoder = Encoder.new(sub_key1, sub_key2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fa96c80-53c9-439a-be13-7c1cc57c55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@genjax.gen\n",
    "def model(decoder):\n",
    "    latent = genjax.tfp_mv_normal_diag(jnp.zeros(10), jnp.ones(10)) @ \"latent\"\n",
    "    logits = decoder(latent)\n",
    "    _ = genjax.tfp_bernoulli(logits) @ \"image\"\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "def guide(encoder, chm):\n",
    "    image = chm[\"image\"]\n",
    "    μ, Σ_scale = encoder(image)\n",
    "    _ = grasp.mv_normal_diag_reparam(μ, Σ_scale) @ \"latent\"\n",
    "\n",
    "\n",
    "def batch_elbo_grad_estimate(key, encoder, decoder, data_batch):\n",
    "    def _inner(key, encoder, decoder, data):\n",
    "        chm = choice_map({\"image\": data.flatten()})\n",
    "        objective = grasp.elbo(model, guide, chm)\n",
    "        return objective.grad_estimate(key, ((decoder,), (encoder, chm)))\n",
    "\n",
    "    sub_keys = jax.random.split(key, len(data_batch))\n",
    "    return jax.vmap(_inner, in_axes=(0, None, None, 0))(\n",
    "        sub_keys, encoder, decoder, data_batch\n",
    "    )\n",
    "\n",
    "\n",
    "jit1 = jax.jit(batch_elbo_grad_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "126c3c33-a970-4309-b97e-cac3b9bacf98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "grasp_runtime_over_batches = []\n",
    "std_ds = []\n",
    "for batch_size in batch_sizes:\n",
    "    print(batch_size)\n",
    "    train_init, train_fetch = load_dataset(MNIST, batch_size=batch_size, split=\"train\")\n",
    "    num_train, train_idx = train_init()\n",
    "    data_batch = train_fetch(0)[0]\n",
    "    durations = []\n",
    "    jit1(key, encoder, decoder, data_batch)\n",
    "    for i in range(0, 100):\n",
    "        t0 = time.perf_counter()\n",
    "        jit1(key, encoder, decoder, data_batch)\n",
    "        duration = time.perf_counter() - t0\n",
    "        durations.append(duration)\n",
    "    grasp_runtime_over_batches.append(jnp.mean(jnp.array(durations)))\n",
    "    std_ds.append(jnp.std(jnp.array(durations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3298eeb0-05e8-4dd8-a8e1-b5e32cb8f9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.11952992\u001b[0m, \u001b[1;36m0.22033532\u001b[0m, \u001b[1;36m0.31144744\u001b[0m, \u001b[1;36m0.56776536\u001b[0m, \u001b[1;36m1.5838046\u001b[0m \u001b[1m]\u001b[0m,\n",
       "      \u001b[33mdtype\u001b[0m=\u001b[35mfloat32\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0298365\u001b[0m , \u001b[1;36m0.22446465\u001b[0m, \u001b[1;36m0.18173508\u001b[0m, \u001b[1;36m0.35711813\u001b[0m, \u001b[1;36m1.1378889\u001b[0m \u001b[1m]\u001b[0m,\n",
       "      \u001b[33mdtype\u001b[0m=\u001b[35mfloat32\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1000 * np.array(grasp_runtime_over_batches), 1000 * np.array(std_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ab819-67ce-44b1-a250-59c987236a9e",
   "metadata": {},
   "source": [
    "@jax.jit\n",
    "def epoch_train(params, opt_state, key, train_idx):\n",
    "    def body_fn(carry, xs):\n",
    "        idx, opt_state, params = carry\n",
    "        updater_key = jax.random.fold_in(key, idx)\n",
    "        batch = train_fetch(idx, train_idx)[0]\n",
    "        ((decoder_grads,), (encoder_grads, _)) = batch_elbo_grad_estimate(\n",
    "            updater_key, encoder, decoder, batch\n",
    "        )\n",
    "        grads = (encoder_grads, decoder_grads)\n",
    "        grads = jtu.tree_map(lambda v: jnp.mean(v, axis=0), grads)\n",
    "        updates, opt_state = optax.adam(1e-3).update(grads, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        idx += 1\n",
    "        return (idx, opt_state, params), ()\n",
    "\n",
    "    idx = 0\n",
    "    (_, _, params), () = jax.lax.scan(\n",
    "        body_fn, (idx, opt_state, params), None, length=64\n",
    "    )\n",
    "    return params, 0.0\n",
    "\n",
    "\n",
    "params = (encoder, decoder)\n",
    "grasp_epoch_times = []\n",
    "for i in range(0, 500):\n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "    train_init, train_fetch = load_dataset(MNIST, batch_size=64, split=\"train\")\n",
    "    adam = optax.adam(1e-3)\n",
    "    opt_state = adam.init(params)\n",
    "    num_batch, train_idx = train_init()\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    t0 = time.perf_counter()\n",
    "    params, loss = epoch_train(params, opt_state, sub_key, train_idx)\n",
    "    duration = time.perf_counter() - t0\n",
    "    if i != 0:\n",
    "        grasp_epoch_times.append(duration)\n",
    "\n",
    "grasp_epoch_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94ba9569-09e4-483b-9e83-dfd2e45926a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow_probability.substrates import jax as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "MvNormalDiag = tfd.MultivariateNormalDiag\n",
    "Bernoulli = tfd.Bernoulli\n",
    "\n",
    "# Manual.\n",
    "def batch_elbo_grad_estimate(key, encoder, decoder, data_batch):\n",
    "    def single_estimate(key, encoder, decoder, data):\n",
    "        image = data.flatten()\n",
    "\n",
    "        def loss_estimate(params):\n",
    "            (encoder, decoder) = params\n",
    "            μ, Σ_scale = encoder(image)\n",
    "            v = MvNormalDiag(jnp.zeros(10), jnp.ones(10)).sample(seed=key)\n",
    "            s = μ + v * Σ_scale\n",
    "            guide_normal_logp = MvNormalDiag(μ, Σ_scale).log_prob(s)\n",
    "            model_normal_logp = MvNormalDiag(jnp.zeros(10), jnp.ones(10)).log_prob(s)\n",
    "            logits = decoder(s)\n",
    "            model_bernoulli_logp = Bernoulli(logits=logits).log_prob(image).sum()\n",
    "            return (model_bernoulli_logp + model_normal_logp) - guide_normal_logp\n",
    "\n",
    "        return jax.grad(loss_estimate)((encoder, decoder))\n",
    "\n",
    "    sub_keys = jax.random.split(key, len(data_batch))\n",
    "    return jax.vmap(single_estimate, in_axes=(0, None, None, 0))(\n",
    "        sub_keys, encoder, decoder, data_batch\n",
    "    )\n",
    "\n",
    "\n",
    "jit2 = jax.jit(batch_elbo_grad_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9c8f8-0079-47b5-a923-b8b25f4a41ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "@jax.jit\n",
    "def epoch_train(params, opt_state, key, train_idx):\n",
    "    def body_fn(carry, xs):\n",
    "        idx, opt_state, params = carry\n",
    "        updater_key = jax.random.fold_in(key, idx)\n",
    "        batch = train_fetch(idx, train_idx)[0]\n",
    "        grads = batch_elbo_grad_estimate(updater_key, encoder, decoder, batch)\n",
    "        grads = jtu.tree_map(lambda v: jnp.mean(v, axis=0), grads)\n",
    "        updates, opt_state = optax.adam(1e-3).update(grads, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        idx += 1\n",
    "        return (idx, opt_state, params), ()\n",
    "\n",
    "    idx = 0\n",
    "    (_, _, params), () = jax.lax.scan(\n",
    "        body_fn, (idx, opt_state, params), None, length=64\n",
    "    )\n",
    "    return params, 0.0\n",
    "\n",
    "\n",
    "params = (encoder, decoder)\n",
    "hand_epoch_times = []\n",
    "for i in range(0, 500):\n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "    train_init, train_fetch = load_dataset(MNIST, batch_size=64, split=\"train\")\n",
    "    adam = optax.adam(1e-3)\n",
    "    opt_state = adam.init(params)\n",
    "    num_batch, train_idx = train_init()\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    t0 = time.perf_counter()\n",
    "    params, loss = epoch_train(params, opt_state, sub_key, train_idx)\n",
    "    duration = time.perf_counter() - t0\n",
    "    if i != 0:\n",
    "        hand_epoch_times.append(duration)\n",
    "\n",
    "hand_epoch_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15bb693a-d6b9-4d91-bf98-878677e7d27a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "hand_runtime_over_batches = []\n",
    "hand_std_ds = []\n",
    "for batch_size in batch_sizes:\n",
    "    print(batch_size)\n",
    "    train_init, train_fetch = load_dataset(MNIST, batch_size=batch_size, split=\"train\")\n",
    "    num_train, train_idx = train_init()\n",
    "    data_batch = train_fetch(0)[0]\n",
    "    durations = []\n",
    "    jit2(key, encoder, decoder, data_batch)\n",
    "    for i in range(0, 100):\n",
    "        t0 = time.perf_counter()\n",
    "        jit2(key, encoder, decoder, data_batch)\n",
    "        duration = time.perf_counter() - t0\n",
    "        durations.append(duration)\n",
    "    hand_runtime_over_batches.append(jnp.mean(jnp.array(durations)))\n",
    "    hand_std_ds.append(jnp.std(jnp.array(durations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84b970a3-ab69-412a-83f6-51bc21d452b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0958897\u001b[0m , \u001b[1;36m0.16077422\u001b[0m, \u001b[1;36m0.29415104\u001b[0m, \u001b[1;36m0.54994816\u001b[0m, \u001b[1;36m1.0759283\u001b[0m \u001b[1m]\u001b[0m,\n",
       "      \u001b[33mdtype\u001b[0m=\u001b[35mfloat32\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.03943987\u001b[0m, \u001b[1;36m0.08780592\u001b[0m, \u001b[1;36m0.17903097\u001b[0m, \u001b[1;36m0.34972316\u001b[0m, \u001b[1;36m0.7014764\u001b[0m \u001b[1m]\u001b[0m,\n",
       "      \u001b[33mdtype\u001b[0m=\u001b[35mfloat32\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1000.0 * np.array(hand_runtime_over_batches), 1000.0 * np.array(hand_std_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0989c6-7586-4160-bb3e-99f10c1d9d74",
   "metadata": {
    "tags": []
   },
   "source": [
    "plt.rcParams[\"text.usetex\"] = False\n",
    "fig = plt.figure(figsize=(10, 4), dpi=240)\n",
    "plt.plot(\n",
    "    jnp.log2(jnp.array(batch_sizes)),\n",
    "    1e3 * jnp.array(grasp_runtime_over_batches),\n",
    "    label=\"Our automation\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.plot(\n",
    "    jnp.log2(jnp.array(batch_sizes)),\n",
    "    1e3 * jnp.array(hand_runtime_over_batches),\n",
    "    label=\"Hand coded\",\n",
    "    color=\"red\",\n",
    ")\n",
    "plt.title(\n",
    "    \"Gradient computation runtime vs. minibatch size\", fontsize=label_fontsize / 3\n",
    ")\n",
    "plt.xlabel(\"Batch size (log2)\", fontsize=label_fontsize / 3)\n",
    "plt.ylabel(\"Runtime (ms)\", fontsize=label_fontsize / 3)\n",
    "plt.legend(fontsize=label_fontsize / 4)\n",
    "plt.xticks(fontsize=label_fontsize / 5)\n",
    "plt.yticks(fontsize=label_fontsize / 5)\n",
    "plt.legend(fontsize=label_fontsize / 4)\n",
    "fig.savefig(\"img/overhead_batch_size.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2af16f-2c73-460b-8a4a-2b6dbca54ae8",
   "metadata": {
    "tags": []
   },
   "source": [
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.hist(\n",
    "    1e3 * jnp.array(grasp_epoch_times),\n",
    "    bins=10,\n",
    "    alpha=0.5,\n",
    "    label=\"Our automation\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.hist(\n",
    "    1e3 * jnp.array(hand_epoch_times),\n",
    "    bins=10,\n",
    "    alpha=0.5,\n",
    "    label=\"Hand coded\",\n",
    "    color=\"red\",\n",
    ")\n",
    "plt.title(\"Epoch time distribution\", fontsize=label_fontsize / 3)\n",
    "plt.xlabel(\"Time (ms)\", fontsize=label_fontsize / 3)\n",
    "plt.ylabel(\"Frequency\", fontsize=label_fontsize / 3)\n",
    "plt.legend(fontsize=label_fontsize / 4)\n",
    "plt.xticks(fontsize=label_fontsize / 5)\n",
    "plt.yticks(fontsize=label_fontsize / 5)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"img/overhead_epoch_histogram.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
