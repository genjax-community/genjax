{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de0133f-4e97-401c-b216-e0bc64664444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import time\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from collections import namedtuple\n",
    "import pyro\n",
    "import optax\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "import pyro.contrib.examples.multi_mnist as multi_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from matplotlib import rcParams\n",
    "from scipy.interpolate import griddata\n",
    "import genjax\n",
    "from genjax import grasp\n",
    "\n",
    "key = jax.random.PRNGKey(314159)\n",
    "console = genjax.pretty()\n",
    "sns.set_theme(style=\"white\")\n",
    "font_path = (\n",
    "    \"/home/femtomc/.local/share/fonts/Unknown Vendor/TrueType/Lato/Lato_Bold.ttf\"\n",
    ")\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "custom_font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rcParams[\"font.family\"] = custom_font_name\n",
    "\n",
    "console = genjax.pretty()\n",
    "key = jax.random.PRNGKey(314159)\n",
    "label_fontsize = 70  # Set the desired font size here\n",
    "\n",
    "smoke_test = \"CI\" in os.environ\n",
    "assert pyro.__version__.startswith(\"1.8.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4985e835-14c9-43f0-8652-34da112dd6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size 80\u001b[0m\u001b[1;36m0x200\u001b[0m\u001b[39m with \u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inpath = \"./data/air/.data\"\n",
    "X_np, Y = multi_mnist.load(inpath)\n",
    "X_np = X_np.astype(np.float32)\n",
    "X_np /= 255.0\n",
    "mnist = jnp.array(X_np)\n",
    "true_counts = jnp.array([len(objs) for objs in Y])\n",
    "\n",
    "\n",
    "def show_images(imgs):\n",
    "    fig = plt.figure(figsize=(8, 2))\n",
    "    for i, img in enumerate(imgs):\n",
    "        ax = plt.subplot(1, len(imgs), i + 1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.imshow(img, cmap=\"gray_r\")\n",
    "\n",
    "\n",
    "show_images(mnist[9:14])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65227bc6-fd5e-486d-9cdc-0bfdf6cbde95",
   "metadata": {},
   "source": [
    "## Defining the variational ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78d35c-3e79-4ea7-95d9-82106cb22ad7",
   "metadata": {},
   "source": [
    "### Utilities / learnable pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38987718-1631-423e-8b70-95a469742beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from genjax import Pytree\n",
    "import equinox as eqx\n",
    "from genjax.typing import Any\n",
    "from genjax.typing import Tuple\n",
    "from genjax.typing import FloatArray\n",
    "from genjax.typing import Int\n",
    "from genjax.typing import IntArray\n",
    "from genjax.typing import PRNGKey\n",
    "from genjax.typing import typecheck\n",
    "\n",
    "# Utilities for defining the model and the guide.\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Decoder(Pytree):\n",
    "    dense_1: Any\n",
    "    dense_2: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense_1, self.dense_2), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key1, key2):\n",
    "        dense_1 = eqx.nn.Linear(50, 200, key=key1)\n",
    "        dense_2 = eqx.nn.Linear(200, 400, key=key2)\n",
    "        return Decoder(dense_1, dense_2)\n",
    "\n",
    "    def __call__(self, z_what):\n",
    "        v = self.dense_1(z_what)\n",
    "        v = jax.nn.leaky_relu(v)\n",
    "        v = self.dense_2(v)\n",
    "        return jax.nn.sigmoid(v)\n",
    "\n",
    "\n",
    "# Create our decoder.\n",
    "key, sub_key1, sub_key2 = jax.random.split(key, 3)\n",
    "decoder = Decoder.new(sub_key1, sub_key2)\n",
    "\n",
    "# Create our RNN for the guide.\n",
    "key, sub_key = jax.random.split(key)\n",
    "rnn = eqx.nn.LSTMCell(2554, 256, key=sub_key)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Encoder(Pytree):\n",
    "    dense_1: Any\n",
    "    dense_2: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense_1, self.dense_2), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key1, key2):\n",
    "        dense_1 = eqx.nn.Linear(400, 200, key=key1)\n",
    "        dense_2 = eqx.nn.Linear(200, 100, key=key2)\n",
    "        return Encoder(dense_1, dense_2)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        v = self.dense_1(data)\n",
    "        v = jax.nn.leaky_relu(v)\n",
    "        v = self.dense_2(v)\n",
    "        return v[0:50], jax.nn.softplus(v[50:])\n",
    "\n",
    "\n",
    "key, sub_key1, sub_key2 = jax.random.split(key, 3)\n",
    "encoder = Encoder.new(sub_key1, sub_key2)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Predict(Pytree):\n",
    "    dense: Any\n",
    "\n",
    "    def flatten(self):\n",
    "        return (self.dense,), ()\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, key):\n",
    "        dense = eqx.nn.Linear(256, 7, key=key)\n",
    "        return Predict(dense)\n",
    "\n",
    "    def __call__(self, h):\n",
    "        a = self.dense(h)\n",
    "        z_pres_p = jax.nn.sigmoid(a[0:1])\n",
    "        z_where_loc = a[1:4]\n",
    "        z_where_scale = jax.nn.softplus(a[4:])\n",
    "        return z_pres_p, z_where_loc, z_where_scale\n",
    "\n",
    "\n",
    "key, sub_key = jax.random.split(key)\n",
    "predict = Predict.new(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82446361-62cd-4cec-a8aa-d76b477603d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######\n",
    "# STN #\n",
    "#######\n",
    "\n",
    "# modified from https://github.com/kevinzakka/spatial-transformer-network/blob/master/stn/transformer.py\n",
    "\n",
    "\n",
    "def affine_grid_generator(height, width, theta):\n",
    "    \"\"\"\n",
    "    This function returns a sampling grid, which when\n",
    "    used with the bilinear sampler on the input feature\n",
    "    map, will create an output feature map that is an\n",
    "    affine transformation [1] of the input feature map.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - height: desired height of grid/output. Used\n",
    "      to downsample or upsample.\n",
    "\n",
    "    - width: desired width of grid/output. Used\n",
    "      to downsample or upsample.\n",
    "\n",
    "    - theta: affine transform matrices of shape (num_batch, 2, 3).\n",
    "      For each image in the batch, we have 6 theta parameters of\n",
    "      the form (2x3) that define the affine transformation T.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - normalized grid (-1, 1) of shape (num_batch, 2, H, W).\n",
    "      The 2nd dimension has 2 components: (x, y) which are the\n",
    "      sampling points of the original image for each point in the\n",
    "      target image.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    [1]: the affine transformation allows cropping, translation,\n",
    "         and isotropic scaling.\n",
    "    \"\"\"\n",
    "    num_batch = theta.shape[0]\n",
    "\n",
    "    # create normalized 2D grid\n",
    "    x = jnp.linspace(-1.0, 1.0, width)\n",
    "    y = jnp.linspace(-1.0, 1.0, height)\n",
    "    x_t, y_t = jnp.meshgrid(x, y)\n",
    "\n",
    "    # flatten\n",
    "    x_t_flat = jnp.reshape(x_t, [-1])\n",
    "    y_t_flat = jnp.reshape(y_t, [-1])\n",
    "\n",
    "    # reshape to [x_t, y_t , 1] - (homogeneous form)\n",
    "    ones = jnp.ones_like(x_t_flat)\n",
    "    sampling_grid = jnp.stack([x_t_flat, y_t_flat, ones])\n",
    "\n",
    "    # repeat grid num_batch times\n",
    "    sampling_grid = jnp.expand_dims(sampling_grid, axis=0)\n",
    "    sampling_grid = jnp.tile(sampling_grid, [num_batch, 1, 1])\n",
    "\n",
    "    # transform the sampling grid - batch multiply\n",
    "    batch_grids = jnp.matmul(theta, sampling_grid)\n",
    "    # batch grid has shape (num_batch, 2, H*W)\n",
    "\n",
    "    # reshape to (num_batch, 2, H, W)\n",
    "    batch_grids = jnp.reshape(batch_grids, [num_batch, 2, height, width])\n",
    "\n",
    "    return batch_grids\n",
    "\n",
    "\n",
    "def bilinear_sampler(img, x, y):\n",
    "    \"\"\"\n",
    "    Performs bilinear sampling of the input images according to the\n",
    "    normalized coordinates provided by the sampling grid. Note that\n",
    "    the sampling is done identically for each channel of the input.\n",
    "\n",
    "    To test if the function works properly, output image should be\n",
    "    identical to input image when theta is initialized to identity\n",
    "    transform.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - img: batch of images in (B, H, W, C) layout.\n",
    "    - grid: x, y which is the output of affine_grid_generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - out: interpolated images according to grids. Same size as grid.\n",
    "    \"\"\"\n",
    "    H = jnp.shape(img)[1]\n",
    "    W = jnp.shape(img)[2]\n",
    "    max_y = H - 1\n",
    "    max_x = W - 1\n",
    "    zero = jnp.zeros([], dtype=int)\n",
    "\n",
    "    # rescale x and y to [0, W-1/H-1]\n",
    "    x = 0.5 * ((x + 1.0) * max_x - 1)\n",
    "    y = 0.5 * ((y + 1.0) * max_y - 1)\n",
    "\n",
    "    # grab 4 nearest corner points for each (x_i, y_i)\n",
    "    x0 = jnp.floor(x).astype(int)\n",
    "    x1 = x0 + 1\n",
    "    y0 = jnp.floor(y).astype(int)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    # clip to range [0, H-1/W-1] to not violate img boundaries\n",
    "    x0 = jnp.clip(x0, zero, max_x)\n",
    "    x1 = jnp.clip(x1, zero, max_x)\n",
    "    y0 = jnp.clip(y0, zero, max_y)\n",
    "    y1 = jnp.clip(y1, zero, max_y)\n",
    "\n",
    "    # get pixel value at corner coords\n",
    "    Ia = get_pixel_value(img, x0, y0)\n",
    "    Ib = get_pixel_value(img, x0, y1)\n",
    "    Ic = get_pixel_value(img, x1, y0)\n",
    "    Id = get_pixel_value(img, x1, y1)\n",
    "\n",
    "    # recast as float for delta calculation\n",
    "    x0 = x0.astype(float)\n",
    "    x1 = x1.astype(float)\n",
    "    y0 = y0.astype(float)\n",
    "    y1 = y1.astype(float)\n",
    "\n",
    "    # calculate deltas\n",
    "    wa = (x1 - x) * (y1 - y)\n",
    "    wb = (x1 - x) * (y - y0)\n",
    "    wc = (x - x0) * (y1 - y)\n",
    "    wd = (x - x0) * (y - y0)\n",
    "\n",
    "    # add dimension for addition\n",
    "    wa = jnp.expand_dims(wa, axis=3)\n",
    "    wb = jnp.expand_dims(wb, axis=3)\n",
    "    wc = jnp.expand_dims(wc, axis=3)\n",
    "    wd = jnp.expand_dims(wd, axis=3)\n",
    "\n",
    "    # compute output\n",
    "    out = wa * Ia + wb * Ib + wc * Ic + wd * Id\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_pixel_value(img, x, y):\n",
    "    \"\"\"\n",
    "    Utility function to get pixel value for coordinate\n",
    "    vectors x and y from a  4D tensor image.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - img: tensor of shape (B, H, W, C)\n",
    "    - x: flattened tensor of shape (B*H*W,)\n",
    "    - y: flattened tensor of shape (B*H*W,)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - output: tensor of shape (B, H, W, C)\n",
    "    \"\"\"\n",
    "    batch_size, height, width = jnp.shape(x)\n",
    "\n",
    "    batch_idx = jnp.arange(0, batch_size)\n",
    "    batch_idx = jnp.reshape(batch_idx, (batch_size, 1, 1))\n",
    "    b = jnp.tile(batch_idx, (1, height, width))\n",
    "\n",
    "    indices = jnp.stack([b, y, x], 3)\n",
    "\n",
    "    return gather_nd(img, indices)\n",
    "\n",
    "\n",
    "# from: https://github.com/google/jax/discussions/6119\n",
    "def gather_nd_unbatched(params, indices):\n",
    "    return params[tuple(jnp.moveaxis(indices, -1, 0))]\n",
    "\n",
    "\n",
    "def gather_nd(params, indices, batch=False):\n",
    "    if not batch:\n",
    "        return gather_nd_unbatched(params, indices)\n",
    "    else:\n",
    "        return vmap(gather_nd_unbatched, (0, 0), 0)(params, indices)\n",
    "\n",
    "\n",
    "def expand_z_where(z_where):\n",
    "    # Takes 3-dimensional vectors, and massages them into 2x3 matrices with elements like so:\n",
    "    # [s,x,y] -> [[s,0,x],\n",
    "    #             [0,s,y]]\n",
    "    n = 1\n",
    "    expansion_indices = jnp.array([1, 0, 2, 0, 1, 3])\n",
    "    z_where = jnp.expand_dims(z_where, axis=0)\n",
    "    out = jnp.concatenate((jnp.broadcast_to(jnp.zeros([1, 1]), (n, 1)), z_where), 1)\n",
    "    return jnp.reshape(out[:, expansion_indices], (n, 2, 3))\n",
    "\n",
    "\n",
    "def object_to_image(z_where, obj):\n",
    "    n = 1\n",
    "    theta = expand_z_where(z_where)\n",
    "    grid = affine_grid_generator(50, 50, theta)\n",
    "    x_s = grid[:, 0, :, :]\n",
    "    y_s = grid[:, 1, :, :]\n",
    "    out = bilinear_sampler(jnp.reshape(obj, (n, 20, 20, 1)), x_s, y_s)\n",
    "    return jnp.reshape(out, (50, 50))\n",
    "\n",
    "\n",
    "def z_where_inv(z_where):\n",
    "    # Take a batch of z_where vectors, and compute their \"inverse\".\n",
    "    # That is, for each row compute:\n",
    "    # [s,x,y] -> [1/s,-x/s,-y/s]\n",
    "    # These are the parameters required to perform the inverse of the\n",
    "    # spatial transform performed in the generative model.\n",
    "    n = 1\n",
    "    out = jnp.array([1, *(-z_where[1:])])\n",
    "    out = out / z_where[0]\n",
    "    return out\n",
    "\n",
    "\n",
    "def image_to_object(z_where, image):\n",
    "    n = 1\n",
    "    theta_inv = expand_z_where(z_where_inv(z_where))\n",
    "    grid = affine_grid_generator(20, 20, theta_inv)\n",
    "    x_s = grid[:, 0, :, :]\n",
    "    y_s = grid[:, 1, :, :]\n",
    "    out = bilinear_sampler(jnp.reshape(image, (n, 50, 50, 1)), x_s, y_s)\n",
    "    return jnp.reshape(out, (400,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6179494f-ccc0-449f-8fcc-7bb48b4783e9",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60196b16-596f-4b7d-b040-85b8a2808423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########\n",
    "# Model #\n",
    "#########\n",
    "\n",
    "# Fixed constants.\n",
    "z_where_prior_loc = jnp.array([3.0, 0.0, 0.0])\n",
    "z_where_prior_scale = jnp.array([0.2, 1.0, 1.0])\n",
    "z_what_prior_loc = jnp.zeros(50, dtype=float)\n",
    "z_what_prior_scale = jnp.ones(50, dtype=float)\n",
    "z_pres_prior = [0.05, 0.05**2.3, 0.05 ** (5)]\n",
    "eps = 1e-4\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def step(\n",
    "    t: Int,\n",
    "    decoder: Decoder,\n",
    "    prev_x: FloatArray,\n",
    "    prev_z_pres: IntArray,\n",
    "):\n",
    "    z_pres = grasp.flip_enum(z_pres_prior[t]) @ f\"z_pres_{t}\"\n",
    "    z_pres = jnp.array([z_pres.astype(int)])\n",
    "    z_where = (\n",
    "        grasp.mv_normal_diag_reparam(z_where_prior_loc, z_where_prior_scale)\n",
    "        @ f\"z_where_{t}\"\n",
    "    )\n",
    "    z_what = (\n",
    "        grasp.mv_normal_diag_reparam(z_what_prior_loc, z_what_prior_scale)\n",
    "        @ f\"z_what_{t}\"\n",
    "    )\n",
    "    y_att = decoder(z_what)\n",
    "    y = object_to_image(z_where, y_att)\n",
    "    x = prev_x + (y * z_pres)\n",
    "    return x, z_pres\n",
    "\n",
    "\n",
    "# TODO: Make sure that this works, where t is a static int.\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def model(decoder: Decoder):\n",
    "    x = jnp.zeros((50, 50), dtype=float)\n",
    "    z_pres = jnp.ones(1, dtype=int)\n",
    "    for t in range(3):\n",
    "        x, z_pres = step.inline(t, decoder, x, z_pres)\n",
    "    obs = grasp.mv_normal_diag_reparam(x, 0.3 * jnp.ones_like(x)) @ \"obs\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee69ad5-2136-4933-ad71-42f01483dab6",
   "metadata": {},
   "source": [
    "#### Samples from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41747dee-44a0-4cd6-8087-4ce4d526fcee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "├── \u001b[1m:obs\u001b[0m\n",
       "│   └──  f32[50,50]\n",
       "├── \u001b[1m:z_what_1\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_where_1\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_pres_2\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_pres_0\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_pres_1\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_what_0\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_where_0\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_where_2\u001b[0m\n",
       "│   └──  f32[3]\n",
       "└── \u001b[1m:z_what_2\u001b[0m\n",
       "    └──  f32[50]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = jax.jit(model.simulate)(key, (decoder,))\n",
    "tr.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8394159-926b-4607-8df0-bbcc49657ae0",
   "metadata": {},
   "source": [
    "### Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33dd2fbf-df45-4e48-ac82-9d005ffaab01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########\n",
    "# Guide #\n",
    "#########\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def guide_step(\n",
    "    t: Int,\n",
    "    rnn: eqx.nn.LSTMCell,\n",
    "    encoder: Encoder,\n",
    "    predict: Predict,\n",
    "    data,\n",
    "    prev: Tuple,\n",
    "):\n",
    "    (prev_z_where, prev_z_what, prev_z_pres, prev_h, prev_c) = prev\n",
    "    rnn_input = jnp.concatenate([data, prev_z_where, prev_z_what, prev_z_pres])\n",
    "    h, c = rnn(rnn_input, (prev_h, prev_c))\n",
    "    z_pres_p, z_where_loc, z_where_scale = predict(h)\n",
    "    z_pres = (\n",
    "        grasp.flip_enum((eps + (z_pres_p[0] * prev_z_pres[0])) / (1 + 1.01 * eps))\n",
    "        @ f\"z_pres_{t}\"\n",
    "    )\n",
    "    z_pres = jnp.array([z_pres.astype(int)])\n",
    "    z_where = grasp.mv_normal_diag_reparam(z_where_loc, z_where_scale) @ f\"z_where_{t}\"\n",
    "    x_att = image_to_object(z_where, data)\n",
    "    z_what_loc, z_what_scale = encoder(x_att)\n",
    "    z_what = grasp.mv_normal_diag_reparam(z_what_loc, z_what_scale) @ f\"z_what_{t}\"\n",
    "    return z_where, z_what, z_pres, h, c\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "@typecheck\n",
    "def guide(\n",
    "    data: genjax.ChoiceMap,\n",
    "    rnn: eqx.nn.LSTMCell,\n",
    "    encoder: Encoder,\n",
    "    predict: Predict,\n",
    "):\n",
    "    h = jnp.zeros(256)\n",
    "    c = jnp.zeros(256)\n",
    "    z_pres = jnp.ones(1)\n",
    "    z_where = jnp.zeros(3)\n",
    "    z_what = jnp.zeros(50)\n",
    "    img = data[\"obs\"]\n",
    "    img_arr = img.flatten()\n",
    "\n",
    "    for t in range(3):\n",
    "        (z_where, z_what, z_pres, h, c) = guide_step.inline(\n",
    "            t, rnn, encoder, predict, img_arr, (z_where, z_what, z_pres, h, c)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89bc83-29fc-4e0e-a47d-dab2acf0c920",
   "metadata": {},
   "source": [
    "#### Samples from the guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2984c5cc-2b4c-40f5-ad0c-a2c3d1508f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "├── \u001b[1m:z_what_1\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_where_1\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_pres_2\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_pres_0\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_pres_1\u001b[0m\n",
       "│   └──  bool[]\n",
       "├── \u001b[1m:z_what_0\u001b[0m\n",
       "│   └──  f32[50]\n",
       "├── \u001b[1m:z_where_0\u001b[0m\n",
       "│   └──  f32[3]\n",
       "├── \u001b[1m:z_where_2\u001b[0m\n",
       "│   └──  f32[3]\n",
       "└── \u001b[1m:z_what_2\u001b[0m\n",
       "    └──  f32[50]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_chm = genjax.choice_map({\"obs\": jnp.ones((50, 50))})\n",
    "tr = jax.jit(guide.simulate)(key, (data_chm, rnn, encoder, predict))\n",
    "tr.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b2f0a-dee4-470d-8bfa-c71a9e466690",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32a7cd-d44b-46dd-bea2-8ddac55aa88a",
   "metadata": {},
   "source": [
    "### Make sure grads are working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc1805-57c9-4c44-8ace-2b0fa068c9c7",
   "metadata": {},
   "source": [
    "#### Define ELBO objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "435472dd-c312-4f5f-8fc4-f2c0125491ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = genjax.choice_map({\"obs\": jnp.ones((50, 50))})\n",
    "objective = grasp.elbo(model, guide, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860fc0c2-6adb-4d7d-8ab1-0c1fccc16a65",
   "metadata": {},
   "source": [
    "#### Go go grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1ec3a5-e506-41bb-9a97-0c13bcbfb108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jitted = jax.jit(objective.value_and_grad_estimate)\n",
    "loss, ((decoder_grads,), (_, rnn_grads, encoder_grads, predict_grads)) = jitted(\n",
    "    key, ((decoder,), (data, rnn, encoder, predict))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817c347c-fdff-4822-9091-2d58887f5baa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mArray\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m-8482.239\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mfloat32\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf5b4af-8df8-4bca-b0f2-c576dd0ba659",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdf9c5ed-4369-4a68-8ce8-af7754576fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_loader(\n",
    "    data,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "):\n",
    "    N = len(data)\n",
    "    data_idxs = np.arange(N)\n",
    "    num_batch = int(np.ceil(N // batch_size))\n",
    "\n",
    "    def init(key):\n",
    "        return (\n",
    "            num_batch,\n",
    "            jax.random.permutation(key, data_idxs) if shuffle else data_idxs,\n",
    "        )\n",
    "\n",
    "    def get_batch(i=0, idxs=data_idxs):\n",
    "        ret_idx = jax.lax.dynamic_slice_in_dim(idxs, i * batch_size, batch_size)\n",
    "        return jax.lax.index_take(data, (ret_idx,), axes=(0,))\n",
    "\n",
    "    return init, get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bce54cb-d22a-43b8-b296-6067484552d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Count Accuracy #\n",
    "##################\n",
    "\n",
    "\n",
    "def count_accuracy(data, true_counts, guide, batch_size=1000):\n",
    "    global prng_key\n",
    "    assert data.shape[0] == true_counts.shape[0], \"Size mismatch.\"\n",
    "    assert data.shape[0] % batch_size == 0, \"Input size must be multiple of batch_size.\"\n",
    "\n",
    "    def eval_guide(key, data, params):\n",
    "        data_chmp = genjax.choice_map({\"obs\": data})\n",
    "        return guide.simulate(key, (data_chmp, *params))\n",
    "\n",
    "    batch_eval_guide = jax.jit(jax.vmap(eval_guide, in_axes=(0, 0, None)))\n",
    "\n",
    "    @jax.jit\n",
    "    def evaluate_count_accuracy(key, params):\n",
    "        def evaluate_batch(counts, batch_id):\n",
    "            data_batch = jax.lax.dynamic_slice_in_dim(\n",
    "                data, batch_id * batch_size, batch_size\n",
    "            )\n",
    "            true_counts_batch = jax.lax.dynamic_slice_in_dim(\n",
    "                true_counts, batch_id * batch_size, batch_size\n",
    "            )\n",
    "            data_chmp = genjax.choice_map({\"obs\": data_batch})\n",
    "            # evaluate guide\n",
    "            keys = jax.random.split(jax.random.fold_in(key, batch_id), batch_size)\n",
    "            tr = batch_eval_guide(keys, data_batch, params)\n",
    "            z_where = [tr[f\"z_where_{i}\"] for i in range(3)]\n",
    "            z_pres = [tr[f\"z_pres_{i}\"] for i in range(3)]\n",
    "            # compute stats\n",
    "            inferred_counts = sum(z for z in z_pres)\n",
    "            true_counts_m = jax.nn.one_hot(true_counts_batch, 3)\n",
    "            inferred_counts_m = jax.nn.one_hot(inferred_counts, 4)\n",
    "            counts += (true_counts_m.T @ inferred_counts_m).astype(int)\n",
    "            error_ind = 1 - (true_counts_batch == inferred_counts).astype(int)\n",
    "            # error_ix = error_ind.nonzero()[0]\n",
    "            # error_latent = jnp.take(latents_to_tensor((z_where, z_pres)), error_ix, 0)\n",
    "            return counts, error_ind\n",
    "\n",
    "        counts = jnp.zeros((3, 4), dtype=int)\n",
    "        counts, error_indices = jax.lax.scan(\n",
    "            evaluate_batch, counts, jnp.arange(data.shape[0] // batch_size)\n",
    "        )\n",
    "\n",
    "        acc = jnp.sum(jnp.diag(counts)).astype(float) / data.shape[0]\n",
    "        error_indices = jnp.concatenate(\n",
    "            error_indices\n",
    "        )  # .nonzero()[0]  # <- not JIT compilable\n",
    "        return acc, counts, error_indices\n",
    "\n",
    "    return evaluate_count_accuracy\n",
    "\n",
    "\n",
    "# Combine z_pres and z_where (as returned by the model and guide) into\n",
    "# a single tensor, with size:\n",
    "# [batch_size, num_steps, z_where_size + z_pres_size]\n",
    "def latents_to_tensor(z):\n",
    "    return jnp.stack(\n",
    "        [\n",
    "            jnp.concatenate((z_where, z_pres.reshape(-1, 1)), 1)\n",
    "            for z_where, z_pres in zip(*z)\n",
    "        ]\n",
    "    ).transpose(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3660daf7-584d-4fd9-a26b-371d32fb5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Visualization  #\n",
    "##################\n",
    "\n",
    "\n",
    "def bounding_box(z_where, x_size):\n",
    "    \"\"\"This doesn't take into account interpolation, but it's close\n",
    "    enough to be usable.\"\"\"\n",
    "    w = x_size / z_where.s\n",
    "    h = x_size / z_where.s\n",
    "    xtrans = -z_where.x / z_where.s * x_size / 2.0\n",
    "    ytrans = -z_where.y / z_where.s * x_size / 2.0\n",
    "    x = (x_size - w) / 2 + xtrans  # origin is top left\n",
    "    y = (x_size - h) / 2 + ytrans\n",
    "    return (x, y), w, h\n",
    "\n",
    "\n",
    "z_obj = namedtuple(\"z\", [\"s\", \"x\", \"y\", \"pres\"])\n",
    "\n",
    "\n",
    "# Map a tensor of latents (as produced by latents_to_tensor) to a list\n",
    "# of z_obj named tuples.\n",
    "def tensor_to_objs(latents):\n",
    "    return [[z_obj._make(step) for step in z] for z in latents]\n",
    "\n",
    "\n",
    "def visualize_model(model, guide):\n",
    "    def reconstruct_digits(key, data, params):\n",
    "        decoder, rnn, encoder, predict = params\n",
    "        data_chmp = genjax.choice_map({\"obs\": data})\n",
    "        key1, key2 = jax.random.split(key)\n",
    "        tr = guide.simulate(key1, (data_chmp, rnn, encoder, predict))\n",
    "        _, tr = model.importance(key2, tr, (decoder,))\n",
    "        reconstruction = tr.get_retval()\n",
    "        z_where = [tr[f\"z_where_{i}\"] for i in range(3)]\n",
    "        z_pres = [tr[f\"z_pres_{i}\"] for i in range(3)]\n",
    "        return reconstruction, (z_where, z_pres)\n",
    "\n",
    "    batch_reconstruct_digits = jax.jit(\n",
    "        jax.vmap(reconstruct_digits, in_axes=(0, 0, None))\n",
    "    )\n",
    "\n",
    "    def visualize(key, params, examples_to_viz):\n",
    "        keys = jax.random.split(key, examples_to_viz.shape[0])\n",
    "        recons, z = batch_reconstruct_digits(keys, examples_to_viz, params)\n",
    "        z_wheres = tensor_to_objs(latents_to_tensor(z))\n",
    "        draw_many(examples_to_viz.reshape(-1, 50, 50), z_wheres, title=\"Original\")\n",
    "        draw_many(recons, z_wheres, title=\"Reconstruction\")\n",
    "\n",
    "    return visualize\n",
    "\n",
    "\n",
    "def colors(k):\n",
    "    return [\"r\", \"g\", \"b\"][k % 3]\n",
    "\n",
    "\n",
    "def draw_one(img, z):\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img, cmap=\"gray_r\")\n",
    "    for k, z in enumerate(z):\n",
    "        if z.pres > 0:\n",
    "            (x, y), w, h = bounding_box(z, img.shape[0])\n",
    "            plt.gca().add_patch(\n",
    "                Rectangle(\n",
    "                    (x, y), w, h, linewidth=1, edgecolor=colors(k), facecolor=\"none\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "def draw_many(imgs, zs, title):\n",
    "    plt.figure(figsize=(8, 1.9))\n",
    "    plt.title(title)\n",
    "    plt.tick_params(left=False, labelleft=False, bottom=False, labelbottom=False)\n",
    "    plt.box(False)\n",
    "    for i, (img, z) in enumerate(zip(imgs, zs)):\n",
    "        plt.subplot(1, len(imgs), i + 1)\n",
    "        draw_one(img, z)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da48a46a-fdb1-4b8d-b4e5-d96d27b898d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (decoder, rnn, encoder, predict)\n",
    "evaluate_accuracy = count_accuracy(mnist, true_counts, guide, batch_size=1000)\n",
    "\n",
    "visualize_examples = mnist[5:10]\n",
    "visualize = visualize_model(model, guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaf743cf-aa9e-44db-9078-6a89f1d26f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(key, n=1, num_epochs=200, batch_size=64, learning_rate=1.0e-3):\n",
    "    def svi_update(model, guide, optimiser):\n",
    "        def batch_updater(key, params, opt_state, data_batch):\n",
    "            def grads(key, params, data):\n",
    "                (decoder, rnn, encoder, predict) = params\n",
    "                data = genjax.choice_map({\"obs\": data})\n",
    "                objective = grasp.iwae_elbo(model, guide, data, n)\n",
    "                loss, (\n",
    "                    (decoder_grads,),\n",
    "                    (_, rnn_grads, encoder_grads, predict_grads),\n",
    "                ) = objective.value_and_grad_estimate(\n",
    "                    key, ((decoder,), (data, rnn, encoder, predict))\n",
    "                )\n",
    "                return loss, (decoder_grads, rnn_grads, encoder_grads, predict_grads)\n",
    "\n",
    "            sub_keys = jax.random.split(key, len(data_batch))\n",
    "            loss, (decoder_grads, rnn_grads, encoder_grads, predict_grads) = jax.vmap(\n",
    "                grads, in_axes=(0, None, 0)\n",
    "            )(sub_keys, params, data_batch)\n",
    "\n",
    "            grads = jtu.tree_map(\n",
    "                lambda v: -1.0 * jnp.mean(v, axis=0),\n",
    "                (decoder_grads, rnn_grads, encoder_grads, predict_grads),\n",
    "            )\n",
    "            updates, opt_state = optimiser.update(grads, opt_state, params)\n",
    "            params = optax.apply_updates(params, updates)\n",
    "            loss = jnp.mean(loss)\n",
    "            return params, opt_state, loss\n",
    "\n",
    "        return batch_updater\n",
    "\n",
    "    adam = optax.adam(learning_rate)\n",
    "    svi_updater = svi_update(model, guide, adam)\n",
    "\n",
    "    @jax.jit\n",
    "    def epoch_train(opt_state, params, key, train_idx):\n",
    "        def body_fn(carry, xs):\n",
    "            idx, params, opt_state, loss = carry\n",
    "            updater_key = jax.random.fold_in(key, idx)\n",
    "            batch = train_fetch(idx, train_idx)\n",
    "            params, opt_state, loss = svi_updater(updater_key, params, opt_state, batch)\n",
    "            idx += 1\n",
    "            return (idx, params, opt_state, loss), loss\n",
    "\n",
    "        idx = 0\n",
    "        (_, params, opt_state, _), losses = jax.lax.scan(\n",
    "            body_fn, (idx, params, opt_state, 0.0), None, length=num_batch\n",
    "        )\n",
    "        return params, opt_state, losses\n",
    "\n",
    "    # Train.\n",
    "    params = (decoder, rnn, encoder, predict)\n",
    "    opt_state = adam.init(params)\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    acc_time = 0.0\n",
    "    wall_clock_times = []\n",
    "    train_init, train_fetch = data_loader(jnp.array(mnist), batch_size)\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    num_batch, train_idx = train_init(sub_key)\n",
    "\n",
    "    # Warm up.\n",
    "    _ = epoch_train(opt_state, params, key, train_idx)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    acc_time = 0.0\n",
    "    for i in range(0, num_epochs + 1):\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        num_batch, train_idx = train_init(sub_key)\n",
    "        key, sub_key = jax.random.split(key)\n",
    "        start = time.perf_counter() - t0\n",
    "        params, opt_state, loss = epoch_train(opt_state, params, sub_key, train_idx)\n",
    "        stop = time.perf_counter() - t0\n",
    "        acc_time += stop - start\n",
    "        losses.append(jnp.mean(loss))\n",
    "        wall_clock_times.append(acc_time)\n",
    "        acc, counts, error_ix = evaluate_accuracy(sub_key, params[1:])\n",
    "        accuracy.append(acc)\n",
    "        print(\n",
    "            f\"Epoch={i}, total_epoch_step_time={acc_time:.2f}, loss={jnp.mean(loss):.2f}\"\n",
    "        )\n",
    "        print(\"accuracy={}, counts={}\".format(acc, counts))\n",
    "\n",
    "    return losses, accuracy, wall_clock_times, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24322557-5242-4358-91c8-ca0dd0cf4b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, total_epoch_step_time=5.99, loss=55.08\n",
      "accuracy=0.2241833359003067, counts=[[11049  8152   743     4]\n",
      " [17598  2400    22     0]\n",
      " [19475   555     2     0]]\n",
      "Epoch=1, total_epoch_step_time=11.96, loss=409.50\n",
      "accuracy=0.2234666645526886, counts=[[11334  7783   818    13]\n",
      " [17920  2074    26     0]\n",
      " [19478   554     0     0]]\n",
      "Epoch=2, total_epoch_step_time=17.97, loss=429.86\n",
      "accuracy=0.22678333520889282, counts=[[11668  7408   858    14]\n",
      " [18058  1939    23     0]\n",
      " [19452   580     0     0]]\n",
      "Epoch=3, total_epoch_step_time=23.90, loss=447.46\n",
      "accuracy=0.241716668009758, counts=[[12583  6688   666    11]\n",
      " [18074  1918    28     0]\n",
      " [19471   559     2     0]]\n",
      "Epoch=4, total_epoch_step_time=29.85, loss=455.82\n",
      "accuracy=0.2513333261013031, counts=[[13242  6206   493     7]\n",
      " [18168  1838    14     0]\n",
      " [19456   576     0     0]]\n",
      "Epoch=5, total_epoch_step_time=36.22, loss=457.84\n",
      "accuracy=0.2624000012874603, counts=[[13919  5681   345     3]\n",
      " [18182  1824    14     0]\n",
      " [19361   670     1     0]]\n",
      "Epoch=6, total_epoch_step_time=42.25, loss=459.11\n",
      "accuracy=0.2976166605949402, counts=[[14823  4786   336     3]\n",
      " [16935  3003    82     0]\n",
      " [17991  2010    31     0]]\n",
      "Epoch=7, total_epoch_step_time=48.41, loss=469.82\n",
      "accuracy=0.4030500054359436, counts=[[15046  4398   494    10]\n",
      " [ 2690  5174  6753  5403]\n",
      " [  659  1285  3963 14125]]\n",
      "Epoch=8, total_epoch_step_time=54.52, loss=510.48\n",
      "accuracy=0.8005833625793457, counts=[[16328  3571    49     0]\n",
      " [  645 15193  4141    41]\n",
      " [   30  2431 16514  1057]]\n",
      "Epoch=9, total_epoch_step_time=60.76, loss=542.79\n",
      "accuracy=0.8822166919708252, counts=[[18139  1805     4     0]\n",
      " [  336 16349  3328     7]\n",
      " [    6  1180 18445   401]]\n",
      "Epoch=10, total_epoch_step_time=66.97, loss=561.70\n",
      "accuracy=0.9274333715438843, counts=[[19295   653     0     0]\n",
      " [  217 17535  2263     5]\n",
      " [    2  1023 18816   191]]\n",
      "Epoch=11, total_epoch_step_time=72.98, loss=579.01\n",
      "accuracy=0.9502500295639038, counts=[[19669   278     1     0]\n",
      " [  199 18452  1367     2]\n",
      " [    1  1048 18894    89]]\n",
      "Epoch=12, total_epoch_step_time=79.02, loss=589.02\n",
      "accuracy=0.9597833156585693, counts=[[19813   135     0     0]\n",
      " [  133 18688  1197     2]\n",
      " [    0   897 19086    49]]\n",
      "Epoch=13, total_epoch_step_time=85.40, loss=595.96\n",
      "accuracy=0.9653333425521851, counts=[[19851    97     0     0]\n",
      " [  108 18891  1020     1]\n",
      " [    0   815 19178    39]]\n",
      "Epoch=14, total_epoch_step_time=91.47, loss=601.13\n",
      "accuracy=0.9714333415031433, counts=[[19885    63     0     0]\n",
      " [   94 19165   760     1]\n",
      " [    0   766 19236    30]]\n",
      "Epoch=15, total_epoch_step_time=98.24, loss=604.86\n",
      "accuracy=0.9731166958808899, counts=[[19908    40     0     0]\n",
      " [   88 19374   557     1]\n",
      " [    0   911 19105    16]]\n",
      "Epoch=16, total_epoch_step_time=104.29, loss=608.07\n",
      "accuracy=0.9764000177383423, counts=[[19911    37     0     0]\n",
      " [   57 19435   526     2]\n",
      " [    0   778 19238    16]]\n",
      "Epoch=17, total_epoch_step_time=110.35, loss=610.94\n",
      "accuracy=0.9769666790962219, counts=[[19928    20     0     0]\n",
      " [   47 19598   374     1]\n",
      " [    0   930 19092    10]]\n",
      "Epoch=18, total_epoch_step_time=116.40, loss=613.50\n",
      "accuracy=0.9785500168800354, counts=[[19927    21     0     0]\n",
      " [   45 19449   526     0]\n",
      " [    0   682 19337    13]]\n",
      "Epoch=19, total_epoch_step_time=122.43, loss=615.81\n",
      "accuracy=0.979033350944519, counts=[[19928    20     0     0]\n",
      " [   42 19495   483     0]\n",
      " [    0   698 19319    15]]\n",
      "Epoch=20, total_epoch_step_time=128.49, loss=617.78\n",
      "accuracy=0.9801833629608154, counts=[[19932    16     0     0]\n",
      " [   34 19529   456     1]\n",
      " [    0   670 19350    12]]\n",
      "Epoch=21, total_epoch_step_time=134.56, loss=619.55\n",
      "accuracy=0.980733335018158, counts=[[19930    18     0     0]\n",
      " [   30 19607   383     0]\n",
      " [    0   719 19307     6]]\n",
      "Epoch=22, total_epoch_step_time=140.62, loss=621.17\n",
      "accuracy=0.9812666773796082, counts=[[19936    12     0     0]\n",
      " [   26 19597   396     1]\n",
      " [    0   683 19343     6]]\n",
      "Epoch=23, total_epoch_step_time=146.69, loss=622.59\n",
      "accuracy=0.9814666509628296, counts=[[19937    11     0     0]\n",
      " [   23 19659   337     1]\n",
      " [    0   732 19292     8]]\n",
      "Epoch=24, total_epoch_step_time=152.75, loss=623.92\n",
      "accuracy=0.9817667007446289, counts=[[19935    13     0     0]\n",
      " [   29 19672   318     1]\n",
      " [    0   727 19299     6]]\n",
      "Epoch=25, total_epoch_step_time=158.81, loss=625.12\n",
      "accuracy=0.9822166562080383, counts=[[19940     8     0     0]\n",
      " [   26 19634   359     1]\n",
      " [    0   665 19359     8]]\n",
      "Epoch=26, total_epoch_step_time=165.28, loss=626.23\n",
      "accuracy=0.9840333461761475, counts=[[19931    17     0     0]\n",
      " [   15 19657   348     0]\n",
      " [    0   569 19454     9]]\n",
      "Epoch=27, total_epoch_step_time=171.60, loss=627.21\n",
      "accuracy=0.9833166599273682, counts=[[19940     8     0     0]\n",
      " [   20 19698   301     1]\n",
      " [    0   663 19361     8]]\n",
      "Epoch=28, total_epoch_step_time=177.85, loss=628.24\n",
      "accuracy=0.9836500287055969, counts=[[19941     7     0     0]\n",
      " [   15 19672   332     1]\n",
      " [    0   619 19406     7]]\n",
      "Epoch=29, total_epoch_step_time=184.85, loss=628.94\n",
      "accuracy=0.9837666749954224, counts=[[19939     9     0     0]\n",
      " [    9 19709   301     1]\n",
      " [    0   646 19378     8]]\n",
      "Epoch=30, total_epoch_step_time=191.74, loss=629.69\n",
      "accuracy=0.9837833642959595, counts=[[19942     6     0     0]\n",
      " [   18 19697   304     1]\n",
      " [    0   638 19388     6]]\n",
      "Epoch=31, total_epoch_step_time=198.60, loss=630.53\n",
      "accuracy=0.9837833642959595, counts=[[19938    10     0     0]\n",
      " [   10 19720   290     0]\n",
      " [    0   657 19369     6]]\n",
      "Epoch=32, total_epoch_step_time=205.46, loss=631.16\n",
      "accuracy=0.9846000075340271, counts=[[19939     9     0     0]\n",
      " [    8 19697   314     1]\n",
      " [    0   586 19440     6]]\n",
      "Epoch=33, total_epoch_step_time=212.31, loss=631.80\n",
      "accuracy=0.9847666621208191, counts=[[19941     7     0     0]\n",
      " [   12 19704   303     1]\n",
      " [    0   586 19441     5]]\n",
      "Epoch=34, total_epoch_step_time=219.11, loss=632.33\n",
      "accuracy=0.9845166802406311, counts=[[19943     5     0     0]\n",
      " [   15 19735   269     1]\n",
      " [    0   634 19393     5]]\n",
      "Epoch=35, total_epoch_step_time=225.87, loss=632.90\n",
      "accuracy=0.9844666719436646, counts=[[19940     8     0     0]\n",
      " [   11 19697   312     0]\n",
      " [    0   594 19431     7]]\n",
      "Epoch=36, total_epoch_step_time=232.65, loss=633.42\n",
      "accuracy=0.9850500226020813, counts=[[19945     3     0     0]\n",
      " [    7 19709   303     1]\n",
      " [    0   578 19449     5]]\n",
      "Epoch=37, total_epoch_step_time=239.42, loss=633.90\n",
      "accuracy=0.9855333566665649, counts=[[19943     5     0     0]\n",
      " [    4 19720   295     1]\n",
      " [    0   558 19469     5]]\n",
      "Epoch=38, total_epoch_step_time=246.26, loss=634.35\n",
      "accuracy=0.9852333664894104, counts=[[19940     8     0     0]\n",
      " [    5 19716   298     1]\n",
      " [    0   568 19458     6]]\n",
      "Epoch=39, total_epoch_step_time=253.08, loss=634.84\n",
      "accuracy=0.9843833446502686, counts=[[19940     8     0     0]\n",
      " [    5 19756   259     0]\n",
      " [    0   659 19367     6]]\n",
      "Epoch=40, total_epoch_step_time=259.90, loss=635.23\n",
      "accuracy=0.9854833483695984, counts=[[19945     3     0     0]\n",
      " [    8 19733   278     1]\n",
      " [    0   575 19451     6]]\n",
      "Epoch=0, total_epoch_step_time=6.49, loss=55.17\n",
      "accuracy=0.22153334319591522, counts=[[11052  8158   730     8]\n",
      " [17761  2240    19     0]\n",
      " [19554   478     0     0]]\n",
      "Epoch=1, total_epoch_step_time=13.06, loss=409.12\n",
      "accuracy=0.2241833359003067, counts=[[11360  7710   871     7]\n",
      " [17910  2088    22     0]\n",
      " [19482   547     3     0]]\n",
      "Epoch=2, total_epoch_step_time=19.82, loss=429.06\n",
      "accuracy=0.22708334028720856, counts=[[11702  7418   820     8]\n",
      " [18086  1922    12     0]\n",
      " [19414   617     1     0]]\n",
      "Epoch=3, total_epoch_step_time=26.62, loss=446.71\n",
      "accuracy=0.23666666448116302, counts=[[12410  6933   596     9]\n",
      " [18210  1790    20     0]\n",
      " [19467   565     0     0]]\n",
      "Epoch=4, total_epoch_step_time=33.33, loss=455.66\n",
      "accuracy=0.24729999899864197, counts=[[13129  6301   513     5]\n",
      " [18293  1708    19     0]\n",
      " [19520   511     1     0]]\n",
      "Epoch=5, total_epoch_step_time=40.04, loss=457.80\n",
      "accuracy=0.2601666748523712, counts=[[13899  5743   305     1]\n",
      " [18297  1709    14     0]\n",
      " [19414   616     2     0]]\n",
      "Epoch=6, total_epoch_step_time=46.77, loss=458.99\n",
      "accuracy=0.2802833318710327, counts=[[14598  5038   310     2]\n",
      " [17774  2219    27     0]\n",
      " [18844  1188     0     0]]\n",
      "Epoch=7, total_epoch_step_time=53.50, loss=462.90\n",
      "accuracy=0.4184499979019165, counts=[[14648  4698   591    11]\n",
      " [ 5393  6397  4540  3690]\n",
      " [ 2458  3139  4062 10373]]\n",
      "Epoch=8, total_epoch_step_time=60.25, loss=500.46\n",
      "accuracy=0.6793333292007446, counts=[[15402  4410   136     0]\n",
      " [  665 10011  9098   246]\n",
      " [   72  1320 15347  3293]]\n",
      "Epoch=9, total_epoch_step_time=67.05, loss=536.44\n",
      "accuracy=0.7791833281517029, counts=[[17267  2660    21     0]\n",
      " [  322 11492  8159    47]\n",
      " [    9  1364 17992   667]]\n",
      "Epoch=10, total_epoch_step_time=73.94, loss=556.07\n",
      "accuracy=0.8285333514213562, counts=[[18892  1055     1     0]\n",
      " [  234 11985  7792     9]\n",
      " [    0   972 18835   225]]\n",
      "Epoch=11, total_epoch_step_time=80.82, loss=572.75\n",
      "accuracy=0.8541666865348816, counts=[[19542   406     0     0]\n",
      " [  206 12543  7267     4]\n",
      " [    3   756 19165   108]]\n",
      "Epoch=12, total_epoch_step_time=87.63, loss=583.99\n",
      "accuracy=0.8707166910171509, counts=[[19745   203     0     0]\n",
      " [  172 13265  6582     1]\n",
      " [    0   746 19233    53]]\n",
      "Epoch=13, total_epoch_step_time=94.47, loss=591.37\n",
      "accuracy=0.8803833723068237, counts=[[19845   103     0     0]\n",
      " [  134 13601  6284     1]\n",
      " [    1   619 19377    35]]\n",
      "Epoch=14, total_epoch_step_time=101.36, loss=596.99\n",
      "accuracy=0.8842666745185852, counts=[[19882    66     0     0]\n",
      " [   96 13750  6172     2]\n",
      " [    0   578 19424    30]]\n",
      "Epoch=15, total_epoch_step_time=108.31, loss=601.27\n",
      "accuracy=0.8917666673660278, counts=[[19910    38     0     0]\n",
      " [   90 14190  5739     1]\n",
      " [    0   612 19406    14]]\n",
      "Epoch=16, total_epoch_step_time=115.22, loss=604.75\n",
      "accuracy=0.8950333595275879, counts=[[19920    28     0     0]\n",
      " [   75 14272  5670     3]\n",
      " [    0   508 19510    14]]\n",
      "Epoch=17, total_epoch_step_time=122.13, loss=607.79\n",
      "accuracy=0.8978333473205566, counts=[[19913    35     0     0]\n",
      " [   56 14489  5474     1]\n",
      " [    0   554 19468    10]]\n",
      "Epoch=18, total_epoch_step_time=129.01, loss=610.39\n",
      "accuracy=0.9007999897003174, counts=[[19929    19     0     0]\n",
      " [   54 14602  5363     1]\n",
      " [    0   505 19517    10]]\n",
      "Epoch=19, total_epoch_step_time=135.93, loss=612.87\n",
      "accuracy=0.9031333327293396, counts=[[19923    25     0     0]\n",
      " [   38 14817  5163     2]\n",
      " [    1   572 19448    11]]\n",
      "Epoch=20, total_epoch_step_time=142.81, loss=614.98\n",
      "accuracy=0.906166672706604, counts=[[19934    14     0     0]\n",
      " [   45 15001  4973     1]\n",
      " [    0   589 19435     8]]\n",
      "Epoch=21, total_epoch_step_time=149.68, loss=616.69\n",
      "accuracy=0.9079000353813171, counts=[[19935    13     0     0]\n",
      " [   33 15015  4972     0]\n",
      " [    0   499 19524     9]]\n",
      "Epoch=22, total_epoch_step_time=156.44, loss=618.36\n",
      "accuracy=0.9087666869163513, counts=[[19933    15     0     0]\n",
      " [   16 15015  4989     0]\n",
      " [    0   445 19578     9]]\n",
      "Epoch=23, total_epoch_step_time=163.32, loss=619.95\n",
      "accuracy=0.9117166996002197, counts=[[19932    16     0     0]\n",
      " [   31 15285  4704     0]\n",
      " [    0   541 19486     5]]\n",
      "Epoch=24, total_epoch_step_time=170.21, loss=621.35\n",
      "accuracy=0.9122166633605957, counts=[[19935    13     0     0]\n",
      " [   30 15234  4756     0]\n",
      " [    0   463 19564     5]]\n",
      "Epoch=25, total_epoch_step_time=176.98, loss=622.63\n",
      "accuracy=0.9146333336830139, counts=[[19938    10     0     0]\n",
      " [   28 15462  4530     0]\n",
      " [    0   550 19478     4]]\n",
      "Epoch=26, total_epoch_step_time=183.52, loss=623.80\n",
      "accuracy=0.9141499996185303, counts=[[19935    13     0     0]\n",
      " [   16 15332  4672     0]\n",
      " [    0   446 19582     4]]\n",
      "Epoch=27, total_epoch_step_time=190.44, loss=624.83\n",
      "accuracy=0.9152166843414307, counts=[[19934    14     0     0]\n",
      " [   19 15484  4517     0]\n",
      " [    0   531 19495     6]]\n",
      "Epoch=28, total_epoch_step_time=197.30, loss=625.87\n",
      "accuracy=0.9164666533470154, counts=[[19944     4     0     0]\n",
      " [   22 15508  4490     0]\n",
      " [    0   492 19536     4]]\n",
      "Epoch=29, total_epoch_step_time=204.15, loss=626.75\n",
      "accuracy=0.9156166911125183, counts=[[19941     7     0     0]\n",
      " [   20 15439  4560     1]\n",
      " [    0   473 19557     2]]\n",
      "Epoch=30, total_epoch_step_time=210.96, loss=627.60\n",
      "accuracy=0.9157166481018066, counts=[[19936    12     0     0]\n",
      " [   17 15432  4571     0]\n",
      " [    0   454 19575     3]]\n",
      "Epoch=31, total_epoch_step_time=217.77, loss=628.32\n",
      "accuracy=0.9176999926567078, counts=[[19938    10     0     0]\n",
      " [   14 15553  4453     0]\n",
      " [    0   458 19571     3]]\n",
      "Epoch=32, total_epoch_step_time=224.65, loss=629.03\n",
      "accuracy=0.9169166684150696, counts=[[19943     5     0     0]\n",
      " [    8 15493  4518     1]\n",
      " [    0   447 19579     6]]\n",
      "Epoch=33, total_epoch_step_time=231.47, loss=629.66\n",
      "accuracy=0.9192166924476624, counts=[[19941     7     0     0]\n",
      " [   19 15672  4328     1]\n",
      " [    0   487 19540     5]]\n",
      "Epoch=34, total_epoch_step_time=238.25, loss=630.29\n",
      "accuracy=0.9194000363349915, counts=[[19941     7     0     0]\n",
      " [   15 15685  4320     0]\n",
      " [    0   492 19538     2]]\n",
      "Epoch=35, total_epoch_step_time=245.13, loss=630.87\n",
      "accuracy=0.9192333221435547, counts=[[19937    11     0     0]\n",
      " [    9 15676  4335     0]\n",
      " [    0   485 19541     6]]\n",
      "Epoch=36, total_epoch_step_time=251.97, loss=631.38\n",
      "accuracy=0.9187833666801453, counts=[[19945     3     0     0]\n",
      " [    9 15595  4414     2]\n",
      " [    0   443 19587     2]]\n",
      "Epoch=37, total_epoch_step_time=258.44, loss=631.89\n",
      "accuracy=0.9194666743278503, counts=[[19942     6     0     0]\n",
      " [   10 15632  4377     1]\n",
      " [    0   434 19594     4]]\n",
      "Epoch=38, total_epoch_step_time=265.01, loss=632.34\n",
      "accuracy=0.9189833402633667, counts=[[19940     8     0     0]\n",
      " [    9 15612  4399     0]\n",
      " [    0   440 19587     5]]\n",
      "Epoch=39, total_epoch_step_time=271.08, loss=632.75\n",
      "accuracy=0.9200500249862671, counts=[[19946     2     0     0]\n",
      " [   10 15682  4328     0]\n",
      " [    0   453 19575     4]]\n",
      "Epoch=40, total_epoch_step_time=277.40, loss=633.15\n",
      "accuracy=0.9200167059898376, counts=[[19945     3     0     0]\n",
      " [    9 15684  4327     0]\n",
      " [    0   457 19572     3]]\n",
      "Epoch=0, total_epoch_step_time=6.59, loss=54.06\n",
      "accuracy=0.22265000641345978, counts=[[11081  8144   716     7]\n",
      " [17724  2274    22     0]\n",
      " [19535   493     4     0]]\n",
      "Epoch=1, total_epoch_step_time=12.93, loss=409.32\n",
      "accuracy=0.22331666946411133, counts=[[11384  7740   808    16]\n",
      " [17982  2013    25     0]\n",
      " [19483   547     2     0]]\n",
      "Epoch=2, total_epoch_step_time=18.76, loss=429.52\n",
      "accuracy=0.22911666333675385, counts=[[11786  7349   801    12]\n",
      " [18029  1959    32     0]\n",
      " [19465   565     2     0]]\n",
      "Epoch=3, total_epoch_step_time=24.66, loss=446.99\n",
      "accuracy=0.24000000953674316, counts=[[12505  6765   672     6]\n",
      " [18109  1893    18     0]\n",
      " [19478   552     2     0]]\n",
      "Epoch=4, total_epoch_step_time=30.76, loss=455.72\n",
      "accuracy=0.25226667523384094, counts=[[13338  6145   452    13]\n",
      " [18211  1795    14     0]\n",
      " [19409   620     3     0]]\n",
      "Epoch=5, total_epoch_step_time=36.80, loss=457.86\n",
      "accuracy=0.26535001397132874, counts=[[14034  5566   343     5]\n",
      " [18109  1887    24     0]\n",
      " [19328   704     0     0]]\n",
      "Epoch=6, total_epoch_step_time=42.79, loss=459.10\n",
      "accuracy=0.29794999957084656, counts=[[14821  4791   330     6]\n",
      " [16915  3026    78     1]\n",
      " [17864  2138    30     0]]\n",
      "Epoch=7, total_epoch_step_time=48.81, loss=470.22\n",
      "accuracy=0.43096667528152466, counts=[[15000  4485   450    13]\n",
      " [ 2634  5922  7302  4162]\n",
      " [  639  1537  4936 12920]]\n",
      "Epoch=8, total_epoch_step_time=54.85, loss=509.62\n",
      "accuracy=0.8160833716392517, counts=[[16359  3530    59     0]\n",
      " [  549 16090  3356    25]\n",
      " [   29  2687 16516   800]]\n",
      "Epoch=9, total_epoch_step_time=61.00, loss=540.26\n",
      "accuracy=0.8908500075340271, counts=[[18217  1724     7     0]\n",
      " [  283 16994  2732    11]\n",
      " [    9  1410 18240   373]]\n",
      "Epoch=10, total_epoch_step_time=67.90, loss=559.77\n",
      "accuracy=0.9276333451271057, counts=[[19315   633     0     0]\n",
      " [  235 17558  2223     4]\n",
      " [    1  1061 18785   185]]\n",
      "Epoch=11, total_epoch_step_time=74.89, loss=575.83\n",
      "accuracy=0.9470333456993103, counts=[[19688   259     1     0]\n",
      " [  198 18308  1511     3]\n",
      " [    1  1116 18826    89]]\n",
      "Epoch=12, total_epoch_step_time=81.55, loss=586.35\n",
      "accuracy=0.9550166726112366, counts=[[19818   130     0     0]\n",
      " [  141 18412  1466     1]\n",
      " [    0   875 19071    86]]\n",
      "Epoch=13, total_epoch_step_time=88.43, loss=593.98\n",
      "accuracy=0.9614666700363159, counts=[[19876    72     0     0]\n",
      " [  112 18764  1143     1]\n",
      " [    2   941 19048    41]]\n",
      "Epoch=14, total_epoch_step_time=95.32, loss=598.95\n",
      "accuracy=0.9666333198547363, counts=[[19899    49     0     0]\n",
      " [   99 18958   962     1]\n",
      " [    0   858 19141    33]]\n",
      "Epoch=15, total_epoch_step_time=102.26, loss=602.94\n",
      "accuracy=0.9672666788101196, counts=[[19910    38     0     0]\n",
      " [   71 19057   890     2]\n",
      " [    0   932 19069    31]]\n",
      "Epoch=16, total_epoch_step_time=109.10, loss=606.61\n",
      "accuracy=0.9713667035102844, counts=[[19919    29     0     0]\n",
      " [   58 19113   848     1]\n",
      " [    0   751 19250    31]]\n",
      "Epoch=17, total_epoch_step_time=115.92, loss=609.58\n",
      "accuracy=0.9740166664123535, counts=[[19936    12     0     0]\n",
      " [   46 19311   661     2]\n",
      " [    0   814 19194    24]]\n",
      "Epoch=18, total_epoch_step_time=122.67, loss=612.33\n",
      "accuracy=0.9753167033195496, counts=[[19928    20     0     0]\n",
      " [   41 19429   549     1]\n",
      " [    0   846 19162    24]]\n",
      "Epoch=19, total_epoch_step_time=129.60, loss=614.78\n",
      "accuracy=0.9755499958992004, counts=[[19941     7     0     0]\n",
      " [   43 19436   541     0]\n",
      " [    0   860 19156    16]]\n",
      "Epoch=20, total_epoch_step_time=136.73, loss=616.86\n",
      "accuracy=0.9779333472251892, counts=[[19937    11     0     0]\n",
      " [   29 19419   571     1]\n",
      " [    0   695 19320    17]]\n",
      "Epoch=21, total_epoch_step_time=143.69, loss=618.65\n",
      "accuracy=0.9791333675384521, counts=[[19942     6     0     0]\n",
      " [   31 19424   565     0]\n",
      " [    0   634 19382    16]]\n",
      "Epoch=22, total_epoch_step_time=150.50, loss=620.27\n",
      "accuracy=0.9788333177566528, counts=[[19933    15     0     0]\n",
      " [   31 19550   439     0]\n",
      " [    0   774 19247    11]]\n",
      "Epoch=23, total_epoch_step_time=157.31, loss=621.72\n",
      "accuracy=0.9801999926567078, counts=[[19940     8     0     0]\n",
      " [   26 19453   541     0]\n",
      " [    0   603 19419    10]]\n",
      "Epoch=24, total_epoch_step_time=164.18, loss=623.05\n",
      "accuracy=0.9809666872024536, counts=[[19938    10     0     0]\n",
      " [   26 19548   446     0]\n",
      " [    0   648 19372    12]]\n",
      "Epoch=25, total_epoch_step_time=171.04, loss=624.23\n",
      "accuracy=0.980983316898346, counts=[[19941     7     0     0]\n",
      " [   25 19587   408     0]\n",
      " [    0   691 19331    10]]\n",
      "Epoch=26, total_epoch_step_time=178.05, loss=625.43\n",
      "accuracy=0.9808499813079834, counts=[[19943     5     0     0]\n",
      " [   21 19620   379     0]\n",
      " [    0   737 19288     7]]\n",
      "Epoch=27, total_epoch_step_time=184.81, loss=626.43\n",
      "accuracy=0.9818666577339172, counts=[[19936    12     0     0]\n",
      " [   10 19626   384     0]\n",
      " [    0   676 19350     6]]\n",
      "Epoch=28, total_epoch_step_time=191.56, loss=627.37\n",
      "accuracy=0.9817000031471252, counts=[[19941     7     0     0]\n",
      " [   12 19577   431     0]\n",
      " [    0   641 19384     7]]\n",
      "Epoch=29, total_epoch_step_time=198.44, loss=628.27\n",
      "accuracy=0.9819833636283875, counts=[[19937    11     0     0]\n",
      " [   11 19640   369     0]\n",
      " [    0   683 19342     7]]\n",
      "Epoch=30, total_epoch_step_time=205.29, loss=629.06\n",
      "accuracy=0.9813666939735413, counts=[[19942     6     0     0]\n",
      " [   14 19644   362     0]\n",
      " [    0   726 19296    10]]\n",
      "Epoch=31, total_epoch_step_time=212.15, loss=629.81\n",
      "accuracy=0.98253333568573, counts=[[19944     4     0     0]\n",
      " [   16 19620   384     0]\n",
      " [    0   637 19388     7]]\n",
      "Epoch=32, total_epoch_step_time=218.91, loss=630.51\n",
      "accuracy=0.9829500317573547, counts=[[19942     6     0     0]\n",
      " [   12 19637   371     0]\n",
      " [    0   626 19398     8]]\n",
      "Epoch=33, total_epoch_step_time=225.66, loss=631.15\n",
      "accuracy=0.9825666546821594, counts=[[19931    17     0     0]\n",
      " [   13 19601   406     0]\n",
      " [    0   603 19422     7]]\n",
      "Epoch=34, total_epoch_step_time=232.44, loss=631.76\n",
      "accuracy=0.9828166961669922, counts=[[19945     3     0     0]\n",
      " [    8 19643   369     0]\n",
      " [    0   646 19381     5]]\n",
      "Epoch=35, total_epoch_step_time=239.23, loss=632.36\n",
      "accuracy=0.9828833341598511, counts=[[19933    15     0     0]\n",
      " [   11 19625   384     0]\n",
      " [    0   609 19415     8]]\n",
      "Epoch=36, total_epoch_step_time=246.06, loss=632.92\n",
      "accuracy=0.9833166599273682, counts=[[19938    10     0     0]\n",
      " [   11 19660   349     0]\n",
      " [    0   624 19401     7]]\n",
      "Epoch=37, total_epoch_step_time=253.11, loss=633.41\n",
      "accuracy=0.9836166501045227, counts=[[19941     7     0     0]\n",
      " [    9 19668   343     0]\n",
      " [    0   618 19408     6]]\n",
      "Epoch=38, total_epoch_step_time=259.98, loss=633.86\n",
      "accuracy=0.9833333492279053, counts=[[19942     6     0     0]\n",
      " [    8 19680   332     0]\n",
      " [    0   649 19378     5]]\n",
      "Epoch=39, total_epoch_step_time=266.82, loss=634.33\n",
      "accuracy=0.9837833642959595, counts=[[19939     9     0     0]\n",
      " [   10 19662   348     0]\n",
      " [    0   599 19426     7]]\n",
      "Epoch=40, total_epoch_step_time=273.65, loss=634.66\n",
      "accuracy=0.9843167066574097, counts=[[19938    10     0     0]\n",
      " [    7 19682   331     0]\n",
      " [    0   584 19439     9]]\n",
      "Epoch=0, total_epoch_step_time=6.63, loss=51.59\n",
      "accuracy=0.22394999861717224, counts=[[11147  8046   748     7]\n",
      " [17708  2289    23     0]\n",
      " [19516   515     1     0]]\n",
      "Epoch=1, total_epoch_step_time=13.33, loss=409.46\n",
      "accuracy=0.22370000183582306, counts=[[11291  7807   835    15]\n",
      " [17872  2128    20     0]\n",
      " [19484   545     3     0]]\n",
      "Epoch=2, total_epoch_step_time=20.18, loss=429.70\n",
      "accuracy=0.23096667230129242, counts=[[11852  7325   760    11]\n",
      " [17987  2006    27     0]\n",
      " [19420   612     0     0]]\n",
      "Epoch=3, total_epoch_step_time=26.88, loss=447.10\n",
      "accuracy=0.23831667006015778, counts=[[12342  6968   626    12]\n",
      " [18042  1955    23     0]\n",
      " [19455   575     2     0]]\n",
      "Epoch=4, total_epoch_step_time=33.58, loss=455.75\n",
      "accuracy=0.2513166666030884, counts=[[13275  6236   431     6]\n",
      " [18204  1802    14     0]\n",
      " [19456   574     2     0]]\n",
      "Epoch=5, total_epoch_step_time=40.25, loss=457.89\n",
      "accuracy=0.2675666809082031, counts=[[14072  5567   305     4]\n",
      " [18012  1981    27     0]\n",
      " [19319   712     1     0]]\n",
      "Epoch=6, total_epoch_step_time=46.97, loss=459.10\n",
      "accuracy=0.30196666717529297, counts=[[14751  4871   320     6]\n",
      " [16597  3318   104     1]\n",
      " [17601  2382    49     0]]\n",
      "Epoch=7, total_epoch_step_time=53.69, loss=472.13\n",
      "accuracy=0.41423332691192627, counts=[[14939  4486   516     7]\n",
      " [ 2286  5189  7854  4691]\n",
      " [  510  1142  4726 13654]]\n",
      "Epoch=8, total_epoch_step_time=60.48, loss=510.50\n",
      "accuracy=0.7991666793823242, counts=[[16473  3424    51     0]\n",
      " [  574 16155  3259    32]\n",
      " [   34  3750 15322   926]]\n",
      "Epoch=9, total_epoch_step_time=67.28, loss=540.63\n",
      "accuracy=0.8823833465576172, counts=[[18166  1774     8     0]\n",
      " [  287 17154  2575     4]\n",
      " [    6  1944 17623   459]]\n",
      "Epoch=10, total_epoch_step_time=74.07, loss=556.78\n",
      "accuracy=0.9239333271980286, counts=[[19202   746     0     0]\n",
      " [  227 17746  2042     5]\n",
      " [    2  1341 18488   201]]\n",
      "Epoch=11, total_epoch_step_time=80.89, loss=573.43\n",
      "accuracy=0.9493333697319031, counts=[[19665   283     0     0]\n",
      " [  163 18450  1405     2]\n",
      " [    2  1082 18845   103]]\n",
      "Epoch=12, total_epoch_step_time=87.70, loss=586.26\n",
      "accuracy=0.9597833156585693, counts=[[19798   150     0     0]\n",
      " [  163 18895   961     1]\n",
      " [    1  1098 18894    39]]\n",
      "Epoch=13, total_epoch_step_time=94.46, loss=594.46\n",
      "accuracy=0.967033326625824, counts=[[19876    72     0     0]\n",
      " [   99 19010   910     1]\n",
      " [    0   869 19136    27]]\n",
      "Epoch=14, total_epoch_step_time=101.30, loss=599.76\n",
      "accuracy=0.9698166847229004, counts=[[19898    50     0     0]\n",
      " [   99 19135   786     0]\n",
      " [    0   852 19156    24]]\n",
      "Epoch=15, total_epoch_step_time=108.06, loss=603.98\n",
      "accuracy=0.9729000329971313, counts=[[19911    37     0     0]\n",
      " [   89 19316   615     0]\n",
      " [    0   869 19147    16]]\n",
      "Epoch=16, total_epoch_step_time=114.84, loss=607.40\n",
      "accuracy=0.9759333729743958, counts=[[19902    46     0     0]\n",
      " [   74 19359   586     1]\n",
      " [    0   722 19295    15]]\n",
      "Epoch=17, total_epoch_step_time=121.59, loss=610.37\n",
      "accuracy=0.9779666662216187, counts=[[19924    24     0     0]\n",
      " [   60 19477   482     1]\n",
      " [    0   743 19277    12]]\n",
      "Epoch=18, total_epoch_step_time=128.33, loss=613.30\n",
      "accuracy=0.9788833260536194, counts=[[19930    18     0     0]\n",
      " [   40 19550   429     1]\n",
      " [    0   772 19253     7]]\n",
      "Epoch=19, total_epoch_step_time=135.11, loss=615.80\n",
      "accuracy=0.9799667000770569, counts=[[19932    16     0     0]\n",
      " [   49 19635   336     0]\n",
      " [    0   794 19231     7]]\n",
      "Epoch=20, total_epoch_step_time=141.85, loss=617.83\n",
      "accuracy=0.980983316898346, counts=[[19929    19     0     0]\n",
      " [   32 19508   479     1]\n",
      " [    0   601 19422     9]]\n",
      "Epoch=21, total_epoch_step_time=148.62, loss=619.70\n",
      "accuracy=0.9801333546638489, counts=[[19940     8     0     0]\n",
      " [   33 19640   347     0]\n",
      " [    0   796 19228     8]]\n",
      "Epoch=22, total_epoch_step_time=155.42, loss=621.35\n",
      "accuracy=0.9813500046730042, counts=[[19939     9     0     0]\n",
      " [   39 19669   312     0]\n",
      " [    0   756 19273     3]]\n",
      "Epoch=23, total_epoch_step_time=162.22, loss=622.86\n",
      "accuracy=0.9822999835014343, counts=[[19941     7     0     0]\n",
      " [   22 19572   426     0]\n",
      " [    0   600 19425     7]]\n",
      "Epoch=24, total_epoch_step_time=168.99, loss=624.23\n",
      "accuracy=0.9828333258628845, counts=[[19937    11     0     0]\n",
      " [   24 19678   318     0]\n",
      " [    0   672 19355     5]]\n",
      "Epoch=25, total_epoch_step_time=175.79, loss=625.46\n",
      "accuracy=0.9831333160400391, counts=[[19934    14     0     0]\n",
      " [   17 19663   340     0]\n",
      " [    0   635 19391     6]]\n",
      "Epoch=26, total_epoch_step_time=182.54, loss=626.58\n",
      "accuracy=0.9827166795730591, counts=[[19931    17     0     0]\n",
      " [   22 19695   303     0]\n",
      " [    0   685 19337    10]]\n",
      "Epoch=27, total_epoch_step_time=189.30, loss=627.59\n",
      "accuracy=0.984499990940094, counts=[[19941     7     0     0]\n",
      " [   15 19675   330     0]\n",
      " [    0   571 19454     7]]\n",
      "Epoch=28, total_epoch_step_time=196.12, loss=628.53\n",
      "accuracy=0.9834666848182678, counts=[[19936    12     0     0]\n",
      " [   16 19740   264     0]\n",
      " [    0   694 19332     6]]\n",
      "Epoch=29, total_epoch_step_time=202.92, loss=629.35\n",
      "accuracy=0.9833500385284424, counts=[[19937    11     0     0]\n",
      " [    8 19778   234     0]\n",
      " [    0   743 19286     3]]\n",
      "Epoch=30, total_epoch_step_time=209.76, loss=630.10\n",
      "accuracy=0.9840666651725769, counts=[[19943     5     0     0]\n",
      " [   12 19744   264     0]\n",
      " [    0   671 19357     4]]\n",
      "Epoch=31, total_epoch_step_time=216.55, loss=630.76\n",
      "accuracy=0.9839833378791809, counts=[[19941     7     0     0]\n",
      " [   14 19754   252     0]\n",
      " [    1   682 19344     5]]\n",
      "Epoch=32, total_epoch_step_time=223.31, loss=631.44\n",
      "accuracy=0.9847000241279602, counts=[[19942     6     0     0]\n",
      " [   13 19718   289     0]\n",
      " [    0   605 19422     5]]\n",
      "Epoch=33, total_epoch_step_time=230.07, loss=632.10\n",
      "accuracy=0.9852499961853027, counts=[[19943     5     0     0]\n",
      " [    7 19673   340     0]\n",
      " [    0   527 19499     6]]\n",
      "Epoch=34, total_epoch_step_time=236.83, loss=632.70\n",
      "accuracy=0.9846333265304565, counts=[[19939     9     0     0]\n",
      " [    9 19726   285     0]\n",
      " [    0   614 19413     5]]\n",
      "Epoch=35, total_epoch_step_time=243.56, loss=633.18\n",
      "accuracy=0.9850167036056519, counts=[[19942     6     0     0]\n",
      " [   11 19707   302     0]\n",
      " [    0   573 19452     7]]\n",
      "Epoch=36, total_epoch_step_time=250.31, loss=633.72\n",
      "accuracy=0.9847333431243896, counts=[[19943     5     0     0]\n",
      " [    7 19765   248     0]\n",
      " [    0   652 19376     4]]\n",
      "Epoch=37, total_epoch_step_time=257.06, loss=634.26\n",
      "accuracy=0.9852166771888733, counts=[[19937    11     0     0]\n",
      " [    9 19735   276     0]\n",
      " [    0   585 19441     6]]\n",
      "Epoch=38, total_epoch_step_time=263.91, loss=634.74\n",
      "accuracy=0.985366702079773, counts=[[19940     8     0     0]\n",
      " [    7 19756   257     0]\n",
      " [    0   603 19426     3]]\n",
      "Epoch=39, total_epoch_step_time=270.70, loss=635.21\n",
      "accuracy=0.9857333302497864, counts=[[19943     5     0     0]\n",
      " [    6 19762   252     0]\n",
      " [    0   590 19439     3]]\n",
      "Epoch=40, total_epoch_step_time=277.49, loss=635.58\n",
      "accuracy=0.9855166673660278, counts=[[19944     4     0     0]\n",
      " [    6 19754   260     0]\n",
      " [    0   594 19433     5]]\n",
      "Epoch=0, total_epoch_step_time=6.63, loss=50.71\n",
      "accuracy=0.22105000913143158, counts=[[11091  8148   705     4]\n",
      " [17826  2172    22     0]\n",
      " [19505   527     0     0]]\n",
      "Epoch=1, total_epoch_step_time=13.48, loss=409.07\n",
      "accuracy=0.22263333201408386, counts=[[11347  7754   837    10]\n",
      " [17985  2009    25     1]\n",
      " [19498   532     2     0]]\n",
      "Epoch=2, total_epoch_step_time=20.68, loss=428.84\n",
      "accuracy=0.22715000808238983, counts=[[11658  7531   751     8]\n",
      " [18026  1969    25     0]\n",
      " [19469   561     2     0]]\n",
      "Epoch=3, total_epoch_step_time=27.34, loss=446.44\n",
      "accuracy=0.2370833307504654, counts=[[12452  6823   665     8]\n",
      " [18226  1772    22     0]\n",
      " [19494   537     1     0]]\n",
      "Epoch=4, total_epoch_step_time=34.03, loss=455.61\n",
      "accuracy=0.24631667137145996, counts=[[13085  6404   455     4]\n",
      " [18312  1694    14     0]\n",
      " [19495   537     0     0]]\n",
      "Epoch=5, total_epoch_step_time=40.76, loss=457.80\n",
      "accuracy=0.25903332233428955, counts=[[13931  5690   324     3]\n",
      " [18394  1609    17     0]\n",
      " [19460   570     2     0]]\n",
      "Epoch=6, total_epoch_step_time=47.45, loss=458.99\n",
      "accuracy=0.28468334674835205, counts=[[14696  4946   302     4]\n",
      " [17607  2380    33     0]\n",
      " [18786  1241     5     0]]\n",
      "Epoch=7, total_epoch_step_time=54.12, loss=463.74\n",
      "accuracy=0.4328500032424927, counts=[[14912  4452   572    12]\n",
      " [ 4725  6583  5007  3705]\n",
      " [ 1747  3011  4476 10798]]\n",
      "Epoch=8, total_epoch_step_time=60.83, loss=499.25\n",
      "accuracy=0.7201833128929138, counts=[[15958  3898    92     0]\n",
      " [  691 11459  7720   150]\n",
      " [   59  1475 15794  2704]]\n",
      "Epoch=9, total_epoch_step_time=67.67, loss=535.31\n",
      "accuracy=0.8302333354949951, counts=[[17800  2133    15     0]\n",
      " [  347 13818  5835    20]\n",
      " [   10  1101 18196   725]]\n",
      "Epoch=10, total_epoch_step_time=74.75, loss=554.24\n",
      "accuracy=0.8806666731834412, counts=[[19139   809     0     0]\n",
      " [  256 14852  4906     6]\n",
      " [    3   912 18849   268]]\n",
      "Epoch=11, total_epoch_step_time=81.55, loss=571.47\n",
      "accuracy=0.9103833436965942, counts=[[19636   312     0     0]\n",
      " [  196 15877  3943     4]\n",
      " [    1   825 19110    96]]\n",
      "Epoch=12, total_epoch_step_time=88.50, loss=583.51\n",
      "accuracy=0.9315500259399414, counts=[[19811   137     0     0]\n",
      " [  168 17058  2791     3]\n",
      " [    1   956 19024    51]]\n",
      "Epoch=13, total_epoch_step_time=95.43, loss=591.36\n",
      "accuracy=0.9398666620254517, counts=[[19856    91     1     0]\n",
      " [  114 17390  2512     4]\n",
      " [    1   844 19146    41]]\n",
      "Epoch=14, total_epoch_step_time=102.23, loss=596.94\n",
      "accuracy=0.9501166939735413, counts=[[19907    41     0     0]\n",
      " [   97 17881  2040     2]\n",
      " [    1   783 19219    29]]\n",
      "Epoch=15, total_epoch_step_time=108.97, loss=601.13\n",
      "accuracy=0.9574666619300842, counts=[[19910    38     0     0]\n",
      " [   90 18362  1567     1]\n",
      " [    0   835 19176    21]]\n",
      "Epoch=16, total_epoch_step_time=115.75, loss=604.78\n",
      "accuracy=0.9649167060852051, counts=[[19920    28     0     0]\n",
      " [   75 18672  1272     1]\n",
      " [    0   713 19303    16]]\n",
      "Epoch=17, total_epoch_step_time=122.51, loss=608.02\n",
      "accuracy=0.9699500203132629, counts=[[19924    24     0     0]\n",
      " [   57 19054   908     1]\n",
      " [    0   794 19219    19]]\n",
      "Epoch=18, total_epoch_step_time=129.64, loss=610.77\n",
      "accuracy=0.9749500155448914, counts=[[19931    17     0     0]\n",
      " [   67 19357   595     1]\n",
      " [    0   812 19209    11]]\n",
      "Epoch=19, total_epoch_step_time=136.95, loss=613.25\n",
      "accuracy=0.9760833382606506, counts=[[19936    12     0     0]\n",
      " [   53 19395   571     1]\n",
      " [    0   786 19234    12]]\n",
      "Epoch=20, total_epoch_step_time=143.86, loss=615.37\n",
      "accuracy=0.9780166745185852, counts=[[19936    12     0     0]\n",
      " [   47 19557   415     1]\n",
      " [    0   834 19188    10]]\n",
      "Epoch=21, total_epoch_step_time=150.65, loss=617.30\n",
      "accuracy=0.979283332824707, counts=[[19934    14     0     0]\n",
      " [   33 19570   417     0]\n",
      " [    0   774 19253     5]]\n",
      "Epoch=22, total_epoch_step_time=157.45, loss=619.00\n",
      "accuracy=0.9810500144958496, counts=[[19933    15     0     0]\n",
      " [   36 19578   405     1]\n",
      " [    0   676 19352     4]]\n",
      "Epoch=23, total_epoch_step_time=164.22, loss=620.47\n",
      "accuracy=0.9814833402633667, counts=[[19941     7     0     0]\n",
      " [   30 19535   454     1]\n",
      " [    0   612 19413     7]]\n",
      "Epoch=24, total_epoch_step_time=171.00, loss=621.90\n",
      "accuracy=0.982366681098938, counts=[[19940     8     0     0]\n",
      " [   22 19592   405     1]\n",
      " [    0   618 19410     4]]\n",
      "Epoch=25, total_epoch_step_time=177.78, loss=623.19\n",
      "accuracy=0.9823833703994751, counts=[[19936    12     0     0]\n",
      " [   26 19660   333     1]\n",
      " [    0   679 19347     6]]\n",
      "Epoch=26, total_epoch_step_time=184.55, loss=624.49\n",
      "accuracy=0.9826333522796631, counts=[[19936    12     0     0]\n",
      " [   20 19668   332     0]\n",
      " [    0   671 19354     7]]\n",
      "Epoch=27, total_epoch_step_time=191.31, loss=625.65\n",
      "accuracy=0.9833500385284424, counts=[[19942     6     0     0]\n",
      " [   20 19651   348     1]\n",
      " [    0   618 19408     6]]\n",
      "Epoch=28, total_epoch_step_time=198.13, loss=626.62\n",
      "accuracy=0.9837000370025635, counts=[[19936    12     0     0]\n",
      " [   19 19541   460     0]\n",
      " [    0   480 19545     7]]\n",
      "Epoch=29, total_epoch_step_time=205.20, loss=627.63\n",
      "accuracy=0.983833372592926, counts=[[19940     8     0     0]\n",
      " [   17 19638   365     0]\n",
      " [    0   576 19452     4]]\n",
      "Epoch=30, total_epoch_step_time=212.57, loss=628.61\n",
      "accuracy=0.9839333295822144, counts=[[19946     2     0     0]\n",
      " [   12 19707   301     0]\n",
      " [    0   643 19383     6]]\n",
      "Epoch=31, total_epoch_step_time=219.37, loss=629.29\n",
      "accuracy=0.9844333529472351, counts=[[19943     5     0     0]\n",
      " [   10 19687   323     0]\n",
      " [    0   592 19436     4]]\n",
      "Epoch=32, total_epoch_step_time=225.90, loss=630.00\n",
      "accuracy=0.9842833280563354, counts=[[19943     5     0     0]\n",
      " [   16 19673   330     1]\n",
      " [    0   588 19441     3]]\n",
      "Epoch=33, total_epoch_step_time=232.79, loss=630.67\n",
      "accuracy=0.9842000007629395, counts=[[19942     6     0     0]\n",
      " [    9 19691   320     0]\n",
      " [    0   608 19419     5]]\n",
      "Epoch=34, total_epoch_step_time=239.96, loss=631.32\n",
      "accuracy=0.9843500256538391, counts=[[19941     7     0     0]\n",
      " [   20 19678   322     0]\n",
      " [    0   584 19442     6]]\n",
      "Epoch=35, total_epoch_step_time=247.41, loss=631.97\n",
      "accuracy=0.9846333265304565, counts=[[19944     4     0     0]\n",
      " [    9 19674   337     0]\n",
      " [    0   566 19460     6]]\n",
      "Epoch=36, total_epoch_step_time=254.85, loss=632.42\n",
      "accuracy=0.9847666621208191, counts=[[19941     7     0     0]\n",
      " [   12 19694   314     0]\n",
      " [    0   575 19451     6]]\n",
      "Epoch=37, total_epoch_step_time=262.07, loss=633.03\n",
      "accuracy=0.9851000308990479, counts=[[19944     4     0     0]\n",
      " [    7 19700   313     0]\n",
      " [    1   561 19462     8]]\n",
      "Epoch=38, total_epoch_step_time=269.44, loss=633.53\n",
      "accuracy=0.9847333431243896, counts=[[19942     6     0     0]\n",
      " [   11 19713   296     0]\n",
      " [    0   597 19429     6]]\n",
      "Epoch=39, total_epoch_step_time=276.48, loss=633.98\n",
      "accuracy=0.9847833514213562, counts=[[19946     2     0     0]\n",
      " [    7 19721   292     0]\n",
      " [    0   605 19420     7]]\n",
      "Epoch=40, total_epoch_step_time=283.33, loss=634.30\n",
      "accuracy=0.9853166937828064, counts=[[19940     8     0     0]\n",
      " [    4 19700   316     0]\n",
      " [    0   546 19479     7]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Run with different random seeds.\n",
    "losses, accuracy, wall_clock_times = None, None, None\n",
    "for train_idx in range(0, 5):\n",
    "    key, sub_key = jax.random.split(key)\n",
    "    r_loss, r_acc, r_times, params = train(\n",
    "        sub_key, learning_rate=1.0e-4, n=1, batch_size=64, num_epochs=40\n",
    "    )\n",
    "    # Save run.\n",
    "    arr = np.array([r_loss, r_acc, r_times])\n",
    "    df = pd.DataFrame(\n",
    "        arr.T, columns=[\"ELBO loss\", \"Accuracy\", \"Epoch wall clock times\"]\n",
    "    )\n",
    "    df.to_csv(\n",
    "        f\"./training_runs/grasp_air_enum_epochs_41_mccoy_prior_{train_idx}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    if losses is None:\n",
    "        losses = r_loss\n",
    "        accuracy = r_acc\n",
    "        wall_clock_times = r_times\n",
    "\n",
    "    else:\n",
    "        losses = np.vstack((losses, r_loss))\n",
    "        accuracy = np.vstack((accuracy, r_acc))\n",
    "        wall_clock_times = np.vstack((wall_clock_times, r_times))\n",
    "\n",
    "arr = np.array([losses, accuracy, wall_clock_times])\n",
    "mean_arr = jnp.mean(arr, axis=1)\n",
    "std_arr = jnp.std(arr, axis=1)\n",
    "df_arr = jnp.vstack((mean_arr, std_arr))\n",
    "df = pd.DataFrame(\n",
    "    df_arr.T,\n",
    "    columns=[\n",
    "        \"Mean ELBO loss\",\n",
    "        \"Mean accuracy\",\n",
    "        \"Mean epoch wall clock times\",\n",
    "        \"Std ELBO loss\",\n",
    "        \"Std accuracy\",\n",
    "        \"Std epoch wall clock times\",\n",
    "    ],\n",
    ")\n",
    "df.to_csv(\"./training_runs/grasp_air_enum_epochs_41_mccoy_prior.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
