{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"Overview","text":"<p>GenJAX: a probabilistic programming library designed to scale probabilistic modeling and inference into high performance settings. (1)</p> <ol> <li> <p>Here, high performance means massively parallel, either cores or devices.</p> <p>For those whom this overview page may be irrelevant: the value proposition is about putting expressive models and customizable Bayesian inference on GPUs, TPUs, etc - without sacrificing abstraction or modularity.</p> </li> </ol> <p>Gen is a multi-paradigm (generative, differentiable, incremental) system for probabilistic programming. GenJAX is an implementation of Gen on top of JAX (2) - exposing the ability to programmatically construct and manipulate generative functions (1) (computational objects which represent probability measures over structured sample spaces), with compilation to native devices, accelerators, and other parallel fabrics. </p> <ol> <li> <p>By design, generative functions expose a concise interface for expressing approximate and differentiable inference algorithms. </p> <p>The set of generative functions is extensible! You can implement your own - allowing advanced users to performance optimize their critical modeling/inference code paths.</p> <p>You can (and we, at the MIT Probabilistic Computing Project, do!) use these objects for machine learning - including robotics, natural language processing, reasoning about agents, and modelling / creating systems which exhibit human-like reasoning.</p> <p>A precise mathematical formulation of generative functions is given in Marco Cusumano-Towner's PhD thesis.</p> </li> <li> <p>If the usage of JAX is not a dead giveaway, GenJAX is written in Python.</p> </li> </ol> Model codeInference code <p><p> Defining a beta-bernoulli process model as a generative function in GenJAX. </p></p> <pre><code>@genjax.gen\ndef model():\np = beta(0, 1) @ \"p\"\nv = bernoulli(p) @ \"v\"\nreturn v\n</code></pre> <p><p> This works for any generative function, not just the beta-bernoulli model. </p></p> <pre><code># Sampling importance resampling.\ndef sir(key: PRNGKey, gen_fn: GenerativeFunction, model_args: Tuple,\nobs: ChoiceMap, n_samples: Int):\nkey, sub_keys = genjax.slash(key, n_samples) # split keys\n_, (lws, trs) = jax.vmap(gen_fn.importance, in_axes=(0, None, None))(\nsub_keys,\nobs,\nargs,\n)\nlog_total_weight = jax.scipy.special.logsumexp(lws)\nlog_normalized_weights = lws - log_total_weight\nlog_ml_estimate = log_total_weight - jnp.log(self.num_particles)\nreturn key, (trs, log_normalized_weights, log_ml_estimate)\n</code></pre>"},{"location":"index.html#what-sort-of-things-do-you-use-genjax-for","title":"What sort of things do you use GenJAX for?","text":"Real time object tracking <p>Real time tracking of objects in 3D using probabilistic rendering. (Left) Ground truth, (center) depth mask, (right) inference overlaid on ground truth.</p> <p><p> </p></p>"},{"location":"index.html#why-gen","title":"Why Gen?","text":"<p>GenJAX is a Gen implementation. If you're considering using GenJAX - it's worth starting by understanding what problems Gen purports to solve.</p>"},{"location":"index.html#the-evolution-of-probabilistic-programming-languages","title":"The evolution of probabilistic programming languages","text":"<p>Probabilistic modeling and inference is hard: understanding a domain well enough to construct a probabilistic model in the Bayesian paradigm is challenging, and that's half the battle - the other half is designing effective inference algorithms to probe the implications of the model (1).</p> <ol> <li> <p>Some probabilistic programming languages restrict the set of allowable models, providing (in return) efficient (often, exact) inference. </p> <p>Gen considers a wide class of models - include Bayesian nonparametrics, open-universe models, and models over rich structures (like programs!) - which don't natively support efficient exact inference.</p> </li> </ol> <p>Model writers have historically considered the following design loop.</p> <pre><code>graph LR\n  A[Design model.] --&gt; B[Implement inference by hand.];\n  B --&gt; C[Model + inference okay?];\n  C --&gt; D[Happy.];\n  C --&gt; A;</code></pre> <p>The first generation (1) of probabilistic programming systems introduced inference engines which could operate abstractly over many different models, without requiring the programmer to return and tweak their inference code. The utopia envisioned by these systems is shown below.</p> <ol> <li> <p>Here, the definition of \"first generation\" includes systems like JAGS, BUGS, BLOG, IBAL, Church, Infer.NET, Figaro, Stan, amongst others.</p> <p>But more precisely, many systems preceded the DARPA PPAML project - which gave rise to several novel systems, including the predecessors of Gen.</p> </li> </ol> <pre><code>graph LR\n  A[Design model.] --&gt; D[Model + inference okay?];\n  B[Inference engine.] ---&gt; D;\n  D --&gt; E[Happy.];\n  D ---&gt; A;</code></pre> <p>The problem with this utopia is that we often need to customize our inference algorithms (1) to achieve maximum performance, with respect to accuracy as well as runtime (2). First generation systems were not designed with this in mind.</p> <ol> <li>Here, programmable inference denotes using a custom proposal distribution in importance sampling, or a custom variational family for variational inference, or even a custom kernel in Markov chain Monte Carlo.</li> <li>Composition of inference programs can also be highly desirable when performing inference in complex models, or designing a probabilistic application from several modeling and inference components. The first examples of universal inference engines ignored this design problem.</li> </ol>"},{"location":"index.html#programmable-inference","title":"Programmable inference","text":"<p>A worthy design goal is to allow users to customize when required, while retaining the rapid model/inference iteration properties explored by first generation systems.</p> <p>Gen addresses this goal by introducing a separation between modeling and inference code: the generative function interface.</p> <p> </p> <p>The interface provides an abstraction layer that inference algorithms can call to compute the necessary (and hard to get right!) math (1). Probabilistic application developers can also extend the interface to new modeling languages - and immediately gain access to advanced inference procedures.</p> <ol> <li> <p>Examples of hard-to-get-right math: importance weights, accept reject ratios, and gradient estimators. </p> <p>For simple models and inference, one might painlessly derive these quantities. As soon as the model/inference gets complicated, however, you might find yourself thanking the interface.</p> </li> </ol>"},{"location":"index.html#whose-using-gen","title":"Whose using Gen?","text":"<p>Gen supports a growing list of users, with collaboration across academic research labs and industry affiliates.</p> <p> </p> <p>We're looking to expand our user base! If you're interested, please contact us to get involved.</p>"},{"location":"genjax/diff_jl.html","title":"Diffing against Gen.jl","text":"<p><code>GenJAX</code> is inherits concepts from Gen and algorithm reference implementations from <code>Gen.jl</code> - there are a few necessary design deviations between <code>GenJAX</code> and <code>Gen.jl</code> that stem from JAX's underlying array programming model. In this section, we describe several of these differences and try to highlight workarounds or discuss the reason for the discrepancy.</p>"},{"location":"genjax/diff_jl.html#turing-universality","title":"Turing universality","text":"<p><code>Gen.jl</code> is Turing universal - it can encode any computable distribution, including those expressed by forms of unbounded recursion.</p> <p>It is a bit ambiguous whether or not <code>GenJAX</code> falls in this category: JAX does not feature mechanisms for dynamic shape allocations, but it does feature mechanisms for unbounded recursion.</p> <p>The former provides a technical barrier to implementing Gen's trace machinery. While JAX allows for unbounded recursion, to support Gen's interfaces we also need the ability to dynamically allocate choice data. This requirement is currently at tension with XLA's requirements of knowing the static shape of everything.</p> <p>However, <code>GenJAX</code> supports generative function combinators with bounded recursion / unfold chain length. Ahead of time, these combinators can be directed to pre-allocate arrays with enough size to handle recursion/looping within the bounds that the programmer sets. If these bounds are exceeded, a Python runtime error will be thrown (both on and off JAX device).</p> <p>In practice, this means that some performance engineering (space vs. expressivity) is required of the programmer. It's certainly feasible to express bounded recursive computations which terminate with probability 1 - but you'll need to ahead of time allocate space for it.</p>"},{"location":"genjax/diff_jl.html#mutation","title":"Mutation","text":"<p>Just like JAX, GenJAX disallows mutation - expressing a mutation to an array must be done through special interfaces, and those interfaces return full copies. There are special circumstances where these interfaces will be performed in place.</p>"},{"location":"genjax/diff_jl.html#to-jit-or-not-to-jit","title":"To JIT or not to JIT","text":"<p><code>Gen.jl</code> is written in Julia, which automatically JITs everything. <code>GenJAX</code>, by virtue of being constructed on top of JAX, allows us to JIT JAX compatible code - but the JIT process is user directed. Thus, the idioms that are used to express and optimize inference code are necessarily different compared to <code>Gen.jl</code>. In the inference standard library, you'll typically find algorithms implemented as dataclasses which inherit (and implement) the <code>jax.Pytree</code> interfaces. Implementing these interfaces allow usage of inference dataclasses and methods in jittable code - and, as a bonus, allow us to be specific about trace vs. runtime known values.</p> <p>In general, it's productive to enclose as much of a computation as possible in a <code>jax.jit</code> block. This can sometimes lead to long trace times. If trace times are ballooning, a common source is explicit for-loops (with known bounds, else JAX will complain). In these cases, you might look at Advice on speeding up compilation time. We've taken care to optimize (by e.g. using XLA primitives) the code which we expose from GenJAX - but if you find something out of the ordinary, file an issue!</p>"},{"location":"genjax/language_aperitifs.html","title":"Language ap\u00e9ritifs","text":"<p>The implementation of GenJAX adhers to commonly accepted JAX idioms (1) and modern functional programming patterns (2).</p> <ol> <li>One example: everything is a Pytree. Implies another: everything is JAX traceable by default.</li> <li>Modern here meaning patterns concerning the composition of effectful computations via effect handling abstractions.</li> </ol> <p>GenJAX consists of a set of languages based around transforming pure functions to apply semantic transformations. In this page, we'll provide a taste of some of these languages.</p>"},{"location":"genjax/language_aperitifs.html#the-builtin-language","title":"The builtin language","text":"<p>GenJAX provides a builtin language which supports a <code>trace</code> primitive and the ability to invoke other generative functions as callees:</p> <pre><code>@genjax.gen\ndef submodel():\nx = trace(\"x\", normal)(0.0, 1.0) # explicit\nreturn x\n@genjax.gen\ndef model():\nx = submodel() @ \"sub\" # sugared\nreturn x\n</code></pre> <p>The <code>trace</code> call is a JAX primitive which is given semantics by transformations which implement the semantics of inference interfaces described in Generative functions.</p> <p>Addresses (here, <code>\"x\"</code> and <code>\"sub\"</code>) are important - addressed random choices within <code>trace</code> allow us to structure the address hierarchy for the measure over choice maps which generative functions in this language define.</p> <p>Because convenient idioms for working with addresses is so important in Gen, the generative functions from the builtin language also support a form of \"splatting\" addresses into a caller.</p> <pre><code>@genjax.gen\ndef model():\nx = submodel.inline()\nreturn x\n</code></pre> <p>Invoking the <code>submodel</code> via the <code>inline</code> interface here means that the addresses in <code>submodel</code> are flattened into the address level for the <code>model</code>. If there's overlap, that's a problem! But GenJAX will yell at you for that.</p>"},{"location":"genjax/language_aperitifs.html#structured-control-flow-with-combinators","title":"Structured control flow with combinators","text":"<p>The base modeling language is the <code>BuiltinGenerativeFunction</code> language shown above. The builtin language is based on pure functions, with the interface semantics implemented using program transformations. But we'd also like to take advantage of structured control flow in our generative computations. </p> <p>Users gain access to structured control flow via combinators, other generative function mini-languages which implement the interfaces in control flow compatible ways.</p> <pre><code>@functools.partial(genjax.Map, in_axes=(0, 0))\n@genjax.gen\ndef kernel(x, y):\nz = normal(x + y, 1.0) @ \"z\"\nreturn z\n</code></pre> <p>This defines a <code>MapCombinator</code> generative function - a generative function whose interfaces take care of applying <code>vmap</code> in the appropriate ways (1).</p> <ol> <li>Read: compatible with JIT, gradients, and incremental computation.</li> </ol> <p><code>MapCombinator</code> has a vectorial friend named <code>UnfoldCombinator</code> which implements a <code>scan</code>-like pattern of generative computation.</p> <pre><code>@functools.partial(genjax.Unfold, max_length = 10)\n@genjax.gen\ndef scanner(prev, static_args):\nsigma, = static_args\nnew = normal(prev, sigma) @ \"z\"\nreturn new\n</code></pre> <p><code>UnfoldCombinator</code> allows the expression of general state space models - modeled as a generative function which supports a dependent-for (1) control flow pattern.</p> <ol> <li>Dependent-for means that each iteration may depend on the output from the previous iteration. Think of <code>jax.lax.scan</code> here.</li> </ol> <p><code>UnfoldCombinator</code> allows uncertainty over the length of the chain:</p> <pre><code>@genjax.gen\ndef top_model(p):\nlength = truncated_geometric(10, p) @ \"l\"\ninitial_state = normal(0.0, 1.0) @ \"init\"\nsigma = normal(0.0, 1.0) @ \"sigma\"\n(v, xs) = scanner(length, initial_state, sigma)\nreturn v\n</code></pre> <p>Here, <code>length</code> is drawn from a truncated geometric distribution, and determines the index range of the chain which participates in the generative computation.</p> <p>Of course, combinators are composable.</p> <pre><code>@functools.partial(genjax.Map, in_axes = (0, ))\n@genjax.gen\ndef top_model(p):\nlength = truncated_geometric(10, p) @ \"l\"\ninitial_state = normal(0.0, 1.0) @ \"init\"\nsigma = normal(0.0, 1.0) @ \"sigma\"\n(v, xs) = scanner(length, initial_state, sigma)\nreturn v\n</code></pre> <p>Now we're describing a broadcastable generative function whose internal choices include a chain-like generative structure with dynamic truncation using padding. And we could go on!</p>"},{"location":"genjax/notebooks.html","title":"Modeling &amp; inference notebooks","text":"<p>Link to the notebook repository</p> <p>This section contains a link to a (statically hosted) series of tutorial notebooks designed to guide usage of GenJAX. These notebooks are executed and rendered with quarto, and are kept up to date with the repository along with the documentation.</p> <p>The notebook repository can be found here.</p>"},{"location":"genjax/concepts/generative_functions.html","title":"Generative functions","text":"<p>Gen is all about generative functions: computational objects which support an interface that helps automate the tricky math involved in programming Bayesian inference algorithms. In this section, we'll unpack the generative function interface and explain the mathematics behind generative functions (1).</p> <ol> <li>For a deeper dive, enjoy Marco Cusumano-Towner's PhD thesis.</li> </ol>"},{"location":"genjax/library/index.html","title":"Library reference","text":"<p>This is the API documentation for modules which are exposed publicly from <code>genjax</code>. The <code>genjax</code> package consists of several modules, many of which rely on functionality from the <code>genjax.core</code> module, and build upon datatypes and generative datatypes which are documented there.</p> <ul> <li>Core</li> <li>Generative function languages</li> <li>Inference</li> <li>Differentiable programming</li> </ul>"},{"location":"genjax/library/core/index.html","title":"Core","text":"<p>This module provides the core functionality and JAX compatibility layer which <code>GenJAX</code> generative function and inference modules are built on top of. It contains (truncated, and in no particular order):</p> <ul> <li> <p>Core Gen associated data types for generative functions.</p> </li> <li> <p>Utility functionality for automatically registering class definitions as valid <code>Pytree</code> method implementors (guaranteeing <code>flatten</code>/<code>unflatten</code> compatibility across JAX transform boundaries). For more information, see Pytrees.</p> </li> <li> <p>Staging functionality that allows lifting of pure, numerical Python programs to <code>ClosedJaxpr</code> instances.</p> </li> <li> <p>Transformation interpreters: interpreter-based transformations on which operate on <code>ClosedJaxpr</code> instances. Interpreters are all written in initial style - they operate on <code>ClosedJaxpr</code> instances, and don't implement their own custom <code>jax.Tracer</code> types - but they are JAX compatible, implying that they can be staged out for zero runtime cost.</p> </li> <li> <p>Masking functionality which allows active/inactive flagging of data - useful when branching patterns of computation require uncertainty in whether or not data is active with respect to a generative computation.</p> </li> </ul>"},{"location":"genjax/library/core/datatypes.html","title":"Core datatypes","text":"<p>GenJAX features a set of core abstract datatypes which build on JAX's <code>Pytree</code> interface. These datatypes are used as an abstract base mixin (especially <code>Pytree</code>) for basically all of the dataclasses in GenJAX.</p>"},{"location":"genjax/library/core/datatypes.html#genjax.core.Pytree","title":"<code>genjax.core.Pytree</code>","text":"<p>A utility abstract base class which registers a class with JAX's <code>Pytree</code> system.</p> <p>Users who mixin this ABC are required to implement <code>flatten</code> below, but also gain access to a large set of utility functions for working with <code>Pytree</code> data.</p> Source code in <code>src/genjax/_src/core/pytree.py</code> <pre><code>class Pytree(metaclass=abc.ABCMeta):\n\"\"\"\n    A utility abstract base class which registers a class with JAX's `Pytree` system.\n    Users who mixin this ABC are required to implement `flatten` below, but also gain access to a large set of utility functions for working with `Pytree` data.\n    \"\"\"\ndef __init_subclass__(cls, **kwargs):\nsuper().__init_subclass__(**kwargs)\njtu.register_pytree_node(\ncls,\ncls.flatten,\ncls.unflatten,\n)\n@abc.abstractmethod\ndef flatten(self):\n\"\"\"\n        `flatten` must be implemented when a user extends `Pytree` to a new class or dataclass.\n        `flatten` requires the following specification:\n            * must return a 2-tuple of tuples.\n            * the first tuple is \"dynamic\" data - things that JAX tracers are allowed to represent.\n            * the second tuple is \"static\" data - things which are known at JAX tracing time. Static data is also used by JAX for `Pytree` equality comparison.\n        ## Example\n        Let's assume that you are implementing a new dataclass:\n        ```python\n        @dataclass\n        class MyFoo(Pytree):\n            static_field: Any\n            dynamic_field: Any\n            # Implementing `flatten`\n            def flatten(self):\n                return (self.dynamic_field, ), (self.static_field, )\n        ```\n        **Note that the ordering in the dataclass declaration _does matter_ - you should put static fields first. The automatically defined `unflatten` method (c.f. below) assumes this ordering.**\n        \"\"\"\n@classmethod\ndef unflatten(cls, data, xs):\nreturn cls(*data, *xs)\n@classmethod\ndef new(cls, *args, **kwargs):\nreturn cls(*args, **kwargs)\n# This exposes slicing the struct-of-array representation,\n# taking leaves and indexing/randing into them on the first index,\n# returning a value with the same `Pytree` structure.\ndef slice(self, index_or_range):\n\"\"\"\n        Any class which mixes / extends from a `Pytree` base supports indexing/slicing on indices when leaves are arrays with non-null 1st dimension.\n        `obj.slice(index)` will take an instance whose class extends `Pytree`, and return an instance of the same class type, but with leaves indexed into at `index`.\n        \"\"\"\nreturn jtu.tree_map(lambda v: v[index_or_range], self)\ndef stack(self, *trees):\nreturn tree_stack([self, *trees])\ndef unstack(self):\nreturn tree_unstack(self)\n# Lift multiple trees into a sum type.\ndef sum(self, *trees):\nreturn Sumtree.new(self, trees)\n# Defines default pretty printing.\ndef __rich_console__(self, console, options):\ntree = gpp.tree_pformat(self)\nyield tree\ndef __rich_repr__(self):\nyield self\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#genjax._src.core.pytree.Pytree.flatten","title":"<code>flatten()</code>  <code>abstractmethod</code>","text":"<p><code>flatten</code> must be implemented when a user extends <code>Pytree</code> to a new class or dataclass.</p> <p><code>flatten</code> requires the following specification:     * must return a 2-tuple of tuples.     * the first tuple is \"dynamic\" data - things that JAX tracers are allowed to represent.     * the second tuple is \"static\" data - things which are known at JAX tracing time. Static data is also used by JAX for <code>Pytree</code> equality comparison.</p>"},{"location":"genjax/library/core/datatypes.html#genjax._src.core.pytree.Pytree.flatten--example","title":"Example","text":"<p>Let's assume that you are implementing a new dataclass:</p> <pre><code>@dataclass\nclass MyFoo(Pytree):\nstatic_field: Any\ndynamic_field: Any\n# Implementing `flatten`\ndef flatten(self):\nreturn (self.dynamic_field, ), (self.static_field, )\n</code></pre> <p>Note that the ordering in the dataclass declaration does matter - you should put static fields first. The automatically defined <code>unflatten</code> method (c.f. below) assumes this ordering.</p> Source code in <code>src/genjax/_src/core/pytree.py</code> <pre><code>@abc.abstractmethod\ndef flatten(self):\n\"\"\"\n    `flatten` must be implemented when a user extends `Pytree` to a new class or dataclass.\n    `flatten` requires the following specification:\n        * must return a 2-tuple of tuples.\n        * the first tuple is \"dynamic\" data - things that JAX tracers are allowed to represent.\n        * the second tuple is \"static\" data - things which are known at JAX tracing time. Static data is also used by JAX for `Pytree` equality comparison.\n    ## Example\n    Let's assume that you are implementing a new dataclass:\n    ```python\n    @dataclass\n    class MyFoo(Pytree):\n        static_field: Any\n        dynamic_field: Any\n        # Implementing `flatten`\n        def flatten(self):\n            return (self.dynamic_field, ), (self.static_field, )\n    ```\n    **Note that the ordering in the dataclass declaration _does matter_ - you should put static fields first. The automatically defined `unflatten` method (c.f. below) assumes this ordering.**\n    \"\"\"\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#genjax._src.core.pytree.Pytree.unflatten","title":"<code>unflatten(data, xs)</code>  <code>classmethod</code>","text":"Source code in <code>src/genjax/_src/core/pytree.py</code> <pre><code>@classmethod\ndef unflatten(cls, data, xs):\nreturn cls(*data, *xs)\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#genjax._src.core.pytree.Pytree.slice","title":"<code>slice(index_or_range)</code>","text":"<p>Any class which mixes / extends from a <code>Pytree</code> base supports indexing/slicing on indices when leaves are arrays with non-null 1st dimension.</p> <p><code>obj.slice(index)</code> will take an instance whose class extends <code>Pytree</code>, and return an instance of the same class type, but with leaves indexed into at <code>index</code>.</p> Source code in <code>src/genjax/_src/core/pytree.py</code> <pre><code>def slice(self, index_or_range):\n\"\"\"\n    Any class which mixes / extends from a `Pytree` base supports indexing/slicing on indices when leaves are arrays with non-null 1st dimension.\n    `obj.slice(index)` will take an instance whose class extends `Pytree`, and return an instance of the same class type, but with leaves indexed into at `index`.\n    \"\"\"\nreturn jtu.tree_map(lambda v: v[index_or_range], self)\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#genjax._src.core.pytree.Pytree.stack","title":"<code>stack(*trees)</code>","text":"Source code in <code>src/genjax/_src/core/pytree.py</code> <pre><code>def stack(self, *trees):\nreturn tree_stack([self, *trees])\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#genjax._src.core.pytree.Pytree.unstack","title":"<code>unstack()</code>","text":"Source code in <code>src/genjax/_src/core/pytree.py</code> <pre><code>def unstack(self):\nreturn tree_unstack(self)\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#trees","title":"Trees","text":"<p>The <code>Pytree</code> class is used to define abstract classes for tree-shaped datatypes. These classes are used to implement trace, choice map, and selection types.</p>"},{"location":"genjax/library/core/datatypes.html#genjax.core.Tree","title":"<code>genjax.core.Tree</code>  <code>dataclass</code>","text":"<p>         Bases: <code>Pytree</code></p> Source code in <code>src/genjax/_src/core/datatypes/tree.py</code> <pre><code>@dataclass\nclass Tree(Pytree):\n@abc.abstractmethod\ndef has_subtree(self, addr) -&gt; bool:\npass\n@abc.abstractmethod\ndef get_subtree(self, addr):\npass\n@abc.abstractmethod\ndef get_subtrees_shallow(self):\npass\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#genjax._src.core.datatypes.tree.Tree.has_subtree","title":"<code>has_subtree(addr)</code>  <code>abstractmethod</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/tree.py</code> <pre><code>@abc.abstractmethod\ndef has_subtree(self, addr) -&gt; bool:\npass\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#genjax._src.core.datatypes.tree.Tree.get_subtree","title":"<code>get_subtree(addr)</code>  <code>abstractmethod</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/tree.py</code> <pre><code>@abc.abstractmethod\ndef get_subtree(self, addr):\npass\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#genjax._src.core.datatypes.tree.Tree.get_subtrees_shallow","title":"<code>get_subtrees_shallow()</code>  <code>abstractmethod</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/tree.py</code> <pre><code>@abc.abstractmethod\ndef get_subtrees_shallow(self):\npass\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#leaf","title":"Leaf","text":"<p>A <code>Leaf</code> is a <code>Tree</code> without any internal subtrees.</p>"},{"location":"genjax/library/core/datatypes.html#genjax.core.Leaf","title":"<code>genjax.core.Leaf</code>  <code>dataclass</code>","text":"<p>         Bases: <code>Tree</code></p> Source code in <code>src/genjax/_src/core/datatypes/tree.py</code> <pre><code>@dataclass\nclass Leaf(Tree):\n@abc.abstractmethod\ndef get_leaf_value(self):\npass\n@abc.abstractmethod\ndef set_leaf_value(self, v):\npass\ndef has_subtree(self, addr):\nreturn False\ndef get_subtree(self, addr):\nraise Exception(\nf\"{type(self)} is a Leaf: it does not address any internal choices.\"\n)\ndef get_subtrees_shallow(self):\nraise Exception(f\"{type(self)} is a Leaf: it does not have any subtrees.\")\ndef merge(self, other):\nraise Exception(f\"{type(self)} is a Leaf: can't merge.\")\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#genjax._src.core.datatypes.tree.Leaf.has_subtree","title":"<code>has_subtree(addr)</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/tree.py</code> <pre><code>def has_subtree(self, addr):\nreturn False\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#genjax._src.core.datatypes.tree.Leaf.get_subtree","title":"<code>get_subtree(addr)</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/tree.py</code> <pre><code>def get_subtree(self, addr):\nraise Exception(\nf\"{type(self)} is a Leaf: it does not address any internal choices.\"\n)\n</code></pre>"},{"location":"genjax/library/core/datatypes.html#genjax._src.core.datatypes.tree.Leaf.get_subtrees_shallow","title":"<code>get_subtrees_shallow()</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/tree.py</code> <pre><code>def get_subtrees_shallow(self):\nraise Exception(f\"{type(self)} is a Leaf: it does not have any subtrees.\")\n</code></pre>"},{"location":"genjax/library/core/generative.html","title":"Generative datatypes","text":"<p>Key generative datatypes in Gen</p> <p>This documentation page contains the type and interface documentation for the primary generative datatypes used in Gen. The documentation on this page deals with the abstract base classes for these datatypes. </p> <p>Any concrete implementor of these abstract classes should be documented with the language which implements it.</p>"},{"location":"genjax/library/core/generative.html#generative-functions","title":"Generative functions","text":"<p>The main computational objects in Gen are generative functions. These objects support an abstract interface of methods and associated types which allow inference layers to abstract over the implementation of the interface.</p> <p>Below, we document the base abstract class. Concrete generative function languages are described in their own documentation module.</p>"},{"location":"genjax/library/core/generative.html#genjax.core.GenerativeFunction","title":"<code>genjax.core.GenerativeFunction</code>  <code>dataclass</code>","text":"<p>         Bases: <code>Pytree</code></p> <p>Abstract base class for generative functions.</p> <p>Any concrete implementation will interact with the JAX tracing machinery so there are specific API requirements above the requirements enforced in other languages (unlike Gen in Julia, for example).</p> <p>The user must match the interface signatures of the native JAX implementation. This is not statically checked - but failure to do so will lead to unintended behavior or errors.</p> <p>To support argument and choice gradients via JAX, the user must provide a differentiable <code>importance</code> implementation.</p> Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@dataclasses.dataclass\nclass GenerativeFunction(Pytree):\n\"\"\"\n    Abstract base class for generative functions.\n    Any concrete implementation will interact with the JAX tracing machinery\n    so there are specific API requirements above the requirements\n    enforced in other languages (unlike Gen in Julia, for example).\n    The user *must* match the interface signatures of the native JAX\n    implementation. This is not statically checked - but failure to do so\n    will lead to unintended behavior or errors.\n    To support argument and choice gradients via JAX, the user must\n    provide a differentiable `importance` implementation.\n    \"\"\"\n# This is used to support tracing -- the user is not required to provide\n# a PRNGKey, because the value of the key is not important, only\n# the fact that the value has type PRNGKey.\ndef __abstract_call__(self, *args) -&gt; Tuple[PRNGKey, Any]:\nkey = jax.random.PRNGKey(0)\n_, tr = self.simulate(key, args)\nretval = tr.get_retval()\nreturn retval\ndef get_trace_type(self, *args, **kwargs) -&gt; TraceType:\nshape = kwargs.get(\"shape\", ())\nreturn Bottom(shape)\n@abc.abstractmethod\ndef simulate(\nself,\nkey: PRNGKey,\nargs: Tuple,\n) -&gt; Tuple[PRNGKey, Trace]:\npass\n@abc.abstractmethod\ndef importance(\nself,\nkey: PRNGKey,\nchm: ChoiceMap,\nargs: Tuple,\n) -&gt; Tuple[PRNGKey, Tuple[FloatArray, Trace]]:\npass\n@abc.abstractmethod\ndef update(\nself,\nkey: PRNGKey,\noriginal: Trace,\nnew: ChoiceMap,\ndiffs: Tuple,\n) -&gt; Tuple[PRNGKey, Tuple[Any, FloatArray, Trace, ChoiceMap]]:\npass\n@abc.abstractmethod\ndef assess(\nself,\nkey: PRNGKey,\nevaluation_point: ChoiceMap,\nargs: Tuple,\n) -&gt; Tuple[PRNGKey, Tuple[Any, FloatArray]]:\npass\ndef unzip(\nself,\nkey: PRNGKey,\nfixed: ChoiceMap,\n) -&gt; Tuple[\nPRNGKey,\nCallable[[ChoiceMap, Tuple], FloatArray],\nCallable[[ChoiceMap, Tuple], Any],\n]:\nkey, sub_key = jax.random.split(key)\ndef score(differentiable: Tuple, nondifferentiable: Tuple) -&gt; FloatArray:\nprovided, args = tree_zipper(differentiable, nondifferentiable)\nmerged = fixed.merge(provided)\n_, (_, score) = self.assess(sub_key, merged, args)\nreturn score\ndef retval(differentiable: Tuple, nondifferentiable: Tuple) -&gt; Any:\nprovided, args = tree_zipper(differentiable, nondifferentiable)\nmerged = fixed.merge(provided)\n_, (retval, _) = self.assess(sub_key, merged, args)\nreturn retval\nreturn key, score, retval\n# A higher-level gradient API - it relies upon `unzip`,\n# but provides convenient access to first-order gradients.\ndef choice_grad(self, key, trace, selection):\nfixed = selection.complement().filter(trace.strip())\nevaluation_point = selection.filter(trace.strip())\nkey, scorer, _ = self.unzip(key, fixed)\ngrad, nograd = tree_grad_split(\n(evaluation_point, trace.get_args()),\n)\nchoice_gradient_tree, _ = jax.grad(scorer)(grad, nograd)\nreturn key, choice_gradient_tree\n###################\n# ADEV and fusion #\n###################\ndef adev_simulate(self, key: PRNGKey, args: Tuple) -&gt; Tuple[PRNGKey, Any]:\n\"\"\"An opt-in method which expresses forward sampling from the\n        generative function in terms of primitives which are compatible with\n        ADEV's language.\"\"\"\nraise NotImplementedError\ndef prepare_fuse(self, key: PRNGKey, args: Tuple):\n\"\"\"Convert a generative function to a canonical form with ADEV\n        primitives for proposal fusion.\"\"\"\nraise NotImplementedError\ndef fuse(self, _: \"GenerativeFunction\"):\n\"\"\"Fuse a generative function and a proposal to produce a probabilistic\n        computation that returns an ELBO estimate.\"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"genjax/library/core/generative.html#genjax._src.core.datatypes.generative.GenerativeFunction.simulate","title":"<code>simulate(key, args)</code>  <code>abstractmethod</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@abc.abstractmethod\ndef simulate(\nself,\nkey: PRNGKey,\nargs: Tuple,\n) -&gt; Tuple[PRNGKey, Trace]:\npass\n</code></pre>"},{"location":"genjax/library/core/generative.html#genjax._src.core.datatypes.generative.GenerativeFunction.importance","title":"<code>importance(key, chm, args)</code>  <code>abstractmethod</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@abc.abstractmethod\ndef importance(\nself,\nkey: PRNGKey,\nchm: ChoiceMap,\nargs: Tuple,\n) -&gt; Tuple[PRNGKey, Tuple[FloatArray, Trace]]:\npass\n</code></pre>"},{"location":"genjax/library/core/generative.html#genjax._src.core.datatypes.generative.GenerativeFunction.update","title":"<code>update(key, original, new, diffs)</code>  <code>abstractmethod</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@abc.abstractmethod\ndef update(\nself,\nkey: PRNGKey,\noriginal: Trace,\nnew: ChoiceMap,\ndiffs: Tuple,\n) -&gt; Tuple[PRNGKey, Tuple[Any, FloatArray, Trace, ChoiceMap]]:\npass\n</code></pre>"},{"location":"genjax/library/core/generative.html#genjax._src.core.datatypes.generative.GenerativeFunction.assess","title":"<code>assess(key, evaluation_point, args)</code>  <code>abstractmethod</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@abc.abstractmethod\ndef assess(\nself,\nkey: PRNGKey,\nevaluation_point: ChoiceMap,\nargs: Tuple,\n) -&gt; Tuple[PRNGKey, Tuple[Any, FloatArray]]:\npass\n</code></pre>"},{"location":"genjax/library/core/generative.html#traces","title":"Traces","text":""},{"location":"genjax/library/core/generative.html#genjax.core.Trace","title":"<code>genjax.core.Trace</code>  <code>dataclass</code>","text":"<p>         Bases: <code>ChoiceMap</code>, <code>Tree</code></p> <p>Abstract base class for traces of generative functions.</p> <p>A <code>Trace</code> is a data structure used to represent sampled executions of a generative function. It tracks metadata associated with log probability values, as well as values associated with the invocation of a generative function, including the arguments it was invoked with, its return value, and the identity of the generative function itself.</p> Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@dataclasses.dataclass\nclass Trace(ChoiceMap, Tree):\n\"\"\"\n    Abstract base class for traces of generative functions.\n    A `Trace` is a data structure used to represent sampled executions of a generative function. It tracks metadata associated with log probability values, as well as values associated with the invocation of a generative function, including the arguments it was invoked with, its return value, and the identity of the generative function itself.\n    \"\"\"\n@abc.abstractmethod\ndef get_retval(self) -&gt; Any:\npass\n@abc.abstractmethod\ndef get_score(self) -&gt; FloatArray:\npass\n@abc.abstractmethod\ndef get_args(self) -&gt; Tuple:\npass\n@abc.abstractmethod\ndef get_choices(self) -&gt; ChoiceMap:\npass\n@abc.abstractmethod\ndef get_gen_fn(self) -&gt; \"GenerativeFunction\":\npass\n@abc.abstractmethod\ndef project(self, selection: \"Selection\") -&gt; FloatArray:\npass\ndef update(self, key, choices, argdiffs):\ngen_fn = self.get_gen_fn()\nreturn gen_fn.update(key, self, choices, argdiffs)\ndef has_subtree(self, addr) -&gt; BoolArray:\nchoices = self.get_choices()\nreturn choices.has_subtree(addr)\ndef get_subtree(self, addr) -&gt; ChoiceMap:\nchoices = self.get_choices()\nreturn choices.get_subtree(addr)\ndef get_subtrees_shallow(self):\nchoices = self.get_choices()\nreturn choices.get_subtrees_shallow()\ndef merge(self, other) -&gt; ChoiceMap:\nreturn self.get_choices().merge(other.get_choices())\ndef get_selection(self):\nreturn self.get_choices().get_selection()\ndef strip(self):\n\"\"\"\n        Remove all `Trace` metadata, and return a choice map.\n        \"\"\"\ndef _check(v):\nreturn isinstance(v, Trace)\ndef _inner(v):\nif isinstance(v, Trace):\nreturn v.strip()\nelse:\nreturn v\nreturn jtu.tree_map(_inner, self.get_choices(), is_leaf=_check)\ndef __getitem__(self, addr):\nchoices = self.get_choices()\nchoice = choices.get_subtree(addr)\nif isinstance(choice, BooleanMask):\nif is_concrete(choice.mask):\nif choice.mask:\nreturn choice.unmask()\nelse:\nreturn EmptyChoiceMap()\nelse:\nreturn choice\nelif isinstance(choice, Leaf):\nreturn choice.get_leaf_value()\nelse:\nreturn choice\n</code></pre>"},{"location":"genjax/library/core/generative.html#genjax._src.core.datatypes.generative.Trace.get_gen_fn","title":"<code>get_gen_fn()</code>  <code>abstractmethod</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@abc.abstractmethod\ndef get_gen_fn(self) -&gt; \"GenerativeFunction\":\npass\n</code></pre>"},{"location":"genjax/library/core/generative.html#genjax._src.core.datatypes.generative.Trace.get_retval","title":"<code>get_retval()</code>  <code>abstractmethod</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@abc.abstractmethod\ndef get_retval(self) -&gt; Any:\npass\n</code></pre>"},{"location":"genjax/library/core/generative.html#genjax._src.core.datatypes.generative.Trace.get_choices","title":"<code>get_choices()</code>  <code>abstractmethod</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@abc.abstractmethod\ndef get_choices(self) -&gt; ChoiceMap:\npass\n</code></pre>"},{"location":"genjax/library/core/generative.html#genjax._src.core.datatypes.generative.Trace.get_score","title":"<code>get_score()</code>  <code>abstractmethod</code>","text":"Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@abc.abstractmethod\ndef get_score(self) -&gt; FloatArray:\npass\n</code></pre>"},{"location":"genjax/library/core/generative.html#genjax._src.core.datatypes.generative.Trace.strip","title":"<code>strip()</code>","text":"<p>Remove all <code>Trace</code> metadata, and return a choice map.</p> Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>def strip(self):\n\"\"\"\n    Remove all `Trace` metadata, and return a choice map.\n    \"\"\"\ndef _check(v):\nreturn isinstance(v, Trace)\ndef _inner(v):\nif isinstance(v, Trace):\nreturn v.strip()\nelse:\nreturn v\nreturn jtu.tree_map(_inner, self.get_choices(), is_leaf=_check)\n</code></pre>"},{"location":"genjax/library/core/generative.html#choice-maps","title":"Choice maps","text":""},{"location":"genjax/library/core/generative.html#genjax.core.ChoiceMap","title":"<code>genjax.core.ChoiceMap</code>  <code>dataclass</code>","text":"<p>         Bases: <code>Tree</code></p> Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@dataclasses.dataclass\nclass ChoiceMap(Tree):\n@abc.abstractmethod\ndef get_selection(self):\n\"\"\"\n        Convert a `ChoiceMap` to a `Selection`.\n        \"\"\"\ndef get_choices(self):\nreturn self\ndef strip(self):\ndef _check(v):\nreturn isinstance(v, Trace)\ndef _inner(v):\nif isinstance(v, Trace):\nreturn v.strip()\nelse:\nreturn v\nreturn jtu.tree_map(_inner, self, is_leaf=_check)\ndef __eq__(self, other):\nreturn self.flatten() == other.flatten()\ndef __getitem__(self, addr):\nchoice = self.get_subtree(addr)\nif isinstance(choice, Leaf):\nv = choice.get_leaf_value()\n# If the choice is a Leaf, it might participate in masking.\n# Here, we check if the value is masked.\n# Then, we either unwrap the mask - or return it,\n# depending on the concreteness of the mask value.\nif isinstance(v, BooleanMask):\nif is_concrete(v.mask):\nif v.mask:\nreturn v.unmask()\nelse:\nreturn EmptyChoiceMap()\nelse:\nreturn v\nelse:\nreturn v\nelse:\nreturn choice\n</code></pre>"},{"location":"genjax/library/core/generative.html#genjax._src.core.datatypes.generative.ChoiceMap.get_selection","title":"<code>get_selection()</code>  <code>abstractmethod</code>","text":"<p>Convert a <code>ChoiceMap</code> to a <code>Selection</code>.</p> Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@abc.abstractmethod\ndef get_selection(self):\n\"\"\"\n    Convert a `ChoiceMap` to a `Selection`.\n    \"\"\"\n</code></pre>"},{"location":"genjax/library/core/generative.html#selections","title":"Selections","text":""},{"location":"genjax/library/core/generative.html#genjax.core.Selection","title":"<code>genjax.core.Selection</code>  <code>dataclass</code>","text":"<p>         Bases: <code>Tree</code></p> Source code in <code>src/genjax/_src/core/datatypes/generative.py</code> <pre><code>@dataclasses.dataclass\nclass Selection(Tree):\n@abc.abstractmethod\ndef filter(self, chm: ChoiceMap) -&gt; ChoiceMap:\npass\n@abc.abstractmethod\ndef complement(self) -&gt; \"Selection\":\npass\ndef get_selection(self):\nreturn self\ndef __getitem__(self, addr):\nsubselection = self.get_subtree(addr)\nreturn subselection\n</code></pre>"},{"location":"genjax/library/core/interpreters.html","title":"Interpreters","text":"<p>JAX supports transformations of pure, numerical Python programs by staging out interpreters which evaluate <code>Jaxpr</code> representations of programs.</p> <p>The <code>Core</code> module features interpreter infrastructure, and common transforms designed to facilitate certain types of transformations.</p>"},{"location":"genjax/library/core/interpreters.html#contextual-interpreter","title":"Contextual interpreter","text":"<p>A common type of interpreter involves overloading desired primitives with context-specific behavior by inheriting from <code>Trace</code> and define the correct methods to process the primitives.</p> <p>In this module, we provide an interpreter which mixes initial style (e.g. the Python program is immediately staged, and then an interpreter walks the <code>Jaxpr</code> representation) with custom <code>Trace</code> and <code>Tracer</code> overloads. </p> <p>This pattern supports a wide range of program transformations, and allows parametrization over the inner interpreter (e.g. forward evaluation, or CPS).</p>"},{"location":"genjax/library/core/interpreters.html#genjax._src.core.interpreters.context","title":"<code>genjax._src.core.interpreters.context</code>","text":"<p>This module contains a transformation infrastructure based on interpreters with stateful contexts and custom primitive handling lookups.</p>"},{"location":"genjax/library/core/interpreters.html#genjax._src.core.interpreters.context.ContextualTracer","title":"<code>ContextualTracer</code>","text":"<p>         Bases: <code>jc.Tracer</code></p> <p>A <code>ContextualTracer</code> encapsulates a single value.</p> Source code in <code>src/genjax/_src/core/interpreters/context.py</code> <pre><code>class ContextualTracer(jc.Tracer):\n\"\"\"A `ContextualTracer` encapsulates a single value.\"\"\"\ndef __init__(self, trace: \"ContextualTrace\", val: Value):\nself._trace = trace\nself.val = val\n@property\ndef aval(self):\nreturn abstract_arrays.raise_to_shaped(jc.get_aval(self.val))\ndef full_lower(self):\nreturn self\n</code></pre>"},{"location":"genjax/library/core/interpreters.html#genjax._src.core.interpreters.context.ContextualTrace","title":"<code>ContextualTrace</code>","text":"<p>         Bases: <code>jc.Trace</code></p> <p>An evaluating trace that dispatches to a dynamic context.</p> Source code in <code>src/genjax/_src/core/interpreters/context.py</code> <pre><code>class ContextualTrace(jc.Trace):\n\"\"\"An evaluating trace that dispatches to a dynamic context.\"\"\"\ndef pure(self, val: Value) -&gt; ContextualTracer:\nreturn ContextualTracer(self, val)\ndef sublift(self, tracer: ContextualTracer) -&gt; ContextualTracer:\nreturn self.pure(tracer.val)\ndef lift(self, val: Value) -&gt; ContextualTracer:\nreturn self.pure(val)\ndef process_primitive(\nself,\nprimitive: jc.Primitive,\ntracers: List[ContextualTracer],\nparams: Dict[str, Any],\n) -&gt; Union[ContextualTracer, List[ContextualTracer]]:\ncontext = staging.get_dynamic_context(self)\ncustom_rule = context.get_custom_rule(primitive)\nif custom_rule:\nreturn custom_rule(self, *tracers, **params)\nreturn self.default_process_primitive(primitive, tracers, params)\ndef default_process_primitive(\nself,\nprimitive: jc.Primitive,\ntracers: List[ContextualTracer],\nparams: Dict[str, Any],\n) -&gt; Union[ContextualTracer, List[ContextualTracer]]:\ncontext = staging.get_dynamic_context(self)\nvals = [v.val for v in tracers]\nif context.can_process(primitive):\noutvals = context.process_primitive(primitive, *vals, **params)\nreturn jax_util.safe_map(self.pure, outvals)\noutvals = primitive.bind(*vals, **params)\nif not primitive.multiple_results:\noutvals = [outvals]\nout_tracers = jax_util.safe_map(self.full_raise, outvals)\nif primitive.multiple_results:\nreturn out_tracers\nreturn out_tracers[0]\ndef process_call(\nself,\ncall_primitive: jc.Primitive,\nf: Any,\ntracers: List[ContextualTracer],\nparams: Dict[str, Any],\n):\ncontext = staging.get_dynamic_context(self)\nreturn context.process_higher_order_primitive(\nself, call_primitive, f, tracers, params, False\n)\ndef post_process_call(self, call_primitive, out_tracers, params):\nvals = tuple(t.val for t in out_tracers)\nmaster = self.main\ndef todo(x):\ntrace = ContextualTrace(master, jc.cur_sublevel())\nreturn jax_util.safe_map(functools.partial(ContextualTracer, trace), x)\nreturn vals, todo\ndef process_map(\nself,\ncall_primitive: jc.Primitive,\nf: Any,\ntracers: List[ContextualTracer],\nparams: Dict[str, Any],\n):\ncontext = staging.get_dynamic_context(self)\nreturn context.process_higher_order_primitive(\nself, call_primitive, f, tracers, params, True\n)\npost_process_map = post_process_call\ndef process_custom_jvp_call(self, primitive, fun, jvp, tracers, *, symbolic_zeros):\ncontext = staging.get_dynamic_context(self)\nreturn context.process_custom_jvp_call(\nself, primitive, fun, jvp, tracers, symbolic_zeros=symbolic_zeros\n)\ndef post_process_custom_jvp_call(self, out_tracers, jvp_was_run):\ncontext = staging.get_dynamic_context(self)\nreturn context.post_process_custom_jvp_call(self, out_tracers, jvp_was_run)\ndef process_custom_vjp_call(self, primitive, fun, fwd, bwd, tracers, out_trees):\ncontext = staging.get_dynamic_context(self)\nreturn context.process_custom_vjp_call(\nself, primitive, fun, fwd, bwd, tracers, out_trees\n)\ndef post_process_custom_vjp_call(self, out_tracers, params):\ncontext = staging.get_dynamic_context(self)\nreturn context.post_process_custom_vjp_call(self, out_tracers, params)\ndef post_process_custom_vjp_call_fwd(self, out_tracers, out_trees):\ncontext = staging.get_dynamic_context(self)\nreturn context.post_process_custom_vjp_call_fwd(self, out_tracers, out_trees)\n</code></pre>"},{"location":"genjax/library/generative_functions/index.html","title":"Generative function languages","text":"<p>This module contains several standard generative function classes useful for structuring probabilistic programs.</p>"},{"location":"genjax/library/generative_functions/builtin.html","title":"Builtin language","text":"<p>This module provides a function-like modeling language. The generative function interfaces are implemented for objects in this language using transformations by JAX interpreters.</p> <p>The language also exposes a set of JAX primitives which allow hierarchical construction of generative programs. These programs can utilize other generative functions inside of a new JAX primitive (<code>trace</code>) to create hierarchical patterns of generative computation.</p>"},{"location":"genjax/library/generative_functions/builtin.html#usage","title":"Usage","text":"<p>The <code>Builtin</code> language is a common foundation for constructing models. It exposes a DSL based on JAX primitives and transformations which allows the programmer to construct generative functions out of Python functions. </p> <p>Below, we illustrate a simple example:</p> <pre><code>from genjax import beta \nfrom genjax import bernoulli \nfrom genjax import uniform \nfrom genjax import gen\n@genjax.gen\ndef beta_bernoulli_process(u):\np = beta(0, u) @ \"p\"\nv = bernoulli(p) @ \"v\"\nreturn v\n@genjax.gen\ndef joint():\nu = uniform() @ \"u\"\nv = beta_bernoulli_process(u) @ \"bbp\"\nreturn v\n</code></pre>"},{"location":"genjax/library/generative_functions/builtin.html#language-primitives","title":"Language primitives","text":"<p>The builtin language exposes custom primitives, which are handled by JAX interpreters to support the semantics of the generative function interface.</p>"},{"location":"genjax/library/generative_functions/builtin.html#trace","title":"<code>trace</code>","text":"<p>The <code>trace</code> primitive provides access to the to invoke another generative function as a callee.</p>"},{"location":"genjax/library/generative_functions/builtin.html#cache","title":"<code>cache</code>","text":"<p>The <code>cache</code> primitive is designed to expose a space vs. time trade-off for incremental computation in Gen's <code>update</code> interface.</p>"},{"location":"genjax/library/generative_functions/builtin.html#generative-datatypes","title":"Generative datatypes","text":"<p>The builtin language implements a trie-like trace, choice map, and selection.</p>"},{"location":"genjax/library/generative_functions/builtin.html#genjax.generative_functions.builtin.BuiltinTrace","title":"<code>genjax.generative_functions.builtin.BuiltinTrace</code>  <code>dataclass</code>","text":"<p>         Bases: <code>Trace</code></p> Source code in <code>src/genjax/_src/generative_functions/builtin/builtin_datatypes.py</code> <pre><code>@dataclass\nclass BuiltinTrace(Trace):\ngen_fn: GenerativeFunction\nargs: Tuple\nretval: Any\nchoices: Trie\ncache: Trie\nscore: FloatArray\ndef flatten(self):\nreturn (\nself.gen_fn,\nself.args,\nself.retval,\nself.choices,\nself.cache,\nself.score,\n), ()\ndef get_gen_fn(self):\nreturn self.gen_fn\ndef get_choices(self):\nreturn BuiltinChoiceMap(self.choices)\ndef get_retval(self):\nreturn self.retval\ndef get_score(self):\nreturn self.score\ndef get_args(self):\nreturn self.args\ndef project(self, selection: Selection):\nweight = 0.0\nfor (k, v) in self.choices.get_subtrees_shallow():\nif selection.has_subtree(k):\nweight += v.project(selection[k])\nreturn weight\ndef has_cached_value(self, addr):\nreturn self.cache.has_subtree(addr)\ndef get_cached_value(self, addr):\nreturn self.cache.get_subtree(addr)\n</code></pre>"},{"location":"genjax/library/generative_functions/distributions/index.html","title":"Index","text":"<p>This module provides:</p> <ul> <li> <p>Abstract base classes for distributions which inherit from <code>GenerativeFunction</code>, including <code>Distribution</code> and <code>ExactDensity</code>. The latter assumes that the inheritor exposes exact density evaluation, while the former makes no such assumption.</p> </li> <li> <p>Several distributions as generative functions from JAX's <code>scipy</code> module, as well as TensorFlow Distributions from TensorFlow Probability (tfp) using the JAX backend.</p> </li> <li> <p>Custom distributions, including ones with exact posteriors (like discrete HMMs).</p> </li> <li> <p>A language (<code>coryx</code>) based on <code>oryx</code> for defining new distribution objects from inverse log determinant Jacobian transformations on existing distributions.</p> </li> <li> <p>A language (<code>prox</code>) for defining approximate distributions using inference algorithms that support estimation of their own densities.</p> </li> </ul>"},{"location":"genjax/library/inference/index.html","title":"Inference","text":"<p><code>genjax</code> exposes several inference algorithms which are implemented utilizing the generative function interface.</p>"}]}