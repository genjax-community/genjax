{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0b516969-c6ac-4371-b713-2df36415d6bd",
   "metadata": {},
   "source": [
    "---\n",
    "title: Probabilistic programming with approximate densities\n",
    "date: \"December 1, 2022\"\n",
    "abstract: \"This notebook illustrates usage of the Prox language (TODO cite Alex, Mat PLDI) for compositional programming with approximate densities. Advanced approximate inference algorithms often use proposals or variational families which sample auxiliary random variables. Prox provides an inference library whose algorithms themselves are also `Prox` approximate densities.\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e8fa03-db1f-42a6-8ed3-880b478e9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1cd8de-fc88-459a-bb5b-ee3bc4088710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import genjax\n",
    "import genjax.prox as prox\n",
    "from genjax import Normal, TFPUniform\n",
    "from math import pi as π\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Pretty printing.\n",
    "console = genjax.pretty(width=70)\n",
    "\n",
    "# Reproducibility.\n",
    "key = jax.random.PRNGKey(314159)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06fc05-0ffa-4618-8d6b-c720079f1c38",
   "metadata": {},
   "source": [
    "Let's start by defining a model generative program. This example is from [Alex Lew's 2020 LAFI talk on a related language called MetaPPL](https://popl20.sigplan.org/details/lafi-2020/14/MetaPPL-Inference-Algorithms-as-First-Class-Generative-Models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9360b-bb97-4708-8ecc-88e7ff2872d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@genjax.gen\n",
    "def model():\n",
    "    x = Normal(0.0, 10.0) @ \"x\"\n",
    "    y = Normal(0.0, 10.0) @ \"y\"\n",
    "    z = Normal(x**2 + y**2, 1.0) @ \"z\"\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2248642-3b01-470d-82e3-4a7e1b3e2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, sub_keys = genjax.slash(key, 300)\n",
    "_, trs = jax.vmap(model.simulate, in_axes=(0, None))(sub_keys, ())\n",
    "chm = trs.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e72c1-de1d-43e6-a280-4e16151fd0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "ax.scatter(chm[\"x\"], chm[\"y\"], chm[\"z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e275779-d470-402d-97e0-8c3e9460b379",
   "metadata": {},
   "source": [
    "When we use `prox.chm_dist` (which is shorthand for `prox.ChoiceMapDistribution`) - we're creating a new generative function whose internal proposal `q` can be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a01d9e-7e72-4864-9465-6c216baf72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_model = prox.chm_dist(model, selection=genjax.select([\"x\", \"y\"]), custom_q=None)\n",
    "prox_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16b4d75-0990-424a-89ac-cb1202968f4a",
   "metadata": {},
   "source": [
    "Above, we're keeping the default internal proposal `q` by not providing a `custom_q`. This means that `prox_model` inherits `q` from `model`.\n",
    "\n",
    "The resulting `prox_model` object is something called a `ChoiceMapDistribution` - it's an approximate distribution over the random choices at the addresses we pass in via `selection`.\n",
    "\n",
    "We specified `\"x\"` and `\"y\"` - which means we are asking for a distribution which is the **marginal** of the full joint of `model`.\n",
    "\n",
    "$$\n",
    "P(x, y) = \\int P(x, y, z) \\ dz\n",
    "$$\n",
    "\n",
    "As we know, this is the source of the intractability of Bayesian inference in the first place! So how do we get around this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8449892-43a2-4978-a4bb-cd3e6b81cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, tr = prox_model.simulate(key, ())\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a959ac4-ee6b-4f1f-b387-3034b1145e80",
   "metadata": {},
   "source": [
    "Another way to produce an approximate density is to condition a normalized distribution (producing an unnormalized one), then approximately normalize.\n",
    "\n",
    "`Prox` provides a way to express these densities using `prox.Target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af5a07c-5786-441d-af68-4d412d54711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint = genjax.choice_map({\"z\": 4.0})\n",
    "constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df8cb0-6a00-4cfc-a217-3f79eee73e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = prox.target(model, (), constraint)\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673939c2-99ca-43ef-be79-f5e6a3799e48",
   "metadata": {},
   "source": [
    "A `Target` is an unnormalized distribution. The standard inference library in `Prox` exposes inference algorithms which are themselves approximate densities, whose interfaces accept `Target` instances and perform approximate normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c73973-c39b-4e03-becb-ac75c357a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_is = prox.importance(50, None)\n",
    "prox_is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa00f13-494d-46ad-b007-c0d32d39d182",
   "metadata": {},
   "source": [
    "The default variant of `prox.importance` utilizes sampling importance resampling with no custom proposal. Let's examine the quality of the posterior approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee2d30-278d-41a7-a1e1-10d27f5c5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, sub_keys = genjax.slash(key, 1000)\n",
    "_, tr = jax.jit(jax.vmap(prox_is.simulate, in_axes=(0, None)))(sub_keys, (target,))\n",
    "chm = tr.get_retval()\n",
    "chm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f832e6bc-3910-455d-9813-338f04facffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlim(-3, 3)\n",
    "ax.set_ylim(-3, 3)\n",
    "circle = plt.Circle((0, 0), 2.0, color=\"k\", fill=False, lw=3)\n",
    "ax.scatter(chm[\"x\"], chm[\"y\"], marker=\".\")\n",
    "ax.add_artist(circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb5624-8a28-472f-ba0d-63ef9bedd0d9",
   "metadata": {},
   "source": [
    "We can improve the quality of the approximation by providing a custom proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c018e0-5f7f-4fec-8dfd-383333813f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@genjax.gen\n",
    "def custom_q(target):\n",
    "    chm = target.constraints\n",
    "    z = chm[\"z\"]\n",
    "    θ = TFPUniform(0.0, 2 * π) @ \"θ\"\n",
    "    x = Normal(jnp.sqrt(z) * jnp.cos(θ), 0.2) @ \"x\"\n",
    "    y = Normal(jnp.sqrt(z) * jnp.sin(θ), 0.2) @ \"y\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa7c96-ec1c-4f80-aa3b-8f0447b964aa",
   "metadata": {},
   "source": [
    "When run within the sampling importance resampling routine, the custom proposal is allowed to inspect the observed data (here, `chm`).\n",
    "\n",
    "Note that `custom_q` samples auxiliary randomness for the `\"θ\"` address - to correctly define the importance weight density ratio, we need to marginalize out `\"θ\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab27e42-c002-4545-a5ee-94b8e0a3f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_custom_q = prox.chm_dist(custom_q, selection=genjax.select([\"x\", \"y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1932ce6-143d-46fd-a063-2987304ec272",
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_is = prox.importance(50, prox_custom_q)\n",
    "prox_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34abf4-71fb-4dd2-8062-b8a62b3990e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, sub_keys = genjax.slash(key, 1000)\n",
    "_, tr = jax.jit(jax.vmap(prox_is.simulate, in_axes=(0, None)))(sub_keys, (target,))\n",
    "chm = tr.get_retval()\n",
    "chm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173dfa3f-6593-4b16-ae6e-109853b48357",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlim(-3, 3)\n",
    "ax.set_ylim(-3, 3)\n",
    "circle = plt.Circle((0, 0), 2.0, color=\"k\", fill=False, lw=3)\n",
    "ax.scatter(chm[\"x\"], chm[\"y\"], marker=\".\")\n",
    "ax.add_artist(circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee369d-b085-4586-bb28-c0ad35b2e37b",
   "metadata": {},
   "source": [
    "For both variants, we can estimate the log evidence and compare the value - the conditional log evidence ratio is often used for Bayesian model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8438ed-1e88-41be-b09f-5a1473e2163b",
   "metadata": {},
   "source": [
    "## Inference diagnostics for `Prox` distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f935f2c-4598-411e-8b53-65b837512f58",
   "metadata": {},
   "source": [
    "We started with a model $P(x, y, z)$ and then we constructed a posterior inference problem by creating a `Target` with constrained $z$. \n",
    "\n",
    "We then utilized default sampling importance resampling via `prox.importance` to construct an approximate normalized density. Our results for that initial variant were not so good - so we improved it by creating a custom proposal for `prox.importance` - but our custom proposal utilized auxiliary latent variables.\n",
    "\n",
    "To correctly compute the importance weight ratios including these auxiliary latents, we introduced a meta-proposal which we used to approximately marginalize out the new auxiliary latents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
