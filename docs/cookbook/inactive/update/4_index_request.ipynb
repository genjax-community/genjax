{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Speed Gains Part 2: Optimizing updates for vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import genjax\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax import (\n",
    "    IndexRequest,\n",
    "    StaticRequest,\n",
    "    Update,\n",
    "    gen,\n",
    "    normal,\n",
    "    pretty,\n",
    ")\n",
    "from genjax._src.core.pytree import Const\n",
    "\n",
    "pretty()\n",
    "key = jax.random.key(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed in the previous cookbook entries, a main point of `update` is to be used for incremental computation: `update` performs algebraic simplifications of the logpdf-ratios computed in the weight that it returns. This is tracked through the `Diff` system.\n",
    "\n",
    "A limitation of the current automation is that if an address \"x\" has a tensor value, and any index of \"x\" changes, the system will consider that \"x\" has changed without capturing a finer description of what exactly changed.\n",
    "\n",
    "However, we can manually specify how something has changed in a more specific way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def model(size_model_const: Const[int]):\n",
    "    size_model = size_model_const.unwrap()\n",
    "    x = normal(0.0, 1.0) @ \"x\"\n",
    "    a = normal.vmap()(jnp.zeros(size_model), jnp.ones(size_model)) @ \"a\"\n",
    "    b = normal.vmap()(jnp.zeros(size_model), jnp.ones(size_model)) @ \"b\"\n",
    "    c = normal.vmap()(jnp.zeros(size_model), jnp.ones(size_model)) @ \"c\"\n",
    "    obs = normal(jnp.sum(a) + jnp.sum(b) + jnp.sum(c) + x, 5.0) @ \"obs\"\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a trace from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = C[\"obs\"].set(\n",
    "    1.0,\n",
    ")\n",
    "size_model = 10000\n",
    "args = (Const(size_model),)\n",
    "key, subkey = jax.random.split(key)\n",
    "tr, _ = model.importance(subkey, obs, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see an equivalent way to perform do what `update` does. \n",
    "Just like `update` generalizes `importance`, there is yet another more general interface, `edit`, which generalizes `update`.\n",
    "\n",
    "We will go into the details of `edit` in a follow up cookbook.\n",
    "For now, let's see the equivalent of `update` using `edit`. For this, we introduce a `Request` to change the trace.\n",
    "`edit` will then answer the `Request` and change the trace following the logic of the request. \n",
    "To mimick `update`, we will perform an `Update` request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_in_value_for_a = jnp.ones(size_model)\n",
    "\n",
    "# usual update\n",
    "constraints = C[\"a\"].set(change_in_value_for_a)\n",
    "argdiffs = genjax.Diff.no_change(args)\n",
    "key, subkey = jax.random.split(key)\n",
    "new_tr1, _, _, _ = tr.update(subkey, constraints, argdiffs)\n",
    "\n",
    "# update using `Request`\n",
    "val = C.v(change_in_value_for_a)\n",
    "request = StaticRequest({\"a\": Update(val)})\n",
    "key, subkey = jax.random.split(key)\n",
    "new_tr2, _, _, _ = request.edit(subkey, tr, args)\n",
    "\n",
    "# comparing the values of both choicemaps after the update\n",
    "jax.tree_util.tree_all(\n",
    "    jax.tree.map(jnp.allclose, new_tr1.get_choices(), new_tr2.get_choices())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how we can efficiently change the value of \"a\" at a specific index. \n",
    "For that, we create a more specific `Request` called an `IndexRequest`. This request expects another request for what to do at the given index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = StaticRequest({\"a\": IndexRequest(jnp.array(3), Update(C.v(42.0)))})\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "new_tr, _, _, _ = request.edit(subkey, tr, args)\n",
    "\n",
    "# Checking we only made one change by checking that only one value in the choicemap is 42\n",
    "jnp.sum(new_tr.get_choices()[\"a\"] == 42.0) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare the 3 options: naive density ratio computation vs `update` vs `IndexRequest`. \n",
    "For this, we will do a comparison of doing an MH move on a specific variable in the model as we did in the previous cookbook, but this time for a specific index of the traced value \"a\".\n",
    "We will also compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_WHERE_CHANGE_A = 3\n",
    "\n",
    "\n",
    "@gen\n",
    "def rejuv_a(a):\n",
    "    a = normal(a, 1.0) @ \"a\"\n",
    "    return a\n",
    "\n",
    "\n",
    "def compute_ratio_slow(key, fwd_choice, fwd_weight, model_args, chm):\n",
    "    model_weight_old, _ = model.assess(chm, model_args)\n",
    "    new_a = chm[\"a\"].at[IDX_WHERE_CHANGE_A].set(fwd_choice[\"a\"])\n",
    "    new_chm = C[\"a\"].set(new_a) | chm\n",
    "    model_weight_new, _ = model.assess(new_chm, model_args)\n",
    "\n",
    "    old_a = C[\"a\"].set(chm[\"a\", IDX_WHERE_CHANGE_A])\n",
    "    proposal_args_backward = (fwd_choice[\"a\"],)\n",
    "    bwd_weight, _ = rejuv_a.assess(old_a, proposal_args_backward)\n",
    "    α = model_weight_new - model_weight_old - fwd_weight + bwd_weight\n",
    "    return α\n",
    "\n",
    "\n",
    "def compute_ratio_fast(key, fwd_choice, fwd_weight, model_args, trace):\n",
    "    argdiffs = genjax.Diff.no_change(model_args)\n",
    "    constraint = C[\"a\"].set(\n",
    "        trace.get_choices()[\"a\"].at[IDX_WHERE_CHANGE_A].set(fwd_choice[\"a\"])\n",
    "    )\n",
    "    _, weight, _, discard = model.update(key, trace, constraint, argdiffs)\n",
    "    proposal_args_backward = (fwd_choice[\"a\"],)\n",
    "    bwd_weight, _ = rejuv_a.assess(\n",
    "        C[\"a\"].set(discard[\"a\", IDX_WHERE_CHANGE_A]), proposal_args_backward\n",
    "    )\n",
    "    α = weight - fwd_weight + bwd_weight\n",
    "    return α\n",
    "\n",
    "\n",
    "def compute_ratio_very_fast(key, fwd_choice, fwd_weight, model_args, trace):\n",
    "    request = StaticRequest({\n",
    "        \"a\": IndexRequest(jnp.array(IDX_WHERE_CHANGE_A), Update(C.v(fwd_choice[\"a\"])))\n",
    "    })\n",
    "    _, weight, _, _ = request.edit(key, trace, model_args)\n",
    "    proposal_args_backward = (fwd_choice[\"a\"],)\n",
    "    bwd_weight, _ = rejuv_a.assess(\n",
    "        C[\"a\"].set(trace.get_choices()[\"a\", IDX_WHERE_CHANGE_A]), proposal_args_backward\n",
    "    )\n",
    "    α = weight - fwd_weight + bwd_weight\n",
    "    return α\n",
    "\n",
    "\n",
    "def metropolis_hastings_move(key, trace, which_move):\n",
    "    model_args = trace.get_args()\n",
    "    proposal_args_forward = (trace.get_choices()[\"a\", IDX_WHERE_CHANGE_A],)\n",
    "    key, subkey = jax.random.split(key)\n",
    "    fwd_choice, fwd_weight, _ = rejuv_a.propose(subkey, proposal_args_forward)\n",
    "    key, subkey = jax.random.split(key)\n",
    "\n",
    "    if which_move == 0:\n",
    "        chm = trace.get_choices()\n",
    "        α = compute_ratio_slow(subkey, fwd_choice, fwd_weight, model_args, chm)\n",
    "    elif which_move == 1:\n",
    "        α = compute_ratio_fast(subkey, fwd_choice, fwd_weight, model_args, trace)\n",
    "    else:\n",
    "        α = compute_ratio_very_fast(subkey, fwd_choice, fwd_weight, model_args, trace)\n",
    "\n",
    "    old_chm = C[\"a\"].set(trace.get_choices()[\"a\"])\n",
    "    new_chm = C[\"a\"].set(old_chm[\"a\"].at[IDX_WHERE_CHANGE_A].set(fwd_choice[\"a\"]))\n",
    "    key, subkey = jax.random.split(key)\n",
    "    ret_chm = jax.lax.cond(\n",
    "        jnp.log(jax.random.uniform(subkey)) < α, lambda: new_chm, lambda: old_chm\n",
    "    )\n",
    "    return ret_chm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sizes = [1000, 10000, 100000, 1000000, 10000000, 100000000]\n",
    "slow_times = []\n",
    "fast_times = []\n",
    "very_fast_times = []\n",
    "\n",
    "\n",
    "for model_size in model_sizes:\n",
    "    total_time_slow = 0\n",
    "    total_time_fast = 0\n",
    "    total_time_very_fast = 0\n",
    "    num_trials = 10000 if model_size <= 1000000 else 200\n",
    "    model_size = Const(model_size)\n",
    "    obs = C[\"obs\"].set(\n",
    "        1.0,\n",
    "    )\n",
    "    key, subkey = jax.random.split(key)\n",
    "\n",
    "    # create a trace from the model of the right size\n",
    "    tr, _ = jax.jit(model.importance, static_argnums=(2))(subkey, obs, (model_size,))\n",
    "\n",
    "    # warm up run to trigger jit compilation\n",
    "    jitted = jax.jit(metropolis_hastings_move, static_argnums=(2))\n",
    "    jitted(subkey, tr, 0)\n",
    "    jitted(subkey, tr, 1)\n",
    "    jitted(subkey, tr, 2)\n",
    "\n",
    "    # measure time for each algorithm\n",
    "    total_time_slow = timeit.timeit(lambda: jitted(subkey, tr, 0), number=num_trials)\n",
    "    total_time_fast = timeit.timeit(lambda: jitted(subkey, tr, 1), number=num_trials)\n",
    "    total_time_very_fast = timeit.timeit(\n",
    "        lambda: jitted(subkey, tr, 2), number=num_trials\n",
    "    )\n",
    "    average_time_slow = total_time_slow / num_trials\n",
    "    average_time_fast = total_time_fast / num_trials\n",
    "    average_time_very_fast = total_time_very_fast / num_trials\n",
    "    slow_times.append(average_time_slow)\n",
    "    fast_times.append(average_time_fast)\n",
    "    very_fast_times.append(average_time_very_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "# First half of the values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(\n",
    "    model_sizes[: len(model_sizes) // 2],\n",
    "    [time * 1000 for time in slow_times[: len(slow_times) // 2]],\n",
    "    marker=\"o\",\n",
    "    label=\"No incremental computation\",\n",
    ")\n",
    "plt.plot(\n",
    "    model_sizes[: len(model_sizes) // 2],\n",
    "    [time * 1000 for time in fast_times[: len(fast_times) // 2]],\n",
    "    marker=\"o\",\n",
    "    label=\"Default incremental computation\",\n",
    ")\n",
    "plt.plot(\n",
    "    model_sizes[: len(model_sizes) // 2],\n",
    "    [time * 1000 for time in very_fast_times[: len(very_fast_times) // 2]],\n",
    "    marker=\"o\",\n",
    "    label=\"Optimized incremental computation\",\n",
    ")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Argument (n)\")\n",
    "plt.ylabel(\"Average Time (milliseconds)\")\n",
    "plt.title(\"Average Execution Time of MH move for different model sizes (First Half)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Second half of the values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(\n",
    "    model_sizes[len(model_sizes) // 2 :],\n",
    "    [time * 1000 for time in slow_times[len(slow_times) // 2 :]],\n",
    "    marker=\"o\",\n",
    "    label=\"No incremental computation\",\n",
    ")\n",
    "plt.plot(\n",
    "    model_sizes[len(model_sizes) // 2 :],\n",
    "    [time * 1000 for time in fast_times[len(fast_times) // 2 :]],\n",
    "    marker=\"o\",\n",
    "    label=\"Default incremental computation\",\n",
    ")\n",
    "plt.plot(\n",
    "    model_sizes[len(model_sizes) // 2 :],\n",
    "    [time * 1000 for time in very_fast_times[len(very_fast_times) // 2 :]],\n",
    "    marker=\"o\",\n",
    "    label=\"Optimized incremental computation\",\n",
    ")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Argument (n)\")\n",
    "plt.ylabel(\"Average Time (milliseconds)\")\n",
    "plt.title(\"Average Execution Time of MH move for different model sizes (Second Half)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
