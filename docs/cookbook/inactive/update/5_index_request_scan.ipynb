{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed Gains Part 3: Optimizing updates for scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous entry, we have seen how to use `IndexRequest` to perform a more localized `update` in a `vmap` model. This is always sound to do this in a `vmap` model as, by construction, the variables in the different slices are independent (conditioned on the variables outside the `vmap`).\n",
    "\n",
    "Another kind of vectorized model is `scan`. The variable `x` at iteration $i$ and $i+1$ are both stored in the same tensor at the traced address `x`. In a general state-space model represented with a `scan`, if we change the value of `x` at iteration $i$, this change can affect all the downstream computations. Therefore, in general we need to recompute all the logpdf for the values traced at iteration $i+1$ and beyond. \n",
    "\n",
    "The default GenJAX does the conservative thing of recomputing logpdf for all the traced values, even before $i$.\n",
    "There is a special case of interest, however, where we can do better. In Hidden-Markov models (HMM), the conditional probabilities simplify as $P(x_{i+1}~|~x_i,x_{i-1}) = P(x_{i+1}~|~x_i)$. That is, no information from past steps to the future \"leaks through\", and is instead captured by only the previous  step. A simple counter-example would be having a momentum term $\\mu = \\sum_{J \\leq i} c_i.x_i$ that affects the sampling of $x_{i+1}$.\n",
    "\n",
    "In the HMM situation, if we change the value of $x_i$, we only need recompute the logpdf for $x_{i+1}$. This is because a change to $x_{i}$ will not change the value of $x_{i+1}$ and therefore we know there is no change to the logpdf of values $x_{i+1}$ and beyond.\n",
    "This is exactly what `IndexRequest` on a scan model leverages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import genjax\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax import IndexRequest, StaticRequest, Update, gen, normal, pretty\n",
    "\n",
    "key = jax.random.key(0)\n",
    "pretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple example of an HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "@gen\n",
    "def kernel(carry):\n",
    "    x = normal(carry, 1.0) @ \"x\"\n",
    "    y = normal(0.0, 1.0) @ \"y\"\n",
    "    return f(x, y)  # works in general for any deterministic function f\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "args = (jnp.array(0.0),)\n",
    "hmm = kernel.iterate(n=10)\n",
    "tr = hmm.simulate(subkey, args)\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try doing an `IndexRequest` and checking that it matches with what `update is computing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = IndexRequest(jnp.array(3), StaticRequest({\"x\": Update(C.v(42.0))}))\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "new_tr, w, _, _ = request.edit(subkey, tr, genjax.Diff.no_change(args))\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "constraint = C[\"x\"].set(tr.get_choices()[\"x\"].at[3].set(42.0))\n",
    "argdiff = genjax.Diff.no_change(args)\n",
    "new_tr1, w1, _, _ = tr.update(subkey, constraint, argdiff)\n",
    "\n",
    "assert w == w1 and jax.tree_util.tree_all(\n",
    "    jax.tree_util.tree_map(\n",
    "        lambda x, y: jnp.all(x == y), new_tr.get_choices(), new_tr1.get_choices()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of a kernel from a general state-space model that is not an HMM because it has a momentum-like term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(momentum, x, _):\n",
    "    return 0.9 * momentum + x\n",
    "\n",
    "\n",
    "@gen\n",
    "def kernel(momentum):\n",
    "    x = normal(momentum, 1.0) @ \"x\"\n",
    "    y = normal(0.0, 1.0) @ \"y\"\n",
    "    return f(momentum, x, y)\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "ssm = kernel.iterate(n=10)\n",
    "tr = ssm.simulate(subkey, (0.0,))\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, let's check that `IndexRequest` does not work on this model. In fact the system will detect it and throw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    request = IndexRequest(jnp.array(3), StaticRequest({\"x\": Update(C.v(42.0))}))\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    new_tr, w, _, _ = request.edit(subkey, tr, genjax.Diff.no_change(args))\n",
    "except AssertionError:\n",
    "    print(\n",
    "        \"IndexRequest failed as expected - this model does not satisfy the required conditions\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The restriction on `IndexRequest` being valid for a `scan` model is weaker than the HMM assumption. The general condition is that \n",
    "the distributions 2 indices after the request should not be impacted by the change. This is verified by the HMM condition which imposes that all interactions that are 2 steps away are mediated through the interaction one step away, but we don't necessarily need this global condition, and here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def kernel(carry):\n",
    "    _ = normal(carry, 1.0) @ \"x\"\n",
    "    y = normal(0.0, 1.0) @ \"y\"\n",
    "    return carry + y\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "non_hmm = kernel.iterate(n=10)\n",
    "tr = non_hmm.simulate(subkey, (0.0,))\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = IndexRequest(jnp.array(3), StaticRequest({\"x\": Update(C.v(42.0))}))\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "new_tr, w, _, _ = request.edit(subkey, tr, genjax.Diff.no_change(args))\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "constraint = C[\"x\"].set(tr.get_choices()[\"x\"].at[3].set(42.0))\n",
    "argdiff = genjax.Diff.no_change(args)\n",
    "new_tr1, w1, _, _ = tr.update(subkey, constraint, argdiff)\n",
    "\n",
    "assert w == w1 and jax.tree_util.tree_all(\n",
    "    jax.tree_util.tree_map(\n",
    "        lambda x, y: jnp.all(x == y), new_tr.get_choices(), new_tr1.get_choices()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that last model, if we change `y` at some index ten all the following carry which will effect all the following `x`, so the model is not an HMM.\n",
    "However, if we only decide to regenerate `x`, then this particular variable satisfies the condition and we can use `IndexRequest` here.\n",
    "\n",
    "A more intricate example where `x` does affect the future but in a restricted way is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def kernel(carry):\n",
    "    a, b = carry\n",
    "    x = normal(a, 1.0) @ \"x\"\n",
    "    y = normal(b, 1.0) @ \"y\"\n",
    "    return (x + y, b + y)\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "args = ((0.0, 0.0),)\n",
    "fancy_non_hmm = kernel.iterate(n=10)\n",
    "tr = fancy_non_hmm.simulate(subkey, args)\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `x` does affect the future carry (its left component) but it then gets absorbed into the next `x` and doesn’t leak further, so it behaves like an HMM on the left part of the carry. Thus we can use `IndexRequest(jnp.array(idx), Regenerate(S.at[\"x\"]))` . Still, we can’t use `IndexRequest(jnp.array(idx), Regenerate(S.at[\"y\"]))`  for the same argument as in the previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check this for the final example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = IndexRequest(jnp.array(3), StaticRequest({\"x\": Update(C.v(42.0))}))\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "new_tr, w, _, _ = request.edit(subkey, tr, genjax.Diff.no_change(args))\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "constraint = C[\"x\"].set(tr.get_choices()[\"x\"].at[3].set(42.0))\n",
    "argdiff = genjax.Diff.no_change(args)\n",
    "new_tr1, w1, _, _ = tr.update(subkey, constraint, argdiff)\n",
    "\n",
    "assert w == w1 and jax.tree_util.tree_all(\n",
    "    jax.tree_util.tree_map(\n",
    "        lambda x, y: jnp.all(x == y), new_tr.get_choices(), new_tr1.get_choices()\n",
    "    )\n",
    ")\n",
    "try:\n",
    "    key, subkey = jax.random.split(key)\n",
    "    constraint = C[\"y\"].set(tr.get_choices()[\"y\"].at[3].set(42.0))\n",
    "    argdiff = genjax.Diff.no_change(args)\n",
    "    new_tr2, w1, _, _ = tr.update(subkey, constraint, argdiff)\n",
    "except AssertionError:\n",
    "    print(\"Update failed as expected - y affects future carries\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
