{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Markov Chain Monte Carlo (MCMC)\n",
    "subtitle: What is MCMC? How do I use it? How do I write one?\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax import gen, normal, pretty\n",
    "from genjax._src.core.interpreters.incremental import Diff\n",
    "\n",
    "key = jax.random.key(0)\n",
    "pretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first define a simple model using GenJAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def model(x):\n",
    "    a = normal(0.0, 5.0) @ \"a\"\n",
    "    b = normal(0.0, 1.0) @ \"b\"\n",
    "    y = normal(a * x + b, 1.0) @ \"y\"\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together with observations, this creates a posterior inference problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = C[\"y\"].set(4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key ingredient in MCMC is a transition kernel.\n",
    "We can write it in GenJAX as a function that takes a current trace and returns a new trace.\n",
    "\n",
    "Let's write a simple Metropolis-Hastings (MH) kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings_move(mh_args, key):\n",
    "    # For now, we give the kernel the full state of the model, the proposal, and the observations.\n",
    "    trace, model, proposal, proposal_args, observations = mh_args\n",
    "    model_args = trace.get_args()\n",
    "\n",
    "    # The core computation is updating a trace, and for that we will call the model's update method.\n",
    "    # The update method takes a random key, a trace, and a choice map object, and argument difference objects.\n",
    "    argdiffs = Diff.no_change(model_args)\n",
    "    proposal_args_forward = (trace, *proposal_args)\n",
    "\n",
    "    # We sample the proposed changes to the trace.\n",
    "    # This is encapsulated in a simple GenJAX generative function.\n",
    "    key, subkey = jax.random.split(key)\n",
    "    fwd_choices, fwd_weight, _ = proposal.propose(key, proposal_args_forward)\n",
    "\n",
    "    new_trace, weight, _, discard = model.update(subkey, trace, fwd_choices, argdiffs)\n",
    "\n",
    "    # Because we are using MH, we don't directly accept the new trace.\n",
    "    # Instead, we compute a (log) acceptance ratio α and decide whether to accept the new trace, and otherwise keep the old one.\n",
    "    proposal_args_backward = (new_trace, *proposal_args)\n",
    "    bwd_weight, _ = proposal.assess(discard.choice_map, proposal_args_backward)\n",
    "    α = weight - fwd_weight + bwd_weight\n",
    "    key, subkey = jax.random.split(key)\n",
    "    ret_fun = jax.lax.cond(\n",
    "        jnp.log(jax.random.uniform(subkey)) < α, lambda: new_trace, lambda: trace\n",
    "    )\n",
    "    return (ret_fun, model, proposal, proposal_args, observations), ret_fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a simple proposal distribution for the changes in the trace using a Gaussian drift around the current value of `\"a\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def prop(tr, *_):\n",
    "    orig_a = tr.get_choices()[\"a\"]\n",
    "    a = normal(orig_a, 1.0) @ \"a\"\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall MH algorithm is a loop that repeatedly applies the MH kernel,\n",
    "which can conveniently be written using `jax.lax.scan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mh(trace, model, proposal, proposal_args, observations, key, num_updates):\n",
    "    mh_keys = jax.random.split(key, num_updates)\n",
    "    last_carry, mh_chain = jax.lax.scan(\n",
    "        metropolis_hastings_move,\n",
    "        (trace, model, proposal, proposal_args, observations),\n",
    "        mh_keys,\n",
    "    )\n",
    "    return last_carry[0], mh_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom MH algorithm is a simple wrapper around the MH kernel using our chosen proposal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mh(trace, model, observations, key, num_updates):\n",
    "    return mh(trace, model, prop, (), observations, key, num_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to create a function run_inference that takes the inference problem, i.e. the model and observations, a random key, and returns traces from the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, model_args, obs, key, num_samples):\n",
    "    key, subkey1, subkey2 = jax.random.split(key, 3)\n",
    "    # We sample once from a default importance sampler to get an initial trace.\n",
    "    # The particular initial distribution is not important, as the MH kernel will rejuvenate it.\n",
    "    tr, _ = model.importance(subkey1, obs, model_args)\n",
    "    # We then run our custom Metropolis-Hastings kernel to rejuvenate the trace.\n",
    "    rejuvenated_trace, mh_chain = custom_mh(tr, model, obs, subkey2, num_samples)\n",
    "    return rejuvenated_trace, mh_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We add a little visualization function to validate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mh(mh_chain):\n",
    "    a = mh_chain.get_choices()[\"a\"]\n",
    "    b = mh_chain.get_choices()[\"b\"]\n",
    "    y = mh_chain.get_retval()\n",
    "    x = mh_chain.get_args()[0]\n",
    "    plt.plot(range(len(y)), a * x + b)\n",
    "    plt.plot(range(len(y)), y, color=\"k\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the inference function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = (5.0,)\n",
    "num_samples = 40000\n",
    "key, subkey = jax.random.split(key)\n",
    "_, mh_chain = run_inference(model, model_args, obs, subkey, num_samples)\n",
    "validate_mh(mh_chain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
