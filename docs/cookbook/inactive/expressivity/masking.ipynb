{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### I want more dynamic features but JAX only accepts arrays with statically known sizes, what do I do? [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChiSym/genjax/blob/main/docs/cookbook/inactive/expressivity/masking.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    %pip install --quiet \"genjax[genstudio]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from PIL import Image\n",
    "\n",
    "import genjax\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax import bernoulli, categorical, gen, normal, or_else, pretty\n",
    "\n",
    "pretty()\n",
    "key = jax.random.key(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One classic trick is to encode all the options as an array and pick the desired value from the array with a dynamic one.\n",
    "\n",
    "Here's a first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def model(\n",
    "    i, means, vars\n",
    "):  # provide all the possible values and the dynamic index to pick from them\n",
    "    x = normal(means[i], vars[i]) @ \"x\"\n",
    "    return x\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "model.simulate(subkey, (7, jnp.arange(10, dtype=jnp.float32), jnp.ones(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if there's a value we may or may not want to get depending on a dynamic value?\n",
    "\n",
    "In this case, we can use masking. Let's look at an example in JAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_masked = jnp.arange(9).reshape(3, 3)\n",
    "\n",
    "non_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask the upper triangular part of the matrix\n",
    "mask = jnp.mask_indices(3, jnp.triu)\n",
    "\n",
    "non_masked[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use similar logic for generative functions in GenJAX. \n",
    "\n",
    "Let's create an HMM using the scan combinator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = 10\n",
    "length = 10\n",
    "variance = jnp.eye(state_size)\n",
    "key, subkey = jax.random.split(key)\n",
    "initial_state = jax.random.normal(subkey, (state_size,))\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "def hmm_step(x):\n",
    "    new_x = genjax.mv_normal(x, variance) @ \"new_x\"\n",
    "    return new_x\n",
    "\n",
    "\n",
    "hmm = hmm_step.iterate_final(n=length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run it, we get a full trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitted = jax.jit(hmm.simulate)\n",
    "key, subkey = jax.random.split(key)\n",
    "trace = jitted(subkey, (initial_state,))\n",
    "trace.get_choices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the partial results in the HMM instead, we can use the masked version of `iterate_final` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_at_index = 5\n",
    "pairs = jnp.arange(state_size) < stop_at_index\n",
    "masked_hmm = hmm_step.masked_iterate_final()\n",
    "key, subkey = jax.random.split(key)\n",
    "choices = masked_hmm.simulate(subkey, (initial_state, pairs)).get_choices()\n",
    "choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we obtain a filtered choice map, with a selection representing the boolean mask array.\n",
    "Within the filtered choice map, we have a static choice map where all the results are computed, without the mask applied to them.\n",
    "This is generally what will happen behind the scene in GenJAX: results will tend to be computed and then ignored, which is often more efficient on the GPU rather than being too eager in trying to avoid to do computations in the first place.\n",
    "\n",
    "Let's now use it in a bigger computation where the masking index is dynamic and comes from a sampled value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def larger_model(init, probs):\n",
    "    i = categorical(probs) @ \"i\"\n",
    "    mask = jnp.arange(10) < i\n",
    "    x = masked_hmm(init, mask) @ \"x\"\n",
    "    return x\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "init = jax.random.normal(subkey, (state_size,))\n",
    "probs = jnp.arange(state_size) / sum(jnp.arange(state_size))\n",
    "key, subkey = jax.random.split(key)\n",
    "choices = larger_model.simulate(subkey, (init, probs)).get_choices()\n",
    "choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen how to use conditionals in GenJAX models in the `conditionals` notebook. Behind the scene, it's using the same logic with masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def cond_model(p):\n",
    "    pred = p > 0\n",
    "    arg_1 = (p,)\n",
    "    arg_2 = (p,)\n",
    "    v = (\n",
    "        or_else(\n",
    "            gen(lambda p: bernoulli(p) @ \"v1\"), gen(lambda p: bernoulli(-p) @ \"v1\")\n",
    "        )(pred, arg_1, arg_2)\n",
    "        @ \"cond\"\n",
    "    )\n",
    "    return v\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "choices = cond_model.simulate(subkey, (0.5,)).get_choices()\n",
    "choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both branches will get evaluated and a mask will be applied to each branch, whose value depends on the evaluation of the boolean predicate `pred`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening behind the scene for masked values in the trace? Simply put, even though the system computes values, they are ignored w.r.t. the math of inference. \n",
    "\n",
    "We can check it on a simple example, with two versions of a model, where one has an extra masked variable `y`.\n",
    "Let's first define the two versions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def simple_model():\n",
    "    x = normal(0.0, 1.0) @ \"x\"\n",
    "    return x\n",
    "\n",
    "\n",
    "@gen\n",
    "def submodel():\n",
    "    y = normal(0.0, 1.0) @ \"y\"\n",
    "    return y\n",
    "\n",
    "\n",
    "@gen\n",
    "def model_with_mask():\n",
    "    x = normal(0.0, 1.0) @ \"x\"\n",
    "    _ = submodel.mask()(False) @ \"y\"\n",
    "    return x\n",
    "\n",
    "\n",
    "@gen\n",
    "def proposal(_: genjax.Target):\n",
    "    x = normal(3.0, 1.0) @ \"x\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test that on the same key, they return the exact same score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "simple_target = genjax.Target(simple_model, (), C.n())\n",
    "masked_target = genjax.Target(model_with_mask, (), C.n())\n",
    "simple_alg = genjax.smc.Importance(simple_target, q=proposal.marginal())\n",
    "masked_alg = genjax.smc.Importance(masked_target, q=proposal.marginal())\n",
    "\n",
    "# TODO: something's fishy here with the math. Get the same whether I mask or not.\n",
    "simple_alg.simulate(subkey, (simple_target,)).get_score() == masked_alg.simulate(\n",
    "    subkey, (masked_target,)\n",
    ").get_score()\n",
    "\n",
    "masked_alg.simulate(subkey, (masked_target,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a final example for an unknown number of objects that may evolve over time. \n",
    "For this, we can use `vmap` over a masked object andd we get to choose which ones are masked or not. \n",
    "\n",
    "Let's create a model consisting of a 2D image where each pixel is traced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def single_pixel():\n",
    "    pixel = normal(0.0, 1.0) @ \"pixel\"\n",
    "    return pixel\n",
    "\n",
    "\n",
    "image_model = single_pixel.mask().vmap(in_axes=(0,)).vmap(in_axes=(0,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a circular mask around the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_circle_mask(size=200, center=None, radius=80):\n",
    "    if center is None:\n",
    "        center = (size // 2, size // 2)\n",
    "\n",
    "    y, x = jnp.ogrid[:size, :size]\n",
    "    dist_from_center = jnp.sqrt((x - center[0]) ** 2 + (y - center[1]) ** 2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask\n",
    "\n",
    "\n",
    "circle_mask = create_circle_mask()\n",
    "\n",
    "plt.imshow(circle_mask, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now sample from the masked image and play with the mask and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "tr = image_model.simulate(subkey, (circle_mask,))\n",
    "flag = tr.get_choices()[:, :, \"pixel\"].flag\n",
    "im = flag * tr.get_choices()[:, :, \"pixel\"].value\n",
    "\n",
    "plt.imshow(im, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a small animation by updating the mask over time using the GenJAX `update` function to ensure that the probabilistic parts are taken properly into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_iter = 10\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Load the image\n",
    "image_path = \"./ending_dynamic_computation.png\"  # Update with your image path\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert to grayscale if needed and resize to match new_im dimensions\n",
    "image = image.convert(\"L\")  # Convert to grayscale\n",
    "image = image.resize(im.shape[1::-1])  # Resize to match (height, width)\n",
    "\n",
    "# Convert to NumPy array\n",
    "image_array = jnp.array(image) / 255.0\n",
    "\n",
    "images = []\n",
    "for i in range(number_iter):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    new_circle_mask = create_circle_mask(radius=10 * i)\n",
    "    arg_diff = (genjax.Diff(new_circle_mask, genjax.UnknownChange),)\n",
    "    constraints = C.n()\n",
    "    update_problem = genjax.Update(constraints)\n",
    "    tr, _, _, _ = tr.edit(key, update_problem, arg_diff)\n",
    "    flag = tr.get_choices()[:, :, \"pixel\"].flag\n",
    "    new_im = flag * (tr.get_choices()[:, :, \"pixel\"].value / 5.0 + image_array)\n",
    "    images.append([ax.imshow(new_im, cmap=\"gray\", vmin=0, vmax=1, animated=True)])\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, images, interval=200, blit=True, repeat_delay=1000)\n",
    "\n",
    "# Save the animation as a GIF\n",
    "ani.save(\"masked_image_animation.gif\", writer=\"pillow\")\n",
    "\n",
    "# Display the animation in the notebook\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
