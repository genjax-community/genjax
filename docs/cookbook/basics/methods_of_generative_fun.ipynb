{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok I have a generative function. What can I do with it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from genjax import beta\n",
    "from genjax import bernoulli\n",
    "from genjax import gen\n",
    "\n",
    "# Define a generative function\n",
    "@gen\n",
    "def beta_bernoulli_process(u):\n",
    "    p = beta(1.0, u) @ \"p\"\n",
    "    v = bernoulli(p) @ \"v\"\n",
    "    return 2*v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our generative function, the first thing we can do is to generate a traced sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "\n",
      "XorChm(c1=StaticChm(addr='p', c=ValueChm(v=<jax.Array(0.97251576, dtype=float32)>)), c2=StaticChm(addr='v', c=ValueChm(v=<jax.Array(1, dtype=int32)>)))\n",
      "XorChm(c1=StaticChm(addr='p', c=ValueChm(v=<jax.Array(0.97251576, dtype=float32)>)), c2=StaticChm(addr='v', c=ValueChm(v=<jax.Array(1, dtype=int32)>)))\n",
      "0.97251576\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1] Generate a traced sample\n",
    "key = jax.random.PRNGKey(0)\n",
    "trace = jax.jit(beta_bernoulli_process.simulate)(key, (0.5,))\n",
    "\n",
    "# 1.1] Print the return value\n",
    "print(trace.get_retval())\n",
    "print()\n",
    "\n",
    "# 1.2] Print the choice_map, i.e. the list of internal random choices made during the execution\n",
    "print(trace.get_sample())\n",
    "# Alternative way to print the choice_map\n",
    "print(trace.get_choices())\n",
    "# Print specific subparts of the choice_map\n",
    "print(trace.get_sample()[\"p\"])\n",
    "print(trace.get_sample()[\"v\"])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can create a choice_map of observations and perform diverse operations on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XorChm(c1=StaticChm(addr='p', c=ValueChm(v=0.5)), c2=StaticChm(addr='v', c=ValueChm(v=1)))\n",
      "OrChm(c1=StaticChm(addr='v', c=ValueChm(v=1)), c2=StaticChm(addr='p', c=ValueChm(v=0.5)))\n",
      "StaticChm(addr='p', c=StaticChm(addr='v', c=ValueChm(v=1)))\n",
      "ValueChm(v=5.0)\n"
     ]
    }
   ],
   "source": [
    "# Create a choice_map of observations\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "\n",
    "# We can set the value of an address in the choice_map\n",
    "chm = C[\"p\"].set(0.5) ^ C[\"v\"].set(1)\n",
    "print(chm)\n",
    "\n",
    "# A different way to achieve the same result\n",
    "chm = C[\"p\"].set(0.5).at[\"v\"].set(1)\n",
    "print(chm)\n",
    "\n",
    "# This also works for hierarchical addresses\n",
    "chm = C[\"p\", \"v\"].set(1) \n",
    "print(chm)\n",
    "\n",
    "# We can also directly set a value in the choice_map\n",
    "chm = C.v(5.0)\n",
    "print(chm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, we can compute log probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7831962\n",
      "\n",
      "(Array(-0.8206506, dtype=float32), Array(2, dtype=int32))\n",
      "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.\n"
     ]
    }
   ],
   "source": [
    "# 2] Compute log probabilities\n",
    "\n",
    "# 2.1] Print the log probability of the trace\n",
    "print(trace.get_score())\n",
    "print()\n",
    "\n",
    "# 2.2] Print the log probability of an observation encoded as a ChoiceMap under the model\n",
    "# It returns both the log probability and the return value\n",
    "chm = C[\"p\"].set(0.5) ^ C[\"v\"].set(1)\n",
    "args = (0.5,)\n",
    "print(beta_bernoulli_process.assess(chm, args))\n",
    "\n",
    "# Note that the ChoiceMap should be complete, i.e. all random choices should be observed\n",
    "chm_2 = C[\"v\"].set(1)\n",
    "try: \n",
    "    beta_bernoulli_process.assess(chm_2, args)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a partial ChoiceMap as a constraint/observation and generate a full trace with these constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XorChm(c1=StaticChm(addr='p', c=ValueChm(v=<jax.Array(0.4484125, dtype=float32)>)), c2=StaticChm(addr='v', c=ValueChm(v=1)))\n",
      "-0.49386734\n"
     ]
    }
   ],
   "source": [
    "# 3] Generate a sample conditioned on the observations\n",
    "key = jax.random.PRNGKey(42)\n",
    "partial_chm =  C[\"v\"].set(1) # Creates a ChoiceMap of observations\n",
    "args = (0.5,)\n",
    "trace, weight = beta_bernoulli_process.importance(key, partial_chm, args) # Runs importance sampling\n",
    "\n",
    "# This returns a pair containing the new trace and the log probability of produced trace under the model\n",
    "print(trace.get_sample())\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also update a trace. This is for instance useful for performance optimizations in MH algorithms where often most of the trace doesn't change between time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XorChm(c1=StaticChm(addr='p', c=ValueChm(v=<jax.Array(0.4484125, dtype=float32)>)), c2=StaticChm(addr='v', c=ValueChm(v=<jax.Array(1, dtype=int32)>)))\n",
      "Old value for p: 0.4484125\n",
      "New value for p: 0.4484125\n",
      "\n",
      "0.3956688\n",
      "\n",
      "Diff(primal=<jax.Array(2, dtype=int32)>, tangent=_UnknownChange())\n",
      "\n",
      "XorChm(c1=StaticChm(addr='p', c=ValueChm(v=EmptyProblem())), c2=StaticChm(addr='v', c=ValueChm(v=<jax.Array(1, dtype=int32)>)))\n",
      "42.8 µs ± 1.05 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "78.4 µs ± 1.49 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# 4] Update a trace.\n",
    "from genjax.incremental import Diff, NoChange, UnknownChange\n",
    "from genjax import bernoulli, gen, GenericProblem\n",
    "from jax import jit\n",
    "\n",
    "# Define a model for which changing the argument will force a change in the trace.\n",
    "@gen\n",
    "def beta_bernoulli_process(u):\n",
    "    p = beta(1.0, u) @ \"p\"\n",
    "    v = bernoulli(p) @ \"v\"\n",
    "    return 2*v\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "jitted = jit(beta_bernoulli_process.simulate)\n",
    "old_trace = jitted(key, (0.5,))\n",
    "constraint =  C[\"v\"].set(1)\n",
    "# Update uses incremental computation.\n",
    "# It works by tracking the differences between the old new values for arguments.\n",
    "# Just like for differentiation, it can be achieved by providing for each argument a tuple containing the new value and its change compared to the old value.\n",
    "\n",
    "# If there's no change for an argument, the change is set to NoChange.\n",
    "arg_diff = (Diff(1.0, NoChange),) \n",
    "# If there's a change, the change is set to the difference between the new and old value.\n",
    "arg_diff = (Diff(3.0, 2.0),)\n",
    "# If there's an unknown change, the change is set to UnknownChange.\n",
    "arg_diff = (Diff(1.0, UnknownChange),)\n",
    "# we bundle together the arguments and the constraint as a GenericProblem, a simple instance of an UpdateProblem.\n",
    "update = GenericProblem(arg_diff, constraint)\n",
    "\n",
    "jitted_update = jit(beta_bernoulli_process.update)\n",
    "\n",
    "new_trace, weight_diff, ret_diff, discard_choice = jitted_update(\n",
    "    key, \n",
    "    old_trace, \n",
    "    update\n",
    "    )\n",
    "\n",
    "# print the old trace with a message\n",
    "print(old_trace.get_sample())\n",
    "print(\"Old value for p:\", old_trace.get_sample()[\"p\"])\n",
    "print(\"New value for p:\", new_trace.get_sample()[\"p\"]) \n",
    "print()\n",
    "print(weight_diff)\n",
    "print()\n",
    "print(ret_diff)\n",
    "print()\n",
    "print(discard_choice)\n",
    "\n",
    "%timeit jitted(key, (0.5,))\n",
    "%timeit jitted_update(key, old_trace, update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XorChm(c1=StaticChm(addr='p', c=ValueChm(v=<jax.Array(0.97251576, dtype=float32)>)), c2=StaticChm(addr='v', c=ValueChm(v=<jax.Array(1, dtype=int32)>)))\n",
      "\n",
      "0.7831962\n",
      "\n",
      "2\n",
      "\n",
      "StaticGenerativeFunction(source=Closure(dyn_args=(), fn=<function beta_bernoulli_process at 0x2ca085ee0>))\n",
      "\n",
      "(Array(0.5, dtype=float32, weak_type=True),)\n",
      "\n",
      "ValueChm(v=<jax.Array(0.97251576, dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "# 5] A few more convenient methods\n",
    "# 5.1] propose\n",
    "# It uses the same inputs as simulate but returns the sample, the score and the return value\n",
    "sample, score, retval = jit(beta_bernoulli_process.propose)(key, (0.5,))\n",
    "print(sample)\n",
    "print()\n",
    "print(score)\n",
    "print() \n",
    "print(retval)\n",
    "print()\n",
    "\n",
    "# 5.2] get_gen_fn\n",
    "# It returns the generative function that produced the trace\n",
    "gen_fn = trace.get_gen_fn()\n",
    "print(gen_fn)\n",
    "print()\n",
    "\n",
    "# 5.2] get_args\n",
    "# It returns the arguments passed to the generative function used to produce the trace\n",
    "args = trace.get_args()\n",
    "print(args)\n",
    "print()\n",
    "\n",
    "# 5.3] get_subtrace\n",
    "# It takes a `StaticAddress` as argument and returns the sub-trace of a trace rooted at these addresses\n",
    "subtrace = trace.get_subtrace((\"p\",))\n",
    "print(subtrace.get_sample())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genjax-trials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
